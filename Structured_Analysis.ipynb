{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, Normalizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "import sklearn_pandas\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.special import boxcox1p\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress ConvergenceWarning warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle train data\n",
    "data_df = pd.read_csv(\"train.csv\")\n",
    "# kaggle test data\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal   208500.0  \n",
       "1   2007        WD         Normal   181500.0  \n",
       "2   2008        WD         Normal   223500.0  \n",
       "3   2006        WD        Abnorml   140000.0  \n",
       "4   2008        WD         Normal   250000.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat((data_df.loc[:,:], test_df.loc[:, :]))\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic summary:\n",
    "data_df['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='SalePrice', ylabel='Density'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The Density Plot of SalePrice\n",
    "sns.distplot(data_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8828757597682129"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['SalePrice'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"SalePrice\"] = np.log1p(data_df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Density plot of SalePrice after Log Transformation')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SalePrice after Log-transformation\n",
    "sns.distplot(data_df[\"SalePrice\"])\n",
    "plt.title(\"Density plot of SalePrice after Log Transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = data_df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with Nan values\n",
    "\n",
    "At first, I am checking the fraction of Nan values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nan = data_df.isna().sum() / data_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Features with the highest percentage of Nan values')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.set(font_scale=1.2)\n",
    "col_nan[col_nan > 0.01].plot(kind = \"barh\")\n",
    "plt.title(\"Features with the highest percentage of Nan values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns for both train and test dataset\n",
    "data_df = data_df.drop(\"Id\", axis=1)\n",
    "test_df = test_df.drop(\"Id\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns that contain the same value in 100%\n",
    "\n",
    "According to basic statistics provided on Kaggle competiton website, the columns Street and Utilities contain only one value \"Pave\" and \"AllPub\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop([\"Street\", \"Utilities\"], axis=1)\n",
    "test_df = test_df.drop([\"Street\", \"Utilities\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outliers\n",
    "\n",
    "Removing outliers is important step in data analysis. However, while removing outliers in ML we should be careful, because we do not know if there are not any outliers in test set.\n",
    "\n",
    "I used two techniques: more and less rigorous for this data.\n",
    "\n",
    "The first one was Z-score method. Z-scores are expressed in terms of standard deviations from their means. As a result, these z-scores have a distribution with a mean of 0 and a standard deviation of 1.\n",
    "I set threshold = 3 to identify outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(dataset, threshold, columns=None, removed = False):\n",
    "    \"\"\" \n",
    "    Z-score method.\n",
    "    Function returns a dataframe without rows labeled as 'outliers' according to the given threshold.  \n",
    "    ---------------\n",
    "    If columns = None, transform all numerical columns.\n",
    "    If removed = True, return also dataframe with removed rows.\n",
    "    \"\"\"\n",
    "    if columns==None:\n",
    "        numerics = ['int64','float64']\n",
    "        columns = dataset.select_dtypes(include=numerics).columns\n",
    "    \n",
    "    tmp = dataset.copy()\n",
    "    z = np.abs(stats.zscore(tmp[columns]))\n",
    "    outliers = [row.any() for row in (z > threshold)]  \n",
    "    outliers_idxs = tmp.index[outliers].tolist()\n",
    "    print(\"Number of removed rows = {}\".format(len(outliers_idxs)))\n",
    "    if removed: return dataset.drop(outliers_idxs), tmp.loc[outliers]\n",
    "    else: return dataset.drop(outliers_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.scatterplot(x=\"GrLivArea\", y=\"SalePrice\", data=data_df)\n",
    "plt.title(\"GrLivArea vs SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided to remove those records where 'GrLivArea' is more than 4500. We can see on plot that they have a vey low price.\n",
    "clear_data = data_df.drop(data_df[(data_df['GrLivArea']>4500)].index)\n",
    "\n",
    "# Concatenate all data together - both train and test\n",
    "train_ = clear_data.drop(['SalePrice'], axis=1)\n",
    "all_data = pd.concat([data_df, test_df]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GarageYrBlt feature\n",
    "\n",
    "I checked if there are records that YearBuilt or GarageYrBlt have further year than 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there YearBuilt more than 2017 ? :  False\n",
      "Is there GarageYrBlt more than 2017 ? :  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is there YearBuilt more than 2017 ? : \", all_data[all_data.YearBuilt > 2017].count()[0] != 0)\n",
    "print(\"Is there GarageYrBlt more than 2017 ? : \", all_data[all_data.GarageYrBlt > 2017].count()[0] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592    2207.0\n",
       "Name: GarageYrBlt, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data.GarageYrBlt > 2017].GarageYrBlt #It seems like it is a typo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[2590, 'GarageYrBlt'] = 2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LotFrontage feature\n",
    "\n",
    "LotFrontage is a linear feet of street connected to property. I think it is a high probability that these values are similar to houses in the same Neighborhood. I check some statistics for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>avg_mean_median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blmngtn</th>\n",
       "      <td>46.900000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blueste</th>\n",
       "      <td>27.300000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrDale</th>\n",
       "      <td>21.500000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrkSide</th>\n",
       "      <td>55.789474</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.394737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClearCr</th>\n",
       "      <td>88.150000</td>\n",
       "      <td>80.5</td>\n",
       "      <td>84.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CollgCr</th>\n",
       "      <td>71.336364</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.668182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crawfor</th>\n",
       "      <td>69.951807</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.975904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edwards</th>\n",
       "      <td>66.910112</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.955056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilbert</th>\n",
       "      <td>74.207207</td>\n",
       "      <td>64.0</td>\n",
       "      <td>69.103604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDOTRR</th>\n",
       "      <td>62.241379</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.120690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeadowV</th>\n",
       "      <td>25.606061</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>75.144444</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.572222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAmes</th>\n",
       "      <td>75.210667</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.105333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPkVill</th>\n",
       "      <td>28.142857</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NWAmes</th>\n",
       "      <td>81.517647</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoRidge</th>\n",
       "      <td>91.629630</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.314815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NridgHt</th>\n",
       "      <td>84.184049</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.092025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OldTown</th>\n",
       "      <td>61.777293</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.888646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWISU</th>\n",
       "      <td>59.068182</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59.534091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sawyer</th>\n",
       "      <td>74.551020</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.275510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SawyerW</th>\n",
       "      <td>70.669811</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.834906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somerst</th>\n",
       "      <td>64.549383</td>\n",
       "      <td>72.5</td>\n",
       "      <td>68.524691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StoneBr</th>\n",
       "      <td>62.173913</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timber</th>\n",
       "      <td>81.157895</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veenker</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean  median  avg_mean_median\n",
       "Neighborhood                                    \n",
       "Blmngtn       46.900000    43.0        44.950000\n",
       "Blueste       27.300000    24.0        25.650000\n",
       "BrDale        21.500000    21.0        21.250000\n",
       "BrkSide       55.789474    51.0        53.394737\n",
       "ClearCr       88.150000    80.5        84.325000\n",
       "CollgCr       71.336364    70.0        70.668182\n",
       "Crawfor       69.951807    70.0        69.975904\n",
       "Edwards       66.910112    65.0        65.955056\n",
       "Gilbert       74.207207    64.0        69.103604\n",
       "IDOTRR        62.241379    60.0        61.120690\n",
       "MeadowV       25.606061    21.0        23.303030\n",
       "Mitchel       75.144444    74.0        74.572222\n",
       "NAmes         75.210667    73.0        74.105333\n",
       "NPkVill       28.142857    24.0        26.071429\n",
       "NWAmes        81.517647    80.0        80.758824\n",
       "NoRidge       91.629630    89.0        90.314815\n",
       "NridgHt       84.184049    92.0        88.092025\n",
       "OldTown       61.777293    60.0        60.888646\n",
       "SWISU         59.068182    60.0        59.534091\n",
       "Sawyer        74.551020    72.0        73.275510\n",
       "SawyerW       70.669811    67.0        68.834906\n",
       "Somerst       64.549383    72.5        68.524691\n",
       "StoneBr       62.173913    60.0        61.086957\n",
       "Timber        81.157895    82.0        81.578947\n",
       "Veenker       72.000000    80.0        76.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_lot_frontage = all_data.groupby('Neighborhood')['LotFrontage'].agg([\"mean\", \"median\"])\n",
    "neigh_lot_frontage['avg_mean_median'] = (neigh_lot_frontage['mean'] + neigh_lot_frontage['median'] )/ 2\n",
    "neigh_lot_frontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of some numerical variables that are actually categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string(df, columns):\n",
    "    df[columns] = df[columns].astype(str)\n",
    "    return df\n",
    "\n",
    "num_to_categ_features = ['MSSubClass', 'OverallCond']#, 'YrSold', 'MoSold']\n",
    "\n",
    "all_data = convert_to_string(all_data, columns = num_to_categ_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing values in the rest of numerical columns\n",
    "\n",
    "For the other numerical data I will also estimate them according to their statistics and for that I will use SimpleImputer object from sklearn library. For columns: BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, BsmtFullBath and BsmtHalfBath , MasVnrArea I will fill Nan values with constant = 0 and for the rest with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = all_data.select_dtypes(include=['int64','float64']).columns\n",
    "num_features_to_constant = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', \"MasVnrArea\"] \n",
    "num_features_to_median = [feature for feature in num_features if feature not in num_features_to_constant + [\"SalePrice\"]]\n",
    "\n",
    "# Generating numerical features as input to DataFrameMapper.  \n",
    "numeric_features_median = sklearn_pandas.gen_features(columns=[num_features_to_median], \n",
    "                                               classes=[{'class': SimpleImputer, \n",
    "                                                         'strategy': 'median', \n",
    "                                                         'missing_values' : np.nan}])\n",
    "\n",
    "numeric_features_zero = sklearn_pandas.gen_features(columns=[num_features_to_constant], \n",
    "                                               classes=[{'class': SimpleImputer, \n",
    "                                                         'strategy': 'constant',\n",
    "                                                         'fill_value' : 0, \n",
    "                                                         'missing_values' : np.nan}])\n",
    "\n",
    "missing_val_imputer = sklearn_pandas.DataFrameMapper(numeric_features_median + numeric_features_zero)\n",
    "\n",
    "# Fitting\n",
    "imputed_median = missing_val_imputer.fit(all_data)\n",
    "\n",
    "# Transformation\n",
    "imputed_features = imputed_median.transform(all_data)\n",
    "\n",
    "# Putting into dataframe\n",
    "imputed_df = pd.DataFrame(imputed_features, index=all_data.index, columns=num_features_to_median + num_features_to_constant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical to numeral\n",
    "\n",
    "There is a lot of categorical features in data, so the next step is to transform them into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting category features\n",
    "cat_feats = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "none_conversion = [(\"MasVnrType\",\"None\"),\n",
    "                  (\"BsmtQual\",\"NA\"), \n",
    "                  (\"Electrical\", \"SBrkr\"),\n",
    "                  (\"BsmtCond\",\"TA\"),\n",
    "                  (\"BsmtExposure\",\"No\"),\n",
    "                  (\"BsmtFinType1\",\"No\"),\n",
    "                  (\"BsmtFinType2\",\"No\"),\n",
    "                  (\"CentralAir\",\"N\"),\n",
    "                  (\"Condition1\",\"Norm\"), \n",
    "                  (\"Condition2\",\"Norm\"),\n",
    "                  (\"ExterCond\",\"TA\"),\n",
    "                  (\"ExterQual\",\"TA\"), \n",
    "                  (\"FireplaceQu\",\"NA\"),\n",
    "                  (\"Functional\",\"Typ\"),\n",
    "                  (\"GarageType\",\"No\"), \n",
    "                  (\"GarageFinish\",\"No\"), \n",
    "                  (\"GarageQual\",\"NA\"), \n",
    "                  (\"GarageCond\",\"NA\"), \n",
    "                  (\"HeatingQC\",\"TA\"), \n",
    "                  (\"KitchenQual\",\"TA\"), \n",
    "                  (\"Functional\",\"Typ\"), \n",
    "                  (\"GarageType\",\"No\"), \n",
    "                  (\"GarageFinish\",\"No\"), \n",
    "                  (\"GarageQual\",\"No\"), \n",
    "                  (\"GarageCond\",\"No\"), \n",
    "                  (\"HeatingQC\",\"TA\"), \n",
    "                  (\"KitchenQual\",\"TA\"),\n",
    "                  (\"MSZoning\", \"None\"),\n",
    "                  (\"Exterior1st\", \"VinylSd\"), \n",
    "                  (\"Exterior2nd\", \"VinylSd\"), \n",
    "                  (\"SaleType\", \"WD\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented the none_transform function which converts missing categorical values into specific strings from the none_conversion dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_transform(df, conversion_list):\n",
    "    ''' Function that converts missing categorical values \n",
    "    into specific strings according to \"conversion_list\" \n",
    "    \n",
    "    Returns the dataframe after transformation.\n",
    "    '''\n",
    "    for col, new_str in conversion_list:\n",
    "        df.loc[:, col] = df.loc[:, col].fillna(new_str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Applying the \"none_transform\" function \n",
    "all_data = none_transform(all_data, none_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of skewed features\n",
    "\n",
    "As for linear models preferable are normally distributed data, I am transforming the skewed features to make them more normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highly skewed features: \n",
      "\n",
      "['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'HalfBath', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n"
     ]
    }
   ],
   "source": [
    "# collecting the numeric features without considering SalePrice\n",
    "numeric_features = [feat for feat in num_features if feat not in ['SalePrice']] \n",
    "\n",
    "# selecting columns with skew more than 0.5\n",
    "skewed_features = all_data[num_features].apply(lambda x: x.dropna().skew())\n",
    "skewed_features = skewed_features[skewed_features > 0.5].index\n",
    "print(\"\\nHighly skewed features: \\n\\n{}\".format(skewed_features.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Box Cox transformation is a way to transform non-normal dependent variables into a normal shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The â€œoptimal lambdaâ€ is the one that results in the best approximation of a normal distribution curve. I selected lambda= 0.15.\n",
    "\n",
    "lambda_ = 0.15\n",
    "for feature in skewed_features:\n",
    "    all_data[feature] = boxcox1p(all_data[feature], lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical into Numerical\n",
    "\n",
    "As some categorical features (i.e. KitchenQual, GarageQual) can be transformed into the numerical values with some order, I also implemented a new encoder for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderedLabelTransformer(BaseEstimator, TransformerMixin):\n",
    "    orderDict = {\"NA\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_dict(X):\n",
    "        FirstDict = {\"Po\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4}\n",
    "        SecondDict = {\"NA\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}\n",
    "        ThirdDict = {\"NA\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4}\n",
    "        for d in [FirstDict, SecondDict, ThirdDict]:\n",
    "            if set(X) == set(d): \n",
    "                return d\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        def get_label(t):\n",
    "            return self.orderDict[t]\n",
    "        return np.array([get_label(n) for n in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborhoodTransformer(BaseEstimator, TransformerMixin):\n",
    "    neighborhoodsmap = {'StoneBr' : 2, 'NridgHt' : 2, 'NoRidge': 2, \n",
    "                        'MeadowV' : 0, 'IDOTRR' : 0, 'BrDale' : 0 ,\n",
    "                        'CollgCr': 1, 'Veenker' : 1, 'Crawfor' : 1,\n",
    "                        'Mitchel' : 1, 'Somerst' : 1, 'NWAmes' : 1,\n",
    "                        'OldTown' : 1, 'BrkSide' : 1, 'Sawyer' : 1, \n",
    "                        'NAmes' : 1, 'SawyerW' : 1, 'Edwards' : 1,\n",
    "                        'Timber' : 1, 'Gilbert' : 1, 'ClearCr' : 1,\n",
    "                        'NPkVill' : 1, 'Blmngtn' : 1, 'SWISU' : 1,\n",
    "                        'Blueste': 1}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        def get_label(t):\n",
    "            return self.neighborhoodsmap[t]\n",
    "        return np.array([get_label(n) for [n] in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I implemented previously specific transformers for categorical data, I will run the whole pipeline for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating features:\n",
    "order_feats = [\"ExterQual\", \"ExterCond\", \"HeatingQC\", \"KitchenQual\", \"BsmtQual\", \n",
    "               \"BsmtCond\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\"]\n",
    "\n",
    "original_features_df = all_data[order_feats + ['Neighborhood']] # we need to save original values for one-hot encoding\n",
    "\n",
    "order_features = sklearn_pandas.gen_features(order_feats, [OrderedLabelTransformer])\n",
    "neighb_features = [(['Neighborhood'], [NeighborhoodTransformer()])]\n",
    "\n",
    "# Pipeline\n",
    "label_encoder = sklearn_pandas.DataFrameMapper(neighb_features + order_features)\n",
    "\n",
    "# The list with order of column names\n",
    "cols = [\"Neighborhood\"] + order_feats\n",
    "\n",
    "# Transformation both train and test set\n",
    "transformed_feats = label_encoder.fit_transform(all_data)\n",
    "\n",
    "# Putting transformed features into dataframe\n",
    "transformed_df = pd.DataFrame(transformed_feats, index=all_data.index, columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_features_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature without any transformation till now\n",
    "rest_features = set(pd.concat([imputed_df, original_features_df],axis=1).columns).symmetric_difference(set(all_data.columns))\n",
    "rest_features_df = all_data[list(rest_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 78)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([imputed_df, original_features_df, rest_features_df],axis=1)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Creating new features\n",
    "\n",
    "These features seem to be useful for house price prediction. As they are not contained in kaggle dataset I decided to create them from other informations.\n",
    "\n",
    "\"TotalSqrtFeet\" - Total Live Area\n",
    "\"TotalBaths\" - Total Area for Bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Squere Feet for house\n",
    "all_data[\"TotalSqrtFeet\"] = all_data[\"GrLivArea\"] + all_data[\"TotalBsmtSF\"]\n",
    "# test_df[\"TotalSqrtFeet\"] = test_df[\"GrLivArea\"] + test_df[\"TotalBsmtSF\"]\n",
    "\n",
    "# Total number of bathrooms\n",
    "all_data[\"TotalBaths\"] = all_data[\"BsmtFullBath\"] + (all_data[\"BsmtHalfBath\"]  * .5) + all_data[\"FullBath\"] + (all_data[\"HalfBath\"]* .5)\n",
    "# test_df[\"TotalBaths\"] = test_df[\"BsmtFullBath\"] + (test_df[\"BsmtHalfBath\"]  * .5) + test_df[\"FullBath\"] + (test_df[\"HalfBath\"]* .5)\n",
    "\n",
    "# If the house has a garage\n",
    "all_data['Isgarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# If the house has a fireplace\n",
    "all_data['Isfireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# If the house has a pool\n",
    "all_data['Ispool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# If the house has second floor\n",
    "all_data['Issecondfloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# If the house has Open Porch\n",
    "all_data['IsOpenPorch'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# If the house has Wood Deck\n",
    "all_data['IsWoodDeck'] = all_data['WoodDeckSF'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop([\"SalePrice\"], axis = 1)\n",
    "\n",
    "hot_one_features = pd.get_dummies(all_data).reset_index(drop=True)\n",
    "hot_one_features.shape\n",
    "\n",
    "\n",
    "all_data = pd.concat([transformed_df, hot_one_features],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "train_preprocessed = all_data.iloc[:len(data_df),:]\n",
    "test_preprocessed = all_data.iloc[len(train_preprocessed):,:]\n",
    "print(len(test_preprocessed) == len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso, ElasticNetCV\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import RegressorMixin\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment specification:\n",
      "\n",
      "sklearn 1.5.0\n",
      "xgboost 2.0.3\n",
      "lightgbm 4.4.0\n"
     ]
    }
   ],
   "source": [
    "print('Environment specification:\\n')\n",
    "for mod in sklearn, xgb, lgb:\n",
    "    print(mod.__name__, mod.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(model):\n",
    "    n_folds=5\n",
    "    kfold = KFold(n_folds, random_state=42, shuffle=True).get_n_splits(X_train)\n",
    "    rmse_score = np.sqrt(-cross_val_score(model, X_train, y_train, scoring = \"neg_mean_squared_error\", cv = kfold, verbose = 0, n_jobs=-1))\n",
    "    return(np.mean(rmse_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.00858436\n",
      "RMSE score for Linear Regression: 1135.735\n"
     ]
    }
   ],
   "source": [
    "lr_model = make_pipeline(RobustScaler(), LinearRegression()) #TODO: why Robust Scaler?\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "MSE_train = np.mean((y_train_pred - y_train)**2)\n",
    "\n",
    "print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "print(\"RMSE score for Linear Regression: {:.3f}\".format(rmse(lr_model)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_train, y=y_train_pred)\n",
    "plt.xlabel(\"Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(\"Prices vs. Predicted Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_train_pred, y=(y_train_pred - y_train))\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.01197438\n",
      "RMSE score for LASSO: 0.135\n"
     ]
    }
   ],
   "source": [
    "lasso_model = make_pipeline(RobustScaler(), \n",
    "                         LassoCV(alphas = [0.0004, 0.0005, 0.0006],\n",
    "                                 random_state = 0,\n",
    "                                 cv = 10))\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lasso_model.predict(X_train)\n",
    "MSE_train = np.mean((y_train_pred - y_train)**2)\n",
    "\n",
    "# print(\"Best alpha : {}\", lasso_model.alpha_)\n",
    "print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "print(\"RMSE score for LASSO: {:.3f}\".format(rmse(lasso_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plotting predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_train_pred, y=y_train)\n",
    "plt.title(\"Linear Regression with Lasso Regularization\")\n",
    "plt.xlabel(\"Predicted Prices\")\n",
    "plt.ylabel(\"Real Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "param_grid = {'n_estimators': [2500],\n",
    "              'max_features': [13],\n",
    "              'max_depth': [5],\n",
    "              'learning_rate': [0.05],\n",
    "              'subsample': [0.8],\n",
    "             'random_state' : [5]}\n",
    "                              \n",
    "gb_model = GridSearchCV(estimator=gbr, param_grid=param_grid, n_jobs=1, cv=5)\n",
    "gb_model.fit(X_train, y_train)\n",
    "best_params_gbr = gb_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'max_features': 13, 'n_estimators': 2500, 'random_state': 5, 'subsample': 0.8}\n",
      "Mean Squared Error = 0.00000925\n",
      "RMSE score for GB: 0.124\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = gb_model.predict(X_train)\n",
    "MSE_train = np.mean((y_train_pred - y_train)**2)\n",
    "print('Best Parameters: {}'.format(gb_model.best_params_))\n",
    "print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "print(\"RMSE score for GB: {:.3f}\".format(rmse(gb_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5050519794266569, learning_rate=0.0534226888747111, max_depth=10, n_estimators=1632, subsample=0.768059179307574; total time=   2.8s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.7186941777766422, learning_rate=0.07643904937766527, max_depth=5, n_estimators=2902, subsample=0.8456511661859802; total time=   2.9s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5224162561505759, learning_rate=0.08293207307063741, max_depth=4, n_estimators=1867, subsample=0.5751820745469395; total time=   1.9s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.7061979941786817, learning_rate=0.014854962554466472, max_depth=7, n_estimators=2606, subsample=0.7092209312217534; total time=   7.1s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6997767208035865, learning_rate=0.027417584235929056, max_depth=7, n_estimators=2431, subsample=0.8615408290026747; total time=   5.0s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6670140089927842, learning_rate=0.08697005357407943, max_depth=4, n_estimators=1377, subsample=0.820201292582698; total time=   1.6s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6085396792511581, learning_rate=0.059616212167911256, max_depth=6, n_estimators=2749, subsample=0.7370478701222272; total time=   3.2s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5717015338451563, learning_rate=0.08317814418264183, max_depth=6, n_estimators=2675, subsample=0.6296239929137495; total time=   2.9s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.7777389931549641, learning_rate=0.05019049103849115, max_depth=9, n_estimators=1832, subsample=0.6524259059189972; total time=   3.7s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.3018151536273716, learning_rate=0.06574004842664952, max_depth=8, n_estimators=1509, subsample=0.731465734491354; total time=   2.0s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7723598640859095, learning_rate=0.014422446380863988, max_depth=3, n_estimators=1035, subsample=0.5795527477383757; total time=   1.0s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.3094144255518195, learning_rate=0.013320502957030281, max_depth=3, n_estimators=2860, subsample=0.8703667782838318; total time=   2.2s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.3010991077842704, learning_rate=0.012478351640686381, max_depth=10, n_estimators=1099, subsample=0.5037643841695187; total time=   3.4s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9; total time=   1.0s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.9s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6205726152239128, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.6343241431072749; total time=   2.6s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  21.2s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  21.2s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  21.5s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  21.6s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  21.6s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  21.7s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  21.8s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.706394842895185, learning_rate=0.011675058041999937, max_depth=10, n_estimators=2919, subsample=0.502372436965169; total time=  12.0s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6819877099268207, learning_rate=0.07716897819148945, max_depth=3, n_estimators=2986, subsample=0.5095957090380239; total time=   2.6s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.7365063077940044; total time=   0.8s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6865034470798559, learning_rate=0.01, max_depth=3, n_estimators=2408, subsample=0.7550320135175289; total time=   2.2s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=3000, subsample=0.7539925232127335; total time=   2.1s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.33232276441577746, learning_rate=0.010532852169482632, max_depth=5, n_estimators=2996, subsample=0.5073298205675041; total time=   3.3s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2960, subsample=0.5; total time=   2.2s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.3476252208184454, learning_rate=0.09255147616893979, max_depth=3, n_estimators=1158, subsample=0.8875421639015747; total time=   0.9s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7724233585195752, learning_rate=0.013281472599764558, max_depth=6, n_estimators=1044, subsample=0.5162556655324886; total time=   2.0s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.43030496121969697, learning_rate=0.09686734280138501, max_depth=10, n_estimators=2915, subsample=0.5087574450300837; total time=   3.7s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=13.1min\n",
      "[CV] END colsample_bytree=0.7920884745726685, learning_rate=0.011488931206742957, max_depth=10, n_estimators=1141, subsample=0.8441053230410419; total time=13.1min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.013095248151446297, max_depth=3, n_estimators=3000, subsample=0.6663844475001162; total time=   3.5s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=2674, subsample=0.6589039388771762; total time=   1.9s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time= 8.5min\n",
      "[CV] END colsample_bytree=0.30721595095325344, learning_rate=0.03433195018057218, max_depth=3, n_estimators=1266, subsample=0.5067281010870958; total time= 8.5min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.021211435565304408, max_depth=3, n_estimators=3000, subsample=0.5; total time=   3.7s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.3328808734787009, learning_rate=0.03967444818375851, max_depth=3, n_estimators=1261, subsample=0.8868108388184212; total time=   1.0s\n",
      "\n",
      "\n",
      "Beste Parameter fÃ¼r XGBRegressor:  OrderedDict({'colsample_bytree': 0.3, 'learning_rate': 0.013095248151446297, 'max_depth': 3, 'n_estimators': 3000, 'subsample': 0.6663844475001162})\n",
      "Mean Squared Error = 0.00255657\n",
      "RMSE score for XGB: 0.0506\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Definieren Sie das Modell\n",
    "xgbreg = xgb.XGBRegressor(seed=0)\n",
    "\n",
    "# Erstellen Sie den Parameterraum\n",
    "param_space2 = {\n",
    "    'n_estimators': Integer(1000, 3000),\n",
    "    'learning_rate': Real(0.01, 0.1, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 10),\n",
    "    'subsample': Real(0.5, 0.9),\n",
    "    'colsample_bytree': Real(0.3, 0.8)\n",
    "}\n",
    "\n",
    "# Verwenden Sie BayesSearchCV, um die besten Parameter zu finden\n",
    "bayes_search2 = BayesSearchCV(estimator=xgbreg, search_spaces=param_space2, cv=10, n_jobs=-1, verbose=2, n_iter=32, random_state=42)\n",
    "bayes_search2.fit(X_train, y_train)\n",
    "\n",
    "# Holen Sie sich die besten Parameter\n",
    "best_params_xgb = bayes_search2.best_params_\n",
    "print(\"\\n\\nBeste Parameter fÃ¼r XGBRegressor: \", best_params_xgb)\n",
    "\n",
    "# Erstellen Sie ein neues Modell mit den besten Parametern\n",
    "optimal_xgb_model = xgb.XGBRegressor(**best_params_xgb, seed=0)\n",
    "\n",
    "# Trainieren Sie das Modell mit den besten Parametern\n",
    "optimal_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen und Evaluierung\n",
    "y_train_pred = optimal_xgb_model.predict(X_train)\n",
    "MSE_train = mean_squared_error(y_train, y_train_pred)\n",
    "RMSE_train = np.sqrt(MSE_train)\n",
    "\n",
    "print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "print(\"RMSE score for XGB: {:.4f}\".format(RMSE_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbreg = xgb.XGBRegressor(seed=0)\n",
    "#param_grid2 = {'n_estimators': [2000], \n",
    "#              'learning_rate': [0.05],\n",
    "#              'max_depth': [3, 7],\n",
    "#              'subsample': [0.8],\n",
    "#              'colsample_bytree': [0.45, 0.75]}\n",
    "    \n",
    "#xgb_model = GridSearchCV(estimator=xgbreg, param_grid=param_grid2, n_jobs=1, cv=10)\n",
    "#xgb_model.fit(X_train, y_train)\n",
    "\n",
    "#y_train_pred = xgb_model.predict(X_train)\n",
    "#MSE_train = np.mean((y_train_pred - y_train)**2)\n",
    "\n",
    "#print('\\n\\nBest Parameters: {}'.format(xgb_model.best_params_))\n",
    "#print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "#print(\"RMSE score for XGB: {:.3f}\".format(rmse(xgb_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.01171991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4822185843459952, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3192723969507476, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0290749440849707, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2844208747912402, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7969451645771803, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5068336537728344, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1564022308377773, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.393445108587307, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1518006116854353, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9337273638128893, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.489972270042874, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.332932977549862, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.237124919204362, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1952215343900043, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3317384290588548, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.749348017848563, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.2013555434761285, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.176499403676174, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0459447455269437, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5411894024724644, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.012199021634327, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2959052893802747, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9388671140512379, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3451214328459375, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.430687338209221, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1346818316334435, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2139352337579874, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7098176004297443, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.466531599062395, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1995718184090078, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.895689337976064, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.052864649179706, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2982265658284549, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5253104085845974, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9460163390734362, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.020593733969318, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7858253329255191, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1807636941165542, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4051873082581903, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2715959031062232, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5115121695818488, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2117747821527765, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9347062024343256, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.23975087020582, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1052271359292725, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0818905802827743, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4153534789333282, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7295016599046953, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8302539517678929, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.961407834866935, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4225907750371531, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.235806726834345, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2634544437318729, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1072916381294196, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9944201969017845, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7393886973366177, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.151516996679516, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1487236063761062, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3619539499850992, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7552297682998894, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.413140343420876, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9478631455188742, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6874159248355074, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8162762914244741, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.183243534859737, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2146960544205196, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3803339688170002, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.650169809060456, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.9729260422320043, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0909902349717733, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.340150933190829, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3021072218761471, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6625212412276973, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.179630820512994, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8671668738674585, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1746666002052057, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1018596835555199, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.752453851654467, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0723920161804106, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2215712442037514, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.271253330652586, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8256041066955753, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6849315657544679, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.106921208304378, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4101646933439027, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0561494003023748, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5450886362313865, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9948821987057048, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5041747931029459, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1847867806655037, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.358379785549225, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9491816174666816, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2190787294016001, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.38880951131786556, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9870935253451685, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0412497734891009, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5140113201643564, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8173586997832096, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2700700180700482, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9428266628794386, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8458749982109035, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4219168605794605, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3856024274052885, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6530816622952882, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.108391986355465, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7272849216118669, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2879314957029235, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2188792368625494, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.277523705023755, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6663958729007025, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4287195255737473, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1505290707168054, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1874325217797832, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2624277686249208, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4435847181016275, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.755806693556015, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.915742052257439, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.143934239342511, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8148145042946657, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2947172303649221, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.505602425320041, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2845064435682971, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4492055477191768, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.044936060464323, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3177027098009297, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1315480013417218, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1527864255451057, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2846355401576792, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4005087596549846, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1814341544091498, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4881269780107935, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.065969979771876, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1692714322194542, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.307746069093076, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.207301692421123, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7847135738328657, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8137334243113319, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8235689525247274, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.326935183027091, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1872067556533583, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2187240732509812, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5614311825433767, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.163092357500843, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.509206121092264, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8452408013974386, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3382277953998454, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0689042215008682, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3310478661255347, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0524371162890542, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1971746091808981, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4910416598554264, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0943769304627562, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2106160746620933, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.31281974244946, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3127075759360451, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7463372134250066, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.805719355780929, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8842528139414032, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7193976596165612, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1106393124784129, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.188815511504112, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3361557541733875, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9327190697069581, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6551779827323809, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.011208338632719, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.815088188325384, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1985122512720174, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8419454353428053, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.482837168449945, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9115480460842589, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2003091255261875, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9132413270888557, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8370207626548094, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2082960490755008, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5392019543465074, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0799485464851708, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3859473402461298, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4183303815667987, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6880517031912152, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6350363526619764, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.336952864637639, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.214964058819544, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2334063357869391, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3361209859620615, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3752791617229203, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0944411398857312, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.102736565537218, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2040235853891437, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.989501347982692, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2145495874170456, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9699126771945519, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3345821884595326, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5042617432992182, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6620177541595718, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1803952945164085, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0947778337189469, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.497002312212075, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8511665084768198, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3312903959483835, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2581846972814112, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7550040132201978, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2972431380402512, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0358554482299311, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1655073501787667, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5187870793784333, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1647383778678648, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8740310677139855, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7537386634162493, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8021579436866872, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3454504588583536, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9399736584144875, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9501368194902833, tolerance: 0.016191364933028217\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4044996079095933, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7546125163523163, tolerance: 0.016564388322491727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2045288866264459, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2472834016331742, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.307467415475016, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1368868851892442, tolerance: 0.017000683356241546\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5554134226056506, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9878848610385402, tolerance: 0.01680497798591194\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0523449638403521, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.144845741947484, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1830095728401808, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3581148108561285, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9450874736924639, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9025429789296355, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2252348039874619, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2110400009255038, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4118882998672864, tolerance: 0.01718962163269318\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7146895425325468, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0622932735031139, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4784354766343437, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6530225627404427, tolerance: 0.016597742336434518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8020895876904883, tolerance: 0.016229152853316102\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9537895955957056, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5253324570859768, tolerance: 0.01703605459385153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3082791331474386, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.52591036187557, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.283163389581003, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.735018400422895, tolerance: 0.016715052101341856\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4131743236200975, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1898254953602807, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0866194169145418, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.114558500776904, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9403140978852331, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4278411279115995, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.841752202505698, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9652007959761972, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.2262937965420075, tolerance: 0.01724421230265382\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7342318860240553, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2470007311065245, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4335113393817478, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.803390914351592, tolerance: 0.016381718887511023\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8688978330157666, tolerance: 0.016058189376944136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7394547276031673, tolerance: 0.016820932041277954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1172620799820443, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2734855629333959, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.375647573179486, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4455104326750376, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9548739765663745, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1924808078530482, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7598089936777539, tolerance: 0.016780562073736568\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2283967241023817, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1573262689104888, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6946047878467692, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3957128977196245, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0997133878917822, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3925284717042512, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8210847600579951, tolerance: 0.017037673189157467\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6554011231057286, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.68272034438881, tolerance: 0.01582372982794669\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9433542376301673, tolerance: 0.016435531368428256\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3133564593779266, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6662620857891675, tolerance: 0.016870678891167074\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.351359224882863, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2342108549119404, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.280939636700852, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1844273488495887, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7567193578181444, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1229824013799616, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0653097158996152, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1899253007878743, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6890431727955422, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0078061382314436, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9573615198734418, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0819971663377688, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8301196796504735, tolerance: 0.01673301546775035\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5073529195140667, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5168574189661852, tolerance: 0.016220875346186974\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.9115752059026545, tolerance: 0.01704868406654206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5596491880172048, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.816331082700761, tolerance: 0.016426793687948037\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.39043639933677987, tolerance: 0.016658575818731907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4362116287472233, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3708925869697879, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.194910656869193, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2814550077842641, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3004403447522463, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8511364046803669, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.049821480909249, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.117801771398863, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2300242915284718, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1613505797730834, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7325511710406571, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3880227447230782, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9475734336573307, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8233310705478436, tolerance: 0.017336640653448296\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6710611532394806, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7617344274824172, tolerance: 0.016568506490018283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3971943114381897, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7412500256846366, tolerance: 0.016196086975215247\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6574221352945857, tolerance: 0.016858493421971567\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0532826388668841, tolerance: 0.01643950486183928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.295661132235229, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5202281705942688, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2293317853661234, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4401682664489925, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.303202744975473, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1403280572238792, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1966400380731246, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3300569495804444, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2725963482758509, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1599516010304844, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2728386022862077, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1921165446362538, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.152981318049136, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8445347219458439, tolerance: 0.01710724494738662\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0725924501049757, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.0448146926092665, tolerance: 0.01620657436365077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7076074294622456, tolerance: 0.01658072847815932\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7317668993378468, tolerance: 0.016641319325912375\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4603113341787797, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.816990159750044, tolerance: 0.016792489478096563\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3380168358017155, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5006324789068257, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.575406667478651, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2951948721185778, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1727912829953517, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.226695133978092, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3183848358151353, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1783042051289705, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3510900062013187, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0913701749297458, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1028161459993084, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1960414891377669, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.207720781745845, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.828564314908319, tolerance: 0.017119009782919335\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0952495499934622, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.172430845350558, tolerance: 0.016331974492871174\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5213341663921982, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8500957818346295, tolerance: 0.016996587084590755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6946916643577836, tolerance: 0.016704693125725607\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3422564174144798, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7293502165466315, tolerance: 0.0172491414611712\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.723346421257876, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5039837455311948, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0719324176561553, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2199687150085472, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.659601886073041, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3240155813034633, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9402399792970701, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3446526629917894, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6416535486547144, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8484910160134449, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1985207070885746, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8859392206983747, tolerance: 0.017243352750728774\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.205601072994492, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0176382320622723, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1260402404676393, tolerance: 0.016640354869358456\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.818714951281243, tolerance: 0.017478236378267908\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.320788643499158, tolerance: 0.016269721262497063\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9186196860045905, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9173647889067347, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.207284729949147, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3976571802915903, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4324031119689566, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6915986804073171, tolerance: 0.016960523423264092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8421021430560911, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0864224279720167, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2453437864419064, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2253228999294388, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3439455907479472, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.113423868350286, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6354483524494077, tolerance: 0.017179563845710687\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1035251311159975, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.954358706803867, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2109658836558683, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6619210122579693, tolerance: 0.016649360221822274\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3863197068988313, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.324843345286589, tolerance: 0.01727704886909694\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9758514192842203, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.1679917415021674, tolerance: 0.01627855675087019\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.225048848488325, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3442185675723053, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.104252510632156, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8287622289567667, tolerance: 0.017445759364822927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1901617167565641, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7597524654193899, tolerance: 0.01718852443060544\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4060414330651536, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7594738703772759, tolerance: 0.017285240639815232\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+00, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score for ElasticNet: 0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+00, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+00, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+00, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.540e+00, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "en_model = ElasticNetCV(alphas = [0.0001, 0.0003, 0.0004, 0.0006], \n",
    "                        l1_ratio = [.9, .92], \n",
    "                        random_state = 0,\n",
    "                        cv=10)\n",
    "\n",
    "en_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = en_model.predict(X_train)\n",
    "MSE_train = np.mean((y_train_pred - y_train)**2)\n",
    "\n",
    "print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "print(\"RMSE score for ElasticNet: {:.3f}\".format(rmse(en_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3243\n",
      "[LightGBM] [Info] Total Bins 3252\n",
      "[LightGBM] [Info] Total Bins 3250\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 259\n",
      "[LightGBM] [Info] Start training from score 12.023288[LightGBM] [Info] Start training from score 12.021409\n",
      "\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3283\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3254\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[CV] END bagging_fraction=0.8410103958853314, bagging_freq=9, feature_fraction=0.2932867998847834, learning_rate=0.01, max_bin=200, min_data_in_leaf=8, min_sum_hessian_in_leaf=14, n_estimators=800, num_leaves=5; total time=   2.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[CV] END bagging_fraction=0.8410103958853314, bagging_freq=9, feature_fraction=0.2932867998847834, learning_rate=0.01, max_bin=200, min_data_in_leaf=8, min_sum_hessian_in_leaf=14, n_estimators=800, num_leaves=5; total time=   2.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[CV] END bagging_fraction=0.8410103958853314, bagging_freq=9, feature_fraction=0.2932867998847834, learning_rate=0.01, max_bin=200, min_data_in_leaf=8, min_sum_hessian_in_leaf=14, n_estimators=800, num_leaves=5; total time=   2.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[CV] END bagging_fraction=0.8410103958853314, bagging_freq=9, feature_fraction=0.2932867998847834, learning_rate=0.01, max_bin=200, min_data_in_leaf=8, min_sum_hessian_in_leaf=14, n_estimators=800, num_leaves=5; total time=   2.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410103958853314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8410103958853314\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2932867998847834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2932867998847834\n",
      "[CV] END bagging_fraction=0.8410103958853314, bagging_freq=9, feature_fraction=0.2932867998847834, learning_rate=0.01, max_bin=200, min_data_in_leaf=8, min_sum_hessian_in_leaf=14, n_estimators=800, num_leaves=5; total time=   2.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3276\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3305\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3268\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3278\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[CV] END bagging_fraction=0.8837388355553285, bagging_freq=9, feature_fraction=0.2303410109884175, learning_rate=0.1, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=10; total time=   2.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[CV] END bagging_fraction=0.8837388355553285, bagging_freq=9, feature_fraction=0.2303410109884175, learning_rate=0.1, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=10; total time=   3.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[CV] END bagging_fraction=0.8837388355553285, bagging_freq=9, feature_fraction=0.2303410109884175, learning_rate=0.1, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=10; total time=   3.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[CV] END bagging_fraction=0.8837388355553285, bagging_freq=9, feature_fraction=0.2303410109884175, learning_rate=0.1, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=10; total time=   3.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8837388355553285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837388355553285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2303410109884175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2303410109884175\n",
      "[CV] END bagging_fraction=0.8837388355553285, bagging_freq=9, feature_fraction=0.2303410109884175, learning_rate=0.1, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=10; total time=   3.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1584\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1588\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 259\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 262\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1593\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[CV] END bagging_fraction=0.8444832512301153, bagging_freq=10, feature_fraction=0.21048591585527038, learning_rate=0.05, max_bin=55, min_data_in_leaf=8, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   3.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[CV] END bagging_fraction=0.8444832512301153, bagging_freq=10, feature_fraction=0.21048591585527038, learning_rate=0.05, max_bin=55, min_data_in_leaf=8, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[CV] END bagging_fraction=0.8444832512301153, bagging_freq=10, feature_fraction=0.21048591585527038, learning_rate=0.05, max_bin=55, min_data_in_leaf=8, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[CV] END bagging_fraction=0.8444832512301153, bagging_freq=10, feature_fraction=0.21048591585527038, learning_rate=0.05, max_bin=55, min_data_in_leaf=8, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8444832512301153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8444832512301153\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21048591585527038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21048591585527038\n",
      "[CV] END bagging_fraction=0.8444832512301153, bagging_freq=10, feature_fraction=0.21048591585527038, learning_rate=0.05, max_bin=55, min_data_in_leaf=8, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2269\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2270\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Total Bins 2255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2275\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[CV] END bagging_fraction=0.8812395988357363, bagging_freq=6, feature_fraction=0.2598047077512128, learning_rate=0.1, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=18, n_estimators=800, num_leaves=20; total time=   7.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[CV] END bagging_fraction=0.8812395988357363, bagging_freq=6, feature_fraction=0.2598047077512128, learning_rate=0.1, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=18, n_estimators=800, num_leaves=20; total time=   7.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[CV] END bagging_fraction=0.8812395988357363, bagging_freq=6, feature_fraction=0.2598047077512128, learning_rate=0.1, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=18, n_estimators=800, num_leaves=20; total time=   7.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[CV] END bagging_fraction=0.8812395988357363, bagging_freq=6, feature_fraction=0.2598047077512128, learning_rate=0.1, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=18, n_estimators=800, num_leaves=20; total time=   7.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8812395988357363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8812395988357363\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=18, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2598047077512128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2598047077512128\n",
      "[CV] END bagging_fraction=0.8812395988357363, bagging_freq=6, feature_fraction=0.2598047077512128, learning_rate=0.1, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=18, n_estimators=800, num_leaves=20; total time=   7.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 253\n",
      "[LightGBM] [Info] Total Bins 3242\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 255\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3273\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 256[LightGBM] [Info] Total Bins 3233\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 255\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3246\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[CV] END bagging_fraction=0.8799553441607173, bagging_freq=7, feature_fraction=0.25266202371276925, learning_rate=0.1, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=10; total time=   2.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[CV] END bagging_fraction=0.8799553441607173, bagging_freq=7, feature_fraction=0.25266202371276925, learning_rate=0.1, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=10; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[CV] END bagging_fraction=0.8799553441607173, bagging_freq=7, feature_fraction=0.25266202371276925, learning_rate=0.1, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=10; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[CV] END bagging_fraction=0.8799553441607173, bagging_freq=7, feature_fraction=0.25266202371276925, learning_rate=0.1, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=10; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8799553441607173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8799553441607173\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25266202371276925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25266202371276925\n",
      "[CV] END bagging_fraction=0.8799553441607173, bagging_freq=7, feature_fraction=0.25266202371276925, learning_rate=0.1, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=10; total time=   2.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 265\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Total Bins 3266\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3262\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 267\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3299\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 268\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3266\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[CV] END bagging_fraction=0.8734028017985569, bagging_freq=10, feature_fraction=0.21636071786385502, learning_rate=0.01, max_bin=200, min_data_in_leaf=7, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   4.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[CV] END bagging_fraction=0.8734028017985569, bagging_freq=10, feature_fraction=0.21636071786385502, learning_rate=0.01, max_bin=200, min_data_in_leaf=7, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   4.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[CV] END bagging_fraction=0.8734028017985569, bagging_freq=10, feature_fraction=0.21636071786385502, learning_rate=0.01, max_bin=200, min_data_in_leaf=7, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   5.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[CV] END bagging_fraction=0.8734028017985569, bagging_freq=10, feature_fraction=0.21636071786385502, learning_rate=0.01, max_bin=200, min_data_in_leaf=7, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   5.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734028017985569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734028017985569\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21636071786385502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21636071786385502\n",
      "[CV] END bagging_fraction=0.8734028017985569, bagging_freq=10, feature_fraction=0.21636071786385502, learning_rate=0.01, max_bin=200, min_data_in_leaf=7, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   5.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2244\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 259\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2244\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2258\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2251\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2236\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 262\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[CV] END bagging_fraction=0.8617079358502316, bagging_freq=9, feature_fraction=0.2359022931921404, learning_rate=0.1, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=17, n_estimators=500, num_leaves=20; total time=   6.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[CV] END bagging_fraction=0.8617079358502316, bagging_freq=9, feature_fraction=0.2359022931921404, learning_rate=0.1, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=17, n_estimators=500, num_leaves=20; total time=   5.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[CV] END bagging_fraction=0.8617079358502316, bagging_freq=9, feature_fraction=0.2359022931921404, learning_rate=0.1, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=17, n_estimators=500, num_leaves=20; total time=   6.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[CV] END bagging_fraction=0.8617079358502316, bagging_freq=9, feature_fraction=0.2359022931921404, learning_rate=0.1, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=17, n_estimators=500, num_leaves=20; total time=   6.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8617079358502316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8617079358502316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2359022931921404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2359022931921404\n",
      "[CV] END bagging_fraction=0.8617079358502316, bagging_freq=9, feature_fraction=0.2359022931921404, learning_rate=0.1, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=17, n_estimators=500, num_leaves=20; total time=   6.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1614\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1605\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1615\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1610\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[CV] END bagging_fraction=0.8543403067690313, bagging_freq=10, feature_fraction=0.24964667035967167, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=16, n_estimators=100, num_leaves=10; total time=   0.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[CV] END bagging_fraction=0.8543403067690313, bagging_freq=10, feature_fraction=0.24964667035967167, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=16, n_estimators=100, num_leaves=10; total time=   0.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[CV] END bagging_fraction=0.8543403067690313, bagging_freq=10, feature_fraction=0.24964667035967167, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=16, n_estimators=100, num_leaves=10; total time=   0.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[CV] END bagging_fraction=0.8543403067690313, bagging_freq=10, feature_fraction=0.24964667035967167, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=16, n_estimators=100, num_leaves=10; total time=   0.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8543403067690313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543403067690313\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=16, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24964667035967167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24964667035967167\n",
      "[CV] END bagging_fraction=0.8543403067690313, bagging_freq=10, feature_fraction=0.24964667035967167, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=16, n_estimators=100, num_leaves=10; total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2254\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2246\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 267\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2274\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 268\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[CV] END bagging_fraction=0.8955477986309929, bagging_freq=9, feature_fraction=0.28716519284632147, learning_rate=0.05, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=10; total time=   2.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[CV] END bagging_fraction=0.8955477986309929, bagging_freq=9, feature_fraction=0.28716519284632147, learning_rate=0.05, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=10; total time=   2.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[CV] END bagging_fraction=0.8955477986309929, bagging_freq=9, feature_fraction=0.28716519284632147, learning_rate=0.05, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=10; total time=   2.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8955477986309929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8955477986309929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28716519284632147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28716519284632147\n",
      "[CV] END bagging_fraction=0.8955477986309929, bagging_freq=9, feature_fraction=0.28716519284632147, learning_rate=0.05, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=10; total time=   2.9s\n",
      "[CV] END bagging_fraction=0.8955477986309929, bagging_freq=9, feature_fraction=0.28716519284632147, learning_rate=0.05, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=10; total time=   2.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 2274\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 268\n",
      "\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Total Bins 2254\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2246\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 267\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[CV] END bagging_fraction=0.8003630307254743, bagging_freq=9, feature_fraction=0.2741282744368027, learning_rate=0.01, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=14, n_estimators=100, num_leaves=20; total time=   1.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[CV] END bagging_fraction=0.8003630307254743, bagging_freq=9, feature_fraction=0.2741282744368027, learning_rate=0.01, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=14, n_estimators=100, num_leaves=20; total time=   1.2s\n",
      "[CV] END bagging_fraction=0.8003630307254743, bagging_freq=9, feature_fraction=0.2741282744368027, learning_rate=0.01, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=14, n_estimators=100, num_leaves=20; total time=   1.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[CV] END bagging_fraction=0.8003630307254743, bagging_freq=9, feature_fraction=0.2741282744368027, learning_rate=0.01, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=14, n_estimators=100, num_leaves=20; total time=   1.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003630307254743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003630307254743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=14, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2741282744368027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2741282744368027\n",
      "[CV] END bagging_fraction=0.8003630307254743, bagging_freq=9, feature_fraction=0.2741282744368027, learning_rate=0.01, max_bin=100, min_data_in_leaf=7, min_sum_hessian_in_leaf=14, n_estimators=100, num_leaves=20; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Info] Total Bins 3223\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3238\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3265\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[CV] END bagging_fraction=0.872877754719859, bagging_freq=5, feature_fraction=0.2787834068594753, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=20; total time=   7.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[CV] END bagging_fraction=0.872877754719859, bagging_freq=5, feature_fraction=0.2787834068594753, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=20; total time=   7.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[CV] END bagging_fraction=0.872877754719859, bagging_freq=5, feature_fraction=0.2787834068594753, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=20; total time=   8.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[CV] END bagging_fraction=0.872877754719859, bagging_freq=5, feature_fraction=0.2787834068594753, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=20; total time=   8.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872877754719859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872877754719859\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2787834068594753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2787834068594753\n",
      "[CV] END bagging_fraction=0.872877754719859, bagging_freq=5, feature_fraction=0.2787834068594753, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=20; total time=   8.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1574\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 255\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1580\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 255\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1568\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 253\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1578\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[CV] END bagging_fraction=0.8199927564641241, bagging_freq=7, feature_fraction=0.273955074700042, learning_rate=0.01, max_bin=55, min_data_in_leaf=9, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=5; total time=   1.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[CV] END bagging_fraction=0.8199927564641241, bagging_freq=7, feature_fraction=0.273955074700042, learning_rate=0.01, max_bin=55, min_data_in_leaf=9, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=5; total time=   1.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[CV] END bagging_fraction=0.8199927564641241, bagging_freq=7, feature_fraction=0.273955074700042, learning_rate=0.01, max_bin=55, min_data_in_leaf=9, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=5; total time=   1.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[CV] END bagging_fraction=0.8199927564641241, bagging_freq=7, feature_fraction=0.273955074700042, learning_rate=0.01, max_bin=55, min_data_in_leaf=9, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=5; total time=   1.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8199927564641241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199927564641241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.273955074700042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.273955074700042\n",
      "[CV] END bagging_fraction=0.8199927564641241, bagging_freq=7, feature_fraction=0.273955074700042, learning_rate=0.01, max_bin=55, min_data_in_leaf=9, min_sum_hessian_in_leaf=12, n_estimators=500, num_leaves=5; total time=   1.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3223\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3238\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3265\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[CV] END bagging_fraction=0.8020280997331797, bagging_freq=5, feature_fraction=0.20836775458032544, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=100, num_leaves=20; total time=   1.3s\n",
      "[CV] END bagging_fraction=0.8020280997331797, bagging_freq=5, feature_fraction=0.20836775458032544, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=100, num_leaves=20; total time=   1.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[CV] END bagging_fraction=0.8020280997331797, bagging_freq=5, feature_fraction=0.20836775458032544, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=100, num_leaves=20; total time=   1.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[CV] END bagging_fraction=0.8020280997331797, bagging_freq=5, feature_fraction=0.20836775458032544, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=100, num_leaves=20; total time=   1.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8020280997331797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8020280997331797\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20836775458032544, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20836775458032544\n",
      "[CV] END bagging_fraction=0.8020280997331797, bagging_freq=5, feature_fraction=0.20836775458032544, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=19, n_estimators=100, num_leaves=20; total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2244\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2236\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 262\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2258\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2244\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 259\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2251\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 260\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[CV] END bagging_fraction=0.8566411144913093, bagging_freq=6, feature_fraction=0.21507978264570857, learning_rate=0.01, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   4.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[CV] END bagging_fraction=0.8566411144913093, bagging_freq=6, feature_fraction=0.21507978264570857, learning_rate=0.01, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   4.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[CV] END bagging_fraction=0.8566411144913093, bagging_freq=6, feature_fraction=0.21507978264570857, learning_rate=0.01, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   4.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[CV] END bagging_fraction=0.8566411144913093, bagging_freq=6, feature_fraction=0.21507978264570857, learning_rate=0.01, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   4.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8566411144913093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566411144913093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=15, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21507978264570857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21507978264570857\n",
      "[CV] END bagging_fraction=0.8566411144913093, bagging_freq=6, feature_fraction=0.21507978264570857, learning_rate=0.01, max_bin=100, min_data_in_leaf=8, min_sum_hessian_in_leaf=15, n_estimators=500, num_leaves=20; total time=   4.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Total Bins 3276\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[LightGBM] [Info] Total Bins 3271\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3305\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3278\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[CV] END bagging_fraction=0.8905819557006577, bagging_freq=10, feature_fraction=0.21624482306573245, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=10; total time=   4.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[CV] END bagging_fraction=0.8905819557006577, bagging_freq=10, feature_fraction=0.21624482306573245, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=10; total time=   4.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[CV] END bagging_fraction=0.8905819557006577, bagging_freq=10, feature_fraction=0.21624482306573245, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=10; total time=   4.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[CV] END bagging_fraction=0.8905819557006577, bagging_freq=10, feature_fraction=0.21624482306573245, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=10; total time=   4.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8905819557006577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8905819557006577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=19, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21624482306573245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21624482306573245\n",
      "[CV] END bagging_fraction=0.8905819557006577, bagging_freq=10, feature_fraction=0.21624482306573245, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=19, n_estimators=800, num_leaves=10; total time=   4.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2269\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2270\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Total Bins 2275\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[CV] END bagging_fraction=0.8163249384202208, bagging_freq=5, feature_fraction=0.21104701341751425, learning_rate=0.01, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[CV] END bagging_fraction=0.8163249384202208, bagging_freq=5, feature_fraction=0.21104701341751425, learning_rate=0.01, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[CV] END bagging_fraction=0.8163249384202208, bagging_freq=5, feature_fraction=0.21104701341751425, learning_rate=0.01, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.5s\n",
      "[CV] END bagging_fraction=0.8163249384202208, bagging_freq=5, feature_fraction=0.21104701341751425, learning_rate=0.01, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8163249384202208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8163249384202208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21104701341751425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.21104701341751425\n",
      "[CV] END bagging_fraction=0.8163249384202208, bagging_freq=5, feature_fraction=0.21104701341751425, learning_rate=0.01, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3265\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3238\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3223\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Info] Total Bins 3242\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 255\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3233\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 255\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3273\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3246\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.2812555291475582, learning_rate=0.01, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=13, n_estimators=100, num_leaves=5; total time=   0.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.2812555291475582, learning_rate=0.01, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=13, n_estimators=100, num_leaves=5; total time=   0.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.2812555291475582, learning_rate=0.01, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=13, n_estimators=100, num_leaves=5; total time=   0.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.2812555291475582, learning_rate=0.01, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=13, n_estimators=100, num_leaves=5; total time=   0.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=13, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2812555291475582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2812555291475582\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.2812555291475582, learning_rate=0.01, max_bin=200, min_data_in_leaf=9, min_sum_hessian_in_leaf=13, n_estimators=100, num_leaves=5; total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1594\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 265\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1604\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Total Bins 1596\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 267\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 268\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1598\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 266\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.22773808310448393, learning_rate=0.05, max_bin=55, min_data_in_leaf=7, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   3.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.22773808310448393, learning_rate=0.05, max_bin=55, min_data_in_leaf=7, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   3.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.22773808310448393, learning_rate=0.05, max_bin=55, min_data_in_leaf=7, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.22773808310448393, learning_rate=0.05, max_bin=55, min_data_in_leaf=7, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=12, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.22773808310448393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.22773808310448393\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.22773808310448393, learning_rate=0.05, max_bin=55, min_data_in_leaf=7, min_sum_hessian_in_leaf=12, n_estimators=800, num_leaves=10; total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1564\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Total Bins 1564\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1568\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1575\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1570\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3265\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3223\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3238\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=500, num_leaves=10; total time=   2.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=500, num_leaves=10; total time=   2.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=500, num_leaves=10; total time=   2.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=500, num_leaves=10; total time=   3.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=500, num_leaves=10; total time=   3.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1614\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1605\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1615\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1610\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=100, num_leaves=5; total time=   0.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=100, num_leaves=5; total time=   0.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=100, num_leaves=5; total time=   0.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=100, num_leaves=5; total time=   0.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.3, learning_rate=0.1, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=100, num_leaves=5; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3223\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3265\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3238\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.29974530469589955, learning_rate=0.01, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   3.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.29974530469589955, learning_rate=0.01, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.29974530469589955, learning_rate=0.01, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.29974530469589955, learning_rate=0.01, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.29974530469589955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29974530469589955\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.29974530469589955, learning_rate=0.01, max_bin=200, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2214\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2240\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2235\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=100, num_leaves=20; total time=   0.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=100, num_leaves=20; total time=   0.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=100, num_leaves=20; total time=   1.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=100, num_leaves=20; total time=   1.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=20, n_estimators=100, num_leaves=20; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1605\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1614\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1615\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1610\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   3.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3268\n",
      "[LightGBM] [Info] Total Bins 3276\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3271\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3305\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3278\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.01, max_bin=200, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=10; total time=   4.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1564\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1568\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1564\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1570\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1575\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2214\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 249\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2240\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2235\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.813023906225057, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=5; total time=   1.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.813023906225057, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=5; total time=   1.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.813023906225057, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=5; total time=   1.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.813023906225057, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=5; total time=   1.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.813023906225057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.813023906225057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.813023906225057, bagging_freq=5, feature_fraction=0.3, learning_rate=0.05, max_bin=100, min_data_in_leaf=10, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=5; total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2269\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2270\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Total Bins 2255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2275\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[CV] END bagging_fraction=0.8727299527396375, bagging_freq=10, feature_fraction=0.24640945892219404, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=20; total time=   4.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[CV] END bagging_fraction=0.8727299527396375, bagging_freq=10, feature_fraction=0.24640945892219404, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=20; total time=   4.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[CV] END bagging_fraction=0.8727299527396375, bagging_freq=10, feature_fraction=0.24640945892219404, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=20; total time=   4.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[CV] END bagging_fraction=0.8727299527396375, bagging_freq=10, feature_fraction=0.24640945892219404, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=20; total time=   4.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8727299527396375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8727299527396375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24640945892219404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24640945892219404\n",
      "[CV] END bagging_fraction=0.8727299527396375, bagging_freq=10, feature_fraction=0.24640945892219404, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=500, num_leaves=20; total time=   4.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Total Bins 1614\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1605\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1615\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1610\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=20; total time=   7.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=20; total time=   7.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=20; total time=   7.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=20; total time=   7.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.3, learning_rate=0.01, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=20; total time=   7.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2269\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2275\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2270\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.20982343995375183, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.1s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.20982343995375183, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.20982343995375183, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.20982343995375183, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.20982343995375183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.20982343995375183\n",
      "[CV] END bagging_fraction=0.8, bagging_freq=10, feature_fraction=0.20982343995375183, learning_rate=0.05, max_bin=100, min_data_in_leaf=6, min_sum_hessian_in_leaf=11, n_estimators=800, num_leaves=5; total time=   2.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1615\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1610\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 272\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1605\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1614\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=5; total time=   2.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=5; total time=   2.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=5; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=5; total time=   2.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=20, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[CV] END bagging_fraction=0.9, bagging_freq=10, feature_fraction=0.2, learning_rate=0.05, max_bin=55, min_data_in_leaf=6, min_sum_hessian_in_leaf=20, n_estimators=800, num_leaves=5; total time=   2.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.024057\n",
      "Beste Parameter fÃ¼r LGBMRegressor:  OrderedDict({'bagging_fraction': 0.8, 'bagging_freq': 10, 'feature_fraction': 0.2, 'learning_rate': 0.05, 'max_bin': 55, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 11, 'n_estimators': 800, 'num_leaves': 5})\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.024057\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Mean Squared Error = 0.00541734\n",
      "RMSE score for LGBMRegressor: 0.0736\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Erstellen Sie ein Parameter-Grid\n",
    "param_grid = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 500, 800],\n",
    "    'max_bin': [55, 100, 200],\n",
    "    'bagging_fraction': [0.8, 0.9],\n",
    "    'bagging_freq': [5, 10],\n",
    "    'feature_fraction': [0.2, 0.3],\n",
    "    'min_data_in_leaf': [6, 10],\n",
    "    'min_sum_hessian_in_leaf': [11, 20]\n",
    "}\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression', feature_fraction_seed=9, bagging_seed=9)\n",
    "\n",
    "# Verwenden Sie GridSearchCV, um die besten Parameter zu finden\n",
    "#grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "bayesian_search = BayesSearchCV(estimator=lgb_model, search_spaces=param_grid, cv=5, n_jobs=-1, verbose=2, n_iter=32, random_state=42)\n",
    "\n",
    "bayesian_search.fit(X_train, y_train)\n",
    "\n",
    "# Holen Sie sich die besten Parameter\n",
    "best_params_lgbm = bayesian_search.best_params_\n",
    "print(\"Beste Parameter fÃ¼r LGBMRegressor: \", best_params_lgbm)\n",
    "\n",
    "#Erstellen Sie ein neues Modell mit den besten Parametern\n",
    "optimal_lgb_model = lgb.LGBMRegressor(**best_params_lgbm)\n",
    "\n",
    "# Trainieren Sie das Modell mit den besten Parametern\n",
    "optimal_lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen und Evaluierung\n",
    "y_train_pred = optimal_lgb_model.predict(X_train)\n",
    "MSE_train =  np.mean((y_train_pred - y_train)**2)\n",
    "\n",
    "RMSE_train = np.sqrt(MSE_train)\n",
    "\n",
    "print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "print(\"RMSE score for LGBMRegressor: {:.4f}\".format(RMSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.00541734\n",
      "RMSE score for LGBMRegressor: 0.0736\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "print(\"RMSE score for LGBMRegressor: {:.4f}\".format(RMSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb_model = lgb.LGBMRegressor(objective='regression', num_leaves=5,\n",
    "#                              learning_rate=0.05, n_estimators=800,\n",
    "#                              max_bin = 55, bagging_fraction = 0.8,\n",
    "#                              bagging_freq = 5, feature_fraction = 0.2,\n",
    "#                              feature_fraction_seed=9, bagging_seed=9,\n",
    "#                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "#lgb_model.fit(X_train, y_train)\n",
    "\n",
    "#y_train_pred = lgb_model.predict(X_train)\n",
    "#MSE_train = np.mean((y_train_pred - y_train)**2)\n",
    "\n",
    "#print(\"Mean Squared Error = {:.8f}\".format(MSE_train))\n",
    "#print(\"RMSE score for LGBMRegressor: {:.4f}\".format(rmse(lgb_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "#model2 = sklearn.ensemble.BaggingRegressor(estimator = lasso_model, n_estimators = 50, \n",
    "#                                           max_samples = 30, max_features = 200, verbose = 3, n_jobs = 3)\n",
    "#model2.fit(X_train, y_train)\n",
    "\n",
    "#y_train_pred = model2.predict(X_train)\n",
    "#MSE_train = np.mean((y_train_pred - y_train)**2)\n",
    "\n",
    "#print(\"Mean Squared Error = {:.8f}\".format(MSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"RMSE score for BaggingRegressor: {:.4f}\".format(rmse(model2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "lasso_model = make_pipeline(RobustScaler(),\n",
    "                      LassoCV(max_iter=int(1e7), alphas = [0.0004, 0.0005, 0.0006],\n",
    "                              random_state = 42, cv=5))\n",
    "\n",
    "elasticnet_model = make_pipeline(RobustScaler(), \n",
    "                           ElasticNetCV(max_iter=int(1e7), alphas=[0.0004, 0.0005, 0.0006], \n",
    "                                        cv=5, l1_ratio=[0.7, 0.8, 0.9]))\n",
    "\n",
    "#lgbm_model = make_pipeline(RobustScaler(),\n",
    "#                        lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "#                                      learning_rate=0.05, n_estimators=800,\n",
    "#                                      max_bin = 55, bagging_fraction = 0.8,\n",
    "#                                      bagging_freq = 5, feature_fraction = 0.23,\n",
    "#                                      feature_fraction_seed = 9, bagging_seed=9,\n",
    "#                                      min_data_in_leaf = 6, \n",
    "#\n",
    "#                                       min_sum_hessian_in_leaf = 11))\n",
    "lgbm_model = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    lgb.LGBMRegressor(**best_params_lgbm, objective='regression', feature_fraction_seed=9, bagging_seed=9)\n",
    ")\n",
    "\n",
    "#xgboost_model = make_pipeline(RobustScaler(),\n",
    "#                        xgb.XGBRegressor(learning_rate = 0.01, n_estimators=3400, \n",
    "#                                     max_depth=3,min_child_weight=0 ,\n",
    "#                                     gamma=0, subsample=0.7,\n",
    "#                                     colsample_bytree=0.7,\n",
    "#                                     objective= 'reg:linear',nthread=4,\n",
    "#                                     scale_pos_weight=1,seed=27, \n",
    "#                                     reg_alpha=0.00006))\n",
    "\n",
    "xgboost_model = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    xgb.XGBRegressor(**best_params_xgb, seed=0, objective='reg:linear')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_regressor = StackingCVRegressor(regressors=(lasso_model, elasticnet_model, xgboost_model, lgbm_model), \n",
    "                               meta_regressor=xgboost_model, use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1558\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.021979\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1555\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 251\n",
      "[LightGBM] [Info] Start training from score 12.023757\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1545\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 12.016164\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1558\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.026668\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1551\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 12.031720\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1598\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.024057\n"
     ]
    }
   ],
   "source": [
    "stack_model = stack_regressor.fit(np.array(X_train),  np.array(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1598\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 261\n",
      "[LightGBM] [Info] Start training from score 12.024057\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n"
     ]
    }
   ],
   "source": [
    "# Trainieren der einzelnen Modelle\n",
    "lasso_model.fit(X_train, y_train)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "en_preds = en_model.predict(test_preprocessed)\n",
    "lasso_preds = lasso_model.predict(test_preprocessed)\n",
    "stack_gen_preds = stack_model.predict(test_preprocessed)\n",
    "lgbm_preds = lgbm_model.predict(test_preprocessed)\n",
    "stack_preds = ((0.2*en_preds) + (0.25*lasso_preds) + (0.15*lgbm_preds) + (0.4*stack_gen_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>122197.295295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>157430.601957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>177478.392017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>193394.837934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>191705.459000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SalePrice\n",
       "Id                 \n",
       "1461  122197.295295\n",
       "1462  157430.601957\n",
       "1463  177478.392017\n",
       "1464  193394.837934\n",
       "1465  191705.459000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(np.expm1(stack_preds), \n",
    "                              index = test_preprocessed.index+1, \n",
    "                              columns=[\"SalePrice\"])\n",
    "predictions_df.index.name = \"Id\"\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[\"SalePrice\"].to_csv(\"my_predictions.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
