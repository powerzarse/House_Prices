{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7bf24f-bbc6-492a-bb2e-7645aa9bdc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import optuna\n",
    "import tqdm as notebook_tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243fbe6e-98ba-4bfc-a054-26a05f1e9713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Datei öffnen und lesen\n",
    "#with open('data_description.txt', 'r') as file:\n",
    "#    content = file.read()\n",
    "\n",
    "# Inhalt als Markdown anzeigen\n",
    "#display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b584497-e38d-4c8a-8581-2d9c08c73f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba9c469-5c7b-4262-bc76-7ba22bb92157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bca2a79-db96-4d61-8af8-aadb8a02e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percent Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>872</td>\n",
       "      <td>59.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>47.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>99.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>80.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>96.301370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Values  Percent Missing\n",
       "LotFrontage              259        17.739726\n",
       "Alley                   1369        93.767123\n",
       "MasVnrType               872        59.726027\n",
       "MasVnrArea                 8         0.547945\n",
       "BsmtQual                  37         2.534247\n",
       "BsmtCond                  37         2.534247\n",
       "BsmtExposure              38         2.602740\n",
       "BsmtFinType1              37         2.534247\n",
       "BsmtFinType2              38         2.602740\n",
       "Electrical                 1         0.068493\n",
       "FireplaceQu              690        47.260274\n",
       "GarageType                81         5.547945\n",
       "GarageYrBlt               81         5.547945\n",
       "GarageFinish              81         5.547945\n",
       "GarageQual                81         5.547945\n",
       "GarageCond                81         5.547945\n",
       "PoolQC                  1453        99.520548\n",
       "Fence                   1179        80.753425\n",
       "MiscFeature             1406        96.301370"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count = train.isnull().sum()\n",
    "missing_values_percent = (train.isnull().sum() / len(train)) * 100\n",
    "\n",
    "# Umwandeln des Ergebnisses in ein DataFrame\n",
    "missing_data_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values_count,\n",
    "    'Percent Missing': missing_values_percent\n",
    "})\n",
    "\n",
    "missing_data_df = missing_data_df[missing_data_df['Missing Values'] > 0]\n",
    "missing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be13722a-8e59-4a15-a74e-78f6e7e7ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtQual\n",
      "TA    649\n",
      "Gd    618\n",
      "Ex    121\n",
      "Fa     35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = train['BsmtQual'].value_counts()\n",
    "\n",
    "# Ausgabe des Ergebnisses\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243ffce0-e22b-4624-a14a-76ba8eefb28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after preprocessing: 0\n"
     ]
    }
   ],
   "source": [
    "data = train.drop(columns=['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'])\n",
    "\n",
    "for column in data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if data[column].isnull().mean() > 0:\n",
    "        data[column] = data[column].fillna(data[column].mean())\n",
    "\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if data[column].isnull().mean() > 0:\n",
    "        data[column] = data[column].fillna(data[column].mode()[0])\n",
    "\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "missing_values_after = data.isnull().sum().sum()\n",
    "print(f\"Missing values after preprocessing: {missing_values_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb3a6cc-ad5d-4cc3-b1f1-24480a4e4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 25913.94\n"
     ]
    }
   ],
   "source": [
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisieren und Trainieren des XGBoost Regressors\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                          colsample_bytree=0.3,\n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=5,\n",
    "                          alpha=10,\n",
    "                          n_estimators=500)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen und Berechnen des RMSE\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"XGBoost RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4693e74-a6e8-4bda-bcaf-d8e95395a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 28711.87\n"
     ]
    }
   ],
   "source": [
    "# Initialisieren und Trainieren des RandomForestRegressors\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen und Berechnen des RMSE\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "rmse_rf = root_mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest RMSE: {rmse_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e5df3ba-ec57-493c-8af4-3a3108f81c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35244638208.0000 - val_loss: 34148681728.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 32269766656.0000 - val_loss: 24129609728.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 21063653376.0000 - val_loss: 8924145664.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 8711989248.0000 - val_loss: 4183036672.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 7712146944.0000 - val_loss: 3671467776.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 7167407616.0000 - val_loss: 3337244672.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 4546073600.0000 - val_loss: 3112493056.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 5519971840.0000 - val_loss: 3033553408.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 5227348480.0000 - val_loss: 2814089216.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 4478648320.0000 - val_loss: 2746113280.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 4489806848.0000 - val_loss: 2666915840.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 3852880896.0000 - val_loss: 2594127360.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 3384756224.0000 - val_loss: 2521533952.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 3852185600.0000 - val_loss: 2443661056.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 3067461120.0000 - val_loss: 2385233152.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 3219027456.0000 - val_loss: 2293333760.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 2987624960.0000 - val_loss: 2217140480.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 3158319360.0000 - val_loss: 2113643264.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 2976648960.0000 - val_loss: 2010764928.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 2416246272.0000 - val_loss: 1909048576.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 2491619584.0000 - val_loss: 1838256640.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 2817737984.0000 - val_loss: 1734204544.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 2354175488.0000 - val_loss: 1656316288.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 2865705216.0000 - val_loss: 1589407360.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 2152302848.0000 - val_loss: 1572868352.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 2253841408.0000 - val_loss: 1474230784.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 2054710528.0000 - val_loss: 1441956992.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 2452808704.0000 - val_loss: 1381464960.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 2993423616.0000 - val_loss: 1360539520.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 2008640896.0000 - val_loss: 1321901184.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 2305324544.0000 - val_loss: 1377100928.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 2515342336.0000 - val_loss: 1295284864.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 2403166720.0000 - val_loss: 1252070400.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 1692001536.0000 - val_loss: 1307746560.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 1898338432.0000 - val_loss: 1254724608.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 2041953792.0000 - val_loss: 1228095872.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 2854538752.0000 - val_loss: 1220258432.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 1766800000.0000 - val_loss: 1261145600.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 2781987840.0000 - val_loss: 1211871232.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 2281429760.0000 - val_loss: 1206829952.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 1825858304.0000 - val_loss: 1234105344.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 2045678208.0000 - val_loss: 1193925376.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 1987029888.0000 - val_loss: 1190283648.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1978694784.0000 - val_loss: 1248154112.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 3131169792.0000 - val_loss: 1224838144.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 2254279936.0000 - val_loss: 1195867904.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 1740298112.0000 - val_loss: 1200747904.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 2105531648.0000 - val_loss: 1248906624.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 1474152960.0000 - val_loss: 1236838656.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 2196540928.0000 - val_loss: 1194483840.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 2282685952.0000 - val_loss: 1189593472.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 2103215488.0000 - val_loss: 1240163584.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 1712221568.0000 - val_loss: 1297807104.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 2395557632.0000 - val_loss: 1205954688.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 2127502080.0000 - val_loss: 1206636416.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 1896581632.0000 - val_loss: 1181689728.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 2350804224.0000 - val_loss: 1187169280.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 2128775680.0000 - val_loss: 1263208064.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 1953607936.0000 - val_loss: 1214183040.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 1903084928.0000 - val_loss: 1204091392.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 2366270976.0000 - val_loss: 1186344960.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 2277223168.0000 - val_loss: 1183467520.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 1411937536.0000 - val_loss: 1171900928.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 1769998592.0000 - val_loss: 1176838912.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 1702225408.0000 - val_loss: 1228500608.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 2164157440.0000 - val_loss: 1177646080.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 1517297920.0000 - val_loss: 1191966464.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 1673675392.0000 - val_loss: 1182053760.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 1585344640.0000 - val_loss: 1169338112.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 1660764672.0000 - val_loss: 1152772608.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 2321374208.0000 - val_loss: 1167097984.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 2282507520.0000 - val_loss: 1160134016.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 2126208384.0000 - val_loss: 1157035392.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 1702696064.0000 - val_loss: 1223087488.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 1655202304.0000 - val_loss: 1163774464.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 1892527488.0000 - val_loss: 1147630464.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 2457603840.0000 - val_loss: 1160688512.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 1841976576.0000 - val_loss: 1189494400.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 2036688640.0000 - val_loss: 1169194496.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 1610939776.0000 - val_loss: 1150357632.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 2744863488.0000 - val_loss: 1158675456.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 1519238656.0000 - val_loss: 1173162752.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 1472671232.0000 - val_loss: 1147215232.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 1775587584.0000 - val_loss: 1154836096.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 1748065920.0000 - val_loss: 1183408896.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 2020219392.0000 - val_loss: 1145606912.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 2008761728.0000 - val_loss: 1150968192.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 1542566656.0000 - val_loss: 1175410176.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 1420096000.0000 - val_loss: 1145864704.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 1794414976.0000 - val_loss: 1164307968.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 1531726464.0000 - val_loss: 1163855360.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 1825315840.0000 - val_loss: 1155713792.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 1548801792.0000 - val_loss: 1171868160.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 1571972096.0000 - val_loss: 1201048704.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 1516836096.0000 - val_loss: 1138255488.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 1474284416.0000 - val_loss: 1146018432.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 2107640704.0000 - val_loss: 1128799232.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 1819649664.0000 - val_loss: 1145947648.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 1435780608.0000 - val_loss: 1147578624.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 1411441536.0000 - val_loss: 1189199232.0000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Keras NN RMSE: 40628.98\n"
     ]
    }
   ],
   "source": [
    "# Angenommen, 'data' ist Ihr DataFrame mit den Features und der Zielvariable 'SalePrice'\n",
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)\n",
    "\n",
    "# Initialisieren des Keras-Modells\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Kompilieren des Modells\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Trainieren des Modells\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Vorhersagen und Berechnen des RMSE\n",
    "y_pred_nn = model.predict(X_test)\n",
    "rmse_nn = root_mean_squared_error(y_test, y_pred_nn)\n",
    "print(f\"Keras NN RMSE: {rmse_nn:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9289c71f-3f86-4289-b7b5-f6a79c12b5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 60989.88\n",
      "Ridge Regression RMSE: 30065.05\n",
      "Lasso Regression RMSE: 51803.62\n",
      "Decision Tree Regressor RMSE: 43192.41\n",
      "Random Forest Regressor RMSE: 28711.87\n",
      "Gradient Boosting Regressor RMSE: 28316.66\n",
      "XGBoost Regressor RMSE: 26023.49\n"
     ]
    }
   ],
   "source": [
    "# Angenommen, 'data' ist Ihr DataFrame mit den Features und der Zielvariable 'SalePrice'\n",
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)\n",
    "\n",
    "# Initialisieren der Modelle\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost Regressor\": xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, alpha=10, n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Trainieren und Evaluieren der Modelle\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{name} RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e523c7ff-1229-4938-9587-54852ac69fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92fe1d4a-921c-4164-a2c5-833054de54b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.97269e-13): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.97269e-13): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.42483e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.42483e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.24289e-11): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.24289e-11): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.7266e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.91209e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.91655e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.76608e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.7266e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.93685e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.91209e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.91655e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.76608e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.93685e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 30625.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ridge_params = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 100.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge_grid = GridSearchCV(ridge, ridge_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_rmse = root_mean_squared_error(y_test, best_ridge.predict(X_test))\n",
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb830971-536f-4dc0-9244-95f8ff184ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest RMSE: 28899.30\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_grid = RandomizedSearchCV(rf, rf_params, cv=5, scoring='neg_mean_squared_error', n_iter=10, n_jobs=-1, random_state=42)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_rmse = root_mean_squared_error(y_test, best_rf.predict(X_test))\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7afc2ed6-0df5-4ffc-9184-c920d79c4e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 26374.18\n"
     ]
    }
   ],
   "source": [
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb_grid = RandomizedSearchCV(gb, gb_params, cv=5, scoring='neg_mean_squared_error', n_iter=10, n_jobs=-1, random_state=42)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb535cf-57b8-46bf-9e46-a3eaa625c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost RMSE: 25682.01\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgb_grid = RandomizedSearchCV(xgb_reg, xgb_params, cv=5, scoring='neg_mean_squared_error', n_iter=10, n_jobs=-1, random_state=42)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "xgb_rmse = mean_squared_error(y_test, best_xgb.predict(X_test), squared=False)\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c5e2c08-677d-4783-8916-647ca9efdd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 30625.29\n",
      "Best Random Forest RMSE: 28899.30\n",
      "Best Gradient Boosting RMSE: 26374.18\n",
      "Best XGBoost RMSE: 25682.01\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47cbe96a-395e-427d-9655-8e52312549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angenommen, 'data' ist Ihr DataFrame mit den Features und der Zielvariable 'SalePrice'\n",
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ede0572d-93d5-4367-a271-fba1077dd990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:52:06,239] A new study created in memory with name: no-name-d1b5774f-b3a6-4118-ae56-2f1d80b3969d\n",
      "[I 2024-06-18 20:52:06,757] Trial 2 finished with value: 40412.6875 and parameters: {'alpha': 0.910052609527051, 'solver': 'lsqr'}. Best is trial 2 with value: 40412.6875.\n",
      "[I 2024-06-18 20:52:07,507] Trial 8 finished with value: 40412.71484375 and parameters: {'alpha': 0.6179970056402856, 'solver': 'lsqr'}. Best is trial 2 with value: 40412.6875.\n",
      "[I 2024-06-18 20:52:07,556] Trial 4 finished with value: 40412.69921875 and parameters: {'alpha': 0.2704796366889385, 'solver': 'lsqr'}. Best is trial 2 with value: 40412.6875.\n",
      "[I 2024-06-18 20:52:09,323] Trial 7 finished with value: 43379.76171875 and parameters: {'alpha': 42.57079429944377, 'solver': 'sag'}. Best is trial 2 with value: 40412.6875.\n",
      "[I 2024-06-18 20:52:09,324] Trial 0 finished with value: 43380.390625 and parameters: {'alpha': 0.8482496372775298, 'solver': 'sag'}. Best is trial 2 with value: 40412.6875.\n",
      "[I 2024-06-18 20:52:09,669] Trial 5 finished with value: 43380.27734375 and parameters: {'alpha': 7.381668094893596, 'solver': 'sag'}. Best is trial 2 with value: 40412.6875.\n",
      "[I 2024-06-18 20:52:09,963] Trial 1 finished with value: 44319.2421875 and parameters: {'alpha': 24.265003480569142, 'solver': 'saga'}. Best is trial 2 with value: 40412.6875.\n",
      "[I 2024-06-18 20:52:09,994] Trial 12 finished with value: 40412.59375 and parameters: {'alpha': 50.08187534602627, 'solver': 'lsqr'}. Best is trial 12 with value: 40412.59375.\n",
      "[I 2024-06-18 20:52:10,310] Trial 13 finished with value: 35394.9296875 and parameters: {'alpha': 0.115367104358924, 'solver': 'sparse_cg'}. Best is trial 13 with value: 35394.9296875.\n",
      "[I 2024-06-18 20:52:11,141] Trial 9 finished with value: 44319.7109375 and parameters: {'alpha': 2.9660071738370495, 'solver': 'saga'}. Best is trial 13 with value: 35394.9296875.\n",
      "[I 2024-06-18 20:52:12,305] Trial 17 finished with value: 35374.46484375 and parameters: {'alpha': 0.17968437344471233, 'solver': 'sparse_cg'}. Best is trial 17 with value: 35374.46484375.\n",
      "[I 2024-06-18 20:52:13,237] Trial 18 finished with value: 35386.8046875 and parameters: {'alpha': 0.16008791239787745, 'solver': 'sparse_cg'}. Best is trial 17 with value: 35374.46484375.\n",
      "[I 2024-06-18 20:52:15,417] Trial 19 finished with value: 35385.9453125 and parameters: {'alpha': 0.11756394208929982, 'solver': 'sparse_cg'}. Best is trial 17 with value: 35374.46484375.\n",
      "[I 2024-06-18 20:52:23,026] Trial 10 finished with value: 32486.318359375 and parameters: {'alpha': 71.06491017780931, 'solver': 'cholesky'}. Best is trial 10 with value: 32486.318359375.\n",
      "[I 2024-06-18 20:52:23,066] Trial 3 finished with value: 32261.935546875 and parameters: {'alpha': 0.12776064563574094, 'solver': 'auto'}. Best is trial 3 with value: 32261.935546875.\n",
      "[I 2024-06-18 20:52:25,332] Trial 15 finished with value: 30219.17578125 and parameters: {'alpha': 0.47467804378436645, 'solver': 'svd'}. Best is trial 15 with value: 30219.17578125.\n",
      "[I 2024-06-18 20:52:25,931] Trial 11 finished with value: 31009.44140625 and parameters: {'alpha': 0.21285345752336884, 'solver': 'svd'}. Best is trial 15 with value: 30219.17578125.\n",
      "[I 2024-06-18 20:52:28,536] Trial 14 finished with value: 31148.4375 and parameters: {'alpha': 21.043560841494557, 'solver': 'auto'}. Best is trial 15 with value: 30219.17578125.\n",
      "[I 2024-06-18 20:52:29,133] Trial 20 finished with value: 30269.275390625 and parameters: {'alpha': 0.4294210676786817, 'solver': 'svd'}. Best is trial 15 with value: 30219.17578125.\n",
      "[I 2024-06-18 20:52:30,453] Trial 6 finished with value: 30085.736328125 and parameters: {'alpha': 1.6208808567366828, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:31,970] Trial 16 finished with value: 30492.177734375 and parameters: {'alpha': 0.31655888681705685, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:41,272] Trial 21 finished with value: 30647.54296875 and parameters: {'alpha': 10.406821522640113, 'solver': 'cholesky'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:42,007] Trial 26 finished with value: 30107.03515625 and parameters: {'alpha': 1.9300870662879694, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:42,417] Trial 27 finished with value: 30107.28515625 and parameters: {'alpha': 1.9336174724843427, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:42,873] Trial 23 finished with value: 30322.099609375 and parameters: {'alpha': 0.39306154873547944, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:43,439] Trial 24 finished with value: 30113.267578125 and parameters: {'alpha': 2.015664144201451, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:43,440] Trial 22 finished with value: 30664.865234375 and parameters: {'alpha': 10.726568492904622, 'solver': 'auto'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:46,676] Trial 25 finished with value: 30334.04296875 and parameters: {'alpha': 0.385981955329193, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:49,104] Trial 28 finished with value: 30116.583984375 and parameters: {'alpha': 2.060582391337224, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:58,382] Trial 29 finished with value: 30113.55859375 and parameters: {'alpha': 2.0196709350600033, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:58,705] Trial 30 finished with value: 30101.955078125 and parameters: {'alpha': 1.85944395483162, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:59,672] Trial 32 finished with value: 30112.705078125 and parameters: {'alpha': 2.007961743561515, 'solver': 'svd'}. Best is trial 6 with value: 30085.736328125.\n",
      "[I 2024-06-18 20:52:59,795] Trial 34 finished with value: 30077.447265625 and parameters: {'alpha': 1.48382605840853, 'solver': 'svd'}. Best is trial 34 with value: 30077.447265625.\n",
      "[I 2024-06-18 20:53:00,972] Trial 33 finished with value: 30093.142578125 and parameters: {'alpha': 1.7329345655850605, 'solver': 'svd'}. Best is trial 34 with value: 30077.447265625.\n",
      "[I 2024-06-18 20:53:01,015] Trial 31 finished with value: 30104.345703125 and parameters: {'alpha': 1.892955636803381, 'solver': 'svd'}. Best is trial 34 with value: 30077.447265625.\n",
      "[I 2024-06-18 20:53:01,021] Trial 35 finished with value: 30072.591796875 and parameters: {'alpha': 1.3921216150818871, 'solver': 'svd'}. Best is trial 35 with value: 30072.591796875.\n",
      "[I 2024-06-18 20:53:03,321] Trial 40 finished with value: 44320.2890625 and parameters: {'alpha': 1.0614994441557253, 'solver': 'saga'}. Best is trial 35 with value: 30072.591796875.\n",
      "[I 2024-06-18 20:53:04,321] Trial 43 finished with value: 43379.66015625 and parameters: {'alpha': 1.0038335138722174, 'solver': 'sag'}. Best is trial 35 with value: 30072.591796875.\n",
      "[I 2024-06-18 20:53:04,352] Trial 42 finished with value: 44320.54296875 and parameters: {'alpha': 1.0602032994510202, 'solver': 'saga'}. Best is trial 35 with value: 30072.591796875.\n",
      "[I 2024-06-18 20:53:04,577] Trial 41 finished with value: 44320.640625 and parameters: {'alpha': 1.0526107230738104, 'solver': 'saga'}. Best is trial 35 with value: 30072.591796875.\n",
      "[I 2024-06-18 20:53:06,323] Trial 44 finished with value: 43380.5234375 and parameters: {'alpha': 4.648139622003061, 'solver': 'sag'}. Best is trial 35 with value: 30072.591796875.\n",
      "[I 2024-06-18 20:53:07,262] Trial 36 finished with value: 30064.576171875 and parameters: {'alpha': 1.1652678980835063, 'solver': 'svd'}. Best is trial 36 with value: 30064.576171875.\n",
      "[I 2024-06-18 20:53:19,147] Trial 38 finished with value: 30063.900390625 and parameters: {'alpha': 1.0767097129695828, 'solver': 'svd'}. Best is trial 38 with value: 30063.900390625.\n",
      "[I 2024-06-18 20:53:19,656] Trial 49 finished with value: 30241.470703125 and parameters: {'alpha': 3.7604494125345753, 'solver': 'svd'}. Best is trial 38 with value: 30063.900390625.\n",
      "[I 2024-06-18 20:53:19,726] Trial 47 finished with value: 30310.34765625 and parameters: {'alpha': 4.76695615011632, 'solver': 'cholesky'}. Best is trial 38 with value: 30063.900390625.\n",
      "[I 2024-06-18 20:53:20,009] Trial 39 finished with value: 30064.525390625 and parameters: {'alpha': 1.0220166675671998, 'solver': 'svd'}. Best is trial 38 with value: 30063.900390625.\n",
      "[I 2024-06-18 20:53:20,065] Trial 37 finished with value: 30063.8984375 and parameters: {'alpha': 1.1031420333542, 'solver': 'svd'}. Best is trial 37 with value: 30063.8984375.\n",
      "[I 2024-06-18 20:53:20,180] Trial 46 finished with value: 30311.453125 and parameters: {'alpha': 4.78345414824606, 'solver': 'cholesky'}. Best is trial 37 with value: 30063.8984375.\n",
      "[I 2024-06-18 20:53:20,201] Trial 45 finished with value: 30312.3203125 and parameters: {'alpha': 4.796819987028231, 'solver': 'cholesky'}. Best is trial 37 with value: 30063.8984375.\n",
      "[I 2024-06-18 20:53:20,207] Trial 48 finished with value: 30233.220703125 and parameters: {'alpha': 3.6438936777718913, 'solver': 'svd'}. Best is trial 37 with value: 30063.8984375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 30063.90\n"
     ]
    }
   ],
   "source": [
    "def objective_ridge(trial):\n",
    "    alpha = trial.suggest_loguniform('alpha', 0.1, 100.0)\n",
    "    solver = trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n",
    "    \n",
    "    model = Ridge(alpha=alpha, solver=solver)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_ridge = optuna.create_study(direction='minimize')\n",
    "study_ridge.optimize(objective_ridge, n_trials=50, n_jobs=-1)\n",
    "\n",
    "best_params_ridge = study_ridge.best_params\n",
    "best_ridge = Ridge(**best_params_ridge)\n",
    "best_ridge.fit(X_train, y_train)\n",
    "ridge_rmse = mean_squared_error(y_test, best_ridge.predict(X_test), squared=False)\n",
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fec3bf41-f8a3-4d5c-9f79-3f08b5828dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 26218.34\n"
     ]
    }
   ],
   "source": [
    "# Definieren der Parameter für Bayesian Optimization\n",
    "gb_params = {\n",
    "    'n_estimators': Integer(50, 300),\n",
    "    'learning_rate': Real(0.01, 0.1, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 10),\n",
    "    'subsample': Real(0.7, 1.0),\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'min_samples_leaf': Integer(1, 4)\n",
    "}\n",
    "\n",
    "# Initialisieren des Gradient Boosting Regressors\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Bayesian Optimization mit BayesSearchCV\n",
    "gb_opt = BayesSearchCV(gb, gb_params, n_iter=32, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "gb_opt.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell und RMSE berechnen\n",
    "best_gb = gb_opt.best_estimator_\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90d1e96c-a878-4a6b-89e6-a2fc4e55b8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 30063.90\n",
      "Best Random Forest RMSE: 28899.30\n",
      "Best Gradient Boosting RMSE: 26218.34\n",
      "Best XGBoost RMSE: 25682.01\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dc9ef18-369f-4d7d-8ac2-5f4c216da78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:54:48,262] A new study created in memory with name: no-name-08f2cf99-99f1-4590-a5d4-5d25279ca827\n",
      "[I 2024-06-18 20:54:49,029] Trial 6 finished with value: 30740.802740359533 and parameters: {'n_estimators': 54, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 6 with value: 30740.802740359533.\n",
      "[I 2024-06-18 20:54:49,274] Trial 1 finished with value: 30360.06486732964 and parameters: {'n_estimators': 53, 'max_depth': 43, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 1 with value: 30360.06486732964.\n",
      "[I 2024-06-18 20:54:50,165] Trial 9 finished with value: 30424.430938349724 and parameters: {'n_estimators': 57, 'max_depth': 37, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 1 with value: 30360.06486732964.\n",
      "[I 2024-06-18 20:54:50,219] Trial 5 finished with value: 29465.231761614563 and parameters: {'n_estimators': 106, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 5 with value: 29465.231761614563.\n",
      "[I 2024-06-18 20:54:50,654] Trial 4 finished with value: 29011.179358480687 and parameters: {'n_estimators': 120, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 4 with value: 29011.179358480687.\n",
      "[I 2024-06-18 20:54:50,876] Trial 2 finished with value: 30101.190276463225 and parameters: {'n_estimators': 160, 'max_depth': 35, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 4 with value: 29011.179358480687.\n",
      "[I 2024-06-18 20:54:51,357] Trial 7 finished with value: 31191.345723380422 and parameters: {'n_estimators': 199, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 4 with value: 29011.179358480687.\n",
      "[I 2024-06-18 20:54:51,621] Trial 0 finished with value: 30855.135145585464 and parameters: {'n_estimators': 221, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 4 with value: 29011.179358480687.\n",
      "[I 2024-06-18 20:54:52,073] Trial 11 finished with value: 31174.698468784816 and parameters: {'n_estimators': 117, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 4 with value: 29011.179358480687.\n",
      "[I 2024-06-18 20:54:53,715] Trial 10 finished with value: 30250.815023596802 and parameters: {'n_estimators': 227, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 4 with value: 29011.179358480687.\n",
      "[I 2024-06-18 20:54:54,223] Trial 3 finished with value: 29130.248327896305 and parameters: {'n_estimators': 298, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 4 with value: 29011.179358480687.\n",
      "[I 2024-06-18 20:54:54,658] Trial 8 finished with value: 28927.180743694844 and parameters: {'n_estimators': 291, 'max_depth': 34, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 8 with value: 28927.180743694844.\n",
      "[I 2024-06-18 20:54:54,842] Trial 13 finished with value: 28821.835249454027 and parameters: {'n_estimators': 193, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:54:55,191] Trial 12 finished with value: 29461.14659389436 and parameters: {'n_estimators': 263, 'max_depth': 42, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:54:55,284] Trial 14 finished with value: 31133.877605342892 and parameters: {'n_estimators': 241, 'max_depth': 42, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:54:55,419] Trial 15 finished with value: 30065.017568175976 and parameters: {'n_estimators': 209, 'max_depth': 45, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:54:56,778] Trial 16 finished with value: 29028.796678239676 and parameters: {'n_estimators': 235, 'max_depth': 31, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:55:02,207] Trial 17 finished with value: 28896.8792583946 and parameters: {'n_estimators': 298, 'max_depth': 48, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:55:03,363] Trial 18 finished with value: 28895.965614723398 and parameters: {'n_estimators': 299, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:55:03,522] Trial 20 finished with value: 28926.550072552895 and parameters: {'n_estimators': 281, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:55:04,241] Trial 19 finished with value: 28914.30247502363 and parameters: {'n_estimators': 297, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 13 with value: 28821.835249454027.\n",
      "[I 2024-06-18 20:55:07,793] Trial 22 finished with value: 28443.538258641744 and parameters: {'n_estimators': 290, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 22 with value: 28443.538258641744.\n",
      "[I 2024-06-18 20:55:07,965] Trial 21 finished with value: 28423.067030163096 and parameters: {'n_estimators': 296, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 21 with value: 28423.067030163096.\n",
      "[I 2024-06-18 20:55:08,083] Trial 23 finished with value: 28390.74542848044 and parameters: {'n_estimators': 294, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:10,612] Trial 24 finished with value: 28437.889979752843 and parameters: {'n_estimators': 292, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:10,992] Trial 25 finished with value: 28407.572903840875 and parameters: {'n_estimators': 169, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:11,407] Trial 27 finished with value: 28666.60375902902 and parameters: {'n_estimators': 168, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:11,640] Trial 26 finished with value: 28651.354143408098 and parameters: {'n_estimators': 173, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:15,812] Trial 28 finished with value: 28724.515235121424 and parameters: {'n_estimators': 261, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:16,619] Trial 33 finished with value: 28842.43958968786 and parameters: {'n_estimators': 169, 'max_depth': 38, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:17,543] Trial 29 finished with value: 28726.1598005445 and parameters: {'n_estimators': 258, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:17,912] Trial 31 finished with value: 28704.48479847379 and parameters: {'n_estimators': 262, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:18,096] Trial 30 finished with value: 28716.29258201354 and parameters: {'n_estimators': 261, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:20,174] Trial 34 finished with value: 28962.407866354253 and parameters: {'n_estimators': 256, 'max_depth': 39, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:20,474] Trial 32 finished with value: 28718.53029360589 and parameters: {'n_estimators': 260, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:20,958] Trial 35 finished with value: 28929.360639034247 and parameters: {'n_estimators': 261, 'max_depth': 38, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:21,206] Trial 36 finished with value: 28846.54778996893 and parameters: {'n_estimators': 150, 'max_depth': 38, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:22,303] Trial 38 finished with value: 28751.791601615147 and parameters: {'n_estimators': 146, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:22,919] Trial 40 finished with value: 28846.54778996893 and parameters: {'n_estimators': 150, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:22,969] Trial 39 finished with value: 28803.706640405788 and parameters: {'n_estimators': 151, 'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:24,954] Trial 42 finished with value: 28977.05183397755 and parameters: {'n_estimators': 153, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:25,151] Trial 44 finished with value: 29078.55064012307 and parameters: {'n_estimators': 140, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:25,275] Trial 37 finished with value: 28913.30142379878 and parameters: {'n_estimators': 258, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:25,450] Trial 43 finished with value: 28935.01930349546 and parameters: {'n_estimators': 157, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:27,626] Trial 41 finished with value: 29058.05807077107 and parameters: {'n_estimators': 277, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:29,197] Trial 45 finished with value: 29056.303037094654 and parameters: {'n_estimators': 276, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:29,259] Trial 46 finished with value: 29160.530723450738 and parameters: {'n_estimators': 279, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:29,530] Trial 47 finished with value: 29126.740970999905 and parameters: {'n_estimators': 281, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:31,239] Trial 48 finished with value: 28667.721163798873 and parameters: {'n_estimators': 277, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n",
      "[I 2024-06-18 20:55:31,306] Trial 49 finished with value: 28546.425962271027 and parameters: {'n_estimators': 276, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 28390.74542848044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest RMSE: 28390.75\n"
     ]
    }
   ],
   "source": [
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, n_jobs=-1)\n",
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "best_rf = RandomForestRegressor(\n",
    "    n_estimators=best_params_rf['n_estimators'],\n",
    "    max_depth=best_params_rf['max_depth'],\n",
    "    min_samples_split=best_params_rf['min_samples_split'],\n",
    "    min_samples_leaf=best_params_rf['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "rf_rmse = mean_squared_error(y_test, best_rf.predict(X_test), squared=False)\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b88394fd-4654-4364-8733-6b314057f1a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:55:36,861] A new study created in memory with name: no-name-5f1f44e9-975a-4b27-a8c1-3a4a16b31c71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:55:38,523] Trial 5 finished with value: 31492.097725202875 and parameters: {'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 5 with value: 31492.097725202875.\n",
      "[I 2024-06-18 20:55:38,640] Trial 3 finished with value: 31891.583447554138 and parameters: {'n_estimators': 77, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 5 with value: 31492.097725202875.\n",
      "[I 2024-06-18 20:55:39,179] Trial 1 finished with value: 29548.61623143314 and parameters: {'n_estimators': 81, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 29548.61623143314.\n",
      "[I 2024-06-18 20:55:39,339] Trial 4 finished with value: 33693.41586040484 and parameters: {'n_estimators': 151, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 29548.61623143314.\n",
      "[I 2024-06-18 20:55:39,942] Trial 2 finished with value: 30032.696837011106 and parameters: {'n_estimators': 115, 'max_depth': 43, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 1 with value: 29548.61623143314.\n",
      "[I 2024-06-18 20:55:40,342] Trial 6 finished with value: 29739.34700047482 and parameters: {'n_estimators': 132, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 29548.61623143314.\n",
      "[I 2024-06-18 20:55:40,725] Trial 10 finished with value: 30378.74485789164 and parameters: {'n_estimators': 74, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 1 with value: 29548.61623143314.\n",
      "[I 2024-06-18 20:55:41,057] Trial 12 finished with value: 29933.780856667854 and parameters: {'n_estimators': 55, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 1 with value: 29548.61623143314.\n",
      "[I 2024-06-18 20:55:41,982] Trial 7 finished with value: 30369.08344973399 and parameters: {'n_estimators': 228, 'max_depth': 34, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 1 with value: 29548.61623143314.\n",
      "[I 2024-06-18 20:55:42,323] Trial 0 finished with value: 28314.017027199257 and parameters: {'n_estimators': 176, 'max_depth': 45, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:43,286] Trial 9 finished with value: 29344.666606632858 and parameters: {'n_estimators': 213, 'max_depth': 50, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:44,077] Trial 14 finished with value: 30831.401085972917 and parameters: {'n_estimators': 149, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:44,244] Trial 8 finished with value: 29003.65711192576 and parameters: {'n_estimators': 228, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:44,437] Trial 15 finished with value: 30297.540587610256 and parameters: {'n_estimators': 145, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:44,509] Trial 16 finished with value: 29448.05942982912 and parameters: {'n_estimators': 71, 'max_depth': 33, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:45,606] Trial 13 finished with value: 30050.47997871841 and parameters: {'n_estimators': 214, 'max_depth': 45, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:46,101] Trial 11 finished with value: 28846.297011842074 and parameters: {'n_estimators': 240, 'max_depth': 44, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:48,971] Trial 18 finished with value: 29023.318433013184 and parameters: {'n_estimators': 214, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:49,304] Trial 19 finished with value: 29280.23828581913 and parameters: {'n_estimators': 211, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:50,246] Trial 17 finished with value: 29096.60503108917 and parameters: {'n_estimators': 288, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:51,373] Trial 21 finished with value: 29094.88030413953 and parameters: {'n_estimators': 270, 'max_depth': 49, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:51,822] Trial 20 finished with value: 29123.378019367214 and parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:51,959] Trial 22 finished with value: 29125.049063342165 and parameters: {'n_estimators': 286, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:52,827] Trial 23 finished with value: 29090.00274183133 and parameters: {'n_estimators': 281, 'max_depth': 37, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:53,725] Trial 24 finished with value: 29087.04496503442 and parameters: {'n_estimators': 299, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:57,108] Trial 28 finished with value: 28860.59694011422 and parameters: {'n_estimators': 254, 'max_depth': 38, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:57,363] Trial 30 finished with value: 28850.414512855197 and parameters: {'n_estimators': 251, 'max_depth': 37, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:57,495] Trial 25 finished with value: 28456.639830367723 and parameters: {'n_estimators': 283, 'max_depth': 33, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:57,498] Trial 29 finished with value: 28841.018397050637 and parameters: {'n_estimators': 252, 'max_depth': 38, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:58,007] Trial 26 finished with value: 28400.364001171936 and parameters: {'n_estimators': 290, 'max_depth': 33, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:58,125] Trial 31 finished with value: 28844.97746198016 and parameters: {'n_estimators': 249, 'max_depth': 44, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:58,527] Trial 27 finished with value: 28456.15952752044 and parameters: {'n_estimators': 284, 'max_depth': 33, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:55:58,979] Trial 32 finished with value: 28854.053768574926 and parameters: {'n_estimators': 250, 'max_depth': 44, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:00,783] Trial 33 finished with value: 28720.14270666369 and parameters: {'n_estimators': 183, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:01,152] Trial 34 finished with value: 28725.456519009444 and parameters: {'n_estimators': 181, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:01,824] Trial 35 finished with value: 28789.4641719693 and parameters: {'n_estimators': 183, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:02,116] Trial 36 finished with value: 28782.44697852155 and parameters: {'n_estimators': 192, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:02,318] Trial 37 finished with value: 28789.637711077015 and parameters: {'n_estimators': 182, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:02,966] Trial 39 finished with value: 28771.708531692748 and parameters: {'n_estimators': 184, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:03,251] Trial 41 finished with value: 28755.476805118244 and parameters: {'n_estimators': 105, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:03,820] Trial 40 finished with value: 28811.403389296152 and parameters: {'n_estimators': 194, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:05,299] Trial 43 finished with value: 29217.96136130434 and parameters: {'n_estimators': 113, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:05,509] Trial 38 finished with value: 28739.990454778777 and parameters: {'n_estimators': 268, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:05,575] Trial 44 finished with value: 29212.1598050515 and parameters: {'n_estimators': 104, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:05,845] Trial 45 finished with value: 29339.61400262213 and parameters: {'n_estimators': 115, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:06,230] Trial 46 finished with value: 29143.07044314245 and parameters: {'n_estimators': 96, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:08,525] Trial 48 finished with value: 28799.502461501215 and parameters: {'n_estimators': 167, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:08,684] Trial 42 finished with value: 28762.721338270105 and parameters: {'n_estimators': 271, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:09,893] Trial 47 finished with value: 28953.600256469323 and parameters: {'n_estimators': 277, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n",
      "[I 2024-06-18 20:56:10,439] Trial 49 finished with value: 28949.774248098838 and parameters: {'n_estimators': 267, 'max_depth': 33, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 28314.017027199257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest RMSE: 28314.02\n"
     ]
    }
   ],
   "source": [
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, n_jobs=-1)\n",
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "best_rf = RandomForestRegressor(\n",
    "    n_estimators=best_params_rf['n_estimators'],\n",
    "    max_depth=best_params_rf['max_depth'],\n",
    "    min_samples_split=best_params_rf['min_samples_split'],\n",
    "    min_samples_leaf=best_params_rf['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "rf_rmse = mean_squared_error(y_test, best_rf.predict(X_test), squared=False)\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f51608f3-d399-42dd-afcd-537309524835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:56:13,755] A new study created in memory with name: no-name-61345457-54fe-4ca4-8b4b-06e30d0ce650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:56:15,426] Trial 1 finished with value: 27924.631787909704 and parameters: {'n_estimators': 59, 'learning_rate': 0.06003709314881805, 'max_depth': 9, 'subsample': 0.9030725102232159, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 27924.631787909704.\n",
      "[I 2024-06-18 20:56:15,673] Trial 6 finished with value: 26710.30184441344 and parameters: {'n_estimators': 153, 'learning_rate': 0.05785785839584269, 'max_depth': 4, 'subsample': 0.8469130834819931, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 6 with value: 26710.30184441344.\n",
      "[I 2024-06-18 20:56:15,755] Trial 2 finished with value: 48947.080234240464 and parameters: {'n_estimators': 67, 'learning_rate': 0.011799624126393867, 'max_depth': 9, 'subsample': 0.9691784789387252, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 6 with value: 26710.30184441344.\n",
      "[I 2024-06-18 20:56:17,054] Trial 5 finished with value: 26526.38545384522 and parameters: {'n_estimators': 164, 'learning_rate': 0.058024100856168145, 'max_depth': 9, 'subsample': 0.7104875013781292, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 5 with value: 26526.38545384522.\n",
      "[I 2024-06-18 20:56:17,109] Trial 3 finished with value: 30002.701885784052 and parameters: {'n_estimators': 233, 'learning_rate': 0.010107279270794425, 'max_depth': 5, 'subsample': 0.8897620564855558, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 5 with value: 26526.38545384522.\n",
      "[I 2024-06-18 20:56:17,631] Trial 9 finished with value: 27928.33476298249 and parameters: {'n_estimators': 159, 'learning_rate': 0.017265341937809306, 'max_depth': 6, 'subsample': 0.7211208416973862, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 5 with value: 26526.38545384522.\n",
      "[I 2024-06-18 20:56:17,691] Trial 7 finished with value: 30473.302813492493 and parameters: {'n_estimators': 206, 'learning_rate': 0.010331222537850003, 'max_depth': 7, 'subsample': 0.8616538797133189, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 5 with value: 26526.38545384522.\n",
      "[I 2024-06-18 20:56:17,940] Trial 8 finished with value: 27433.753827605677 and parameters: {'n_estimators': 117, 'learning_rate': 0.06760620580557415, 'max_depth': 9, 'subsample': 0.8384734169499274, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 5 with value: 26526.38545384522.\n",
      "[I 2024-06-18 20:56:18,293] Trial 11 finished with value: 25654.000902194337 and parameters: {'n_estimators': 115, 'learning_rate': 0.08406393095057564, 'max_depth': 4, 'subsample': 0.8083942846168111, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 11 with value: 25654.000902194337.\n",
      "[I 2024-06-18 20:56:19,282] Trial 15 finished with value: 26709.489912535642 and parameters: {'n_estimators': 82, 'learning_rate': 0.04764165671042596, 'max_depth': 7, 'subsample': 0.845356465223128, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 11 with value: 25654.000902194337.\n",
      "[I 2024-06-18 20:56:19,315] Trial 4 finished with value: 25328.16810256572 and parameters: {'n_estimators': 257, 'learning_rate': 0.056140105544712555, 'max_depth': 8, 'subsample': 0.9098454681235447, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 4 with value: 25328.16810256572.\n",
      "[I 2024-06-18 20:56:19,394] Trial 13 finished with value: 26350.629818943093 and parameters: {'n_estimators': 106, 'learning_rate': 0.06363225142732024, 'max_depth': 6, 'subsample': 0.9956379710175802, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 4 with value: 25328.16810256572.\n",
      "[I 2024-06-18 20:56:19,835] Trial 12 finished with value: 27845.168738168377 and parameters: {'n_estimators': 149, 'learning_rate': 0.0203841129009994, 'max_depth': 8, 'subsample': 0.8110738219912197, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 4 with value: 25328.16810256572.\n",
      "[I 2024-06-18 20:56:20,146] Trial 14 finished with value: 26274.4589379391 and parameters: {'n_estimators': 296, 'learning_rate': 0.08325416063994892, 'max_depth': 3, 'subsample': 0.8503915396827475, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 4 with value: 25328.16810256572.\n",
      "[I 2024-06-18 20:56:20,643] Trial 0 finished with value: 28948.07644204963 and parameters: {'n_estimators': 255, 'learning_rate': 0.07229657901375676, 'max_depth': 10, 'subsample': 0.9803291161258596, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 4 with value: 25328.16810256572.\n",
      "[I 2024-06-18 20:56:20,952] Trial 10 finished with value: 26483.076138897548 and parameters: {'n_estimators': 289, 'learning_rate': 0.05008943937256177, 'max_depth': 8, 'subsample': 0.7963896864640942, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 4 with value: 25328.16810256572.\n",
      "[I 2024-06-18 20:56:21,477] Trial 18 finished with value: 25530.6726243308 and parameters: {'n_estimators': 261, 'learning_rate': 0.03264444614309614, 'max_depth': 3, 'subsample': 0.7779733793071836, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 4 with value: 25328.16810256572.\n",
      "[I 2024-06-18 20:56:21,732] Trial 17 finished with value: 24550.776465831896 and parameters: {'n_estimators': 297, 'learning_rate': 0.09260570704325159, 'max_depth': 3, 'subsample': 0.7784183566244233, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 17 with value: 24550.776465831896.\n",
      "[I 2024-06-18 20:56:21,882] Trial 19 finished with value: 24433.908050833244 and parameters: {'n_estimators': 300, 'learning_rate': 0.097198354697278, 'max_depth': 3, 'subsample': 0.7780800517821487, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:22,164] Trial 20 finished with value: 25070.75942942303 and parameters: {'n_estimators': 286, 'learning_rate': 0.09770113164980314, 'max_depth': 3, 'subsample': 0.7833574973267744, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:22,362] Trial 21 finished with value: 26363.984004574057 and parameters: {'n_estimators': 280, 'learning_rate': 0.09651226330523155, 'max_depth': 3, 'subsample': 0.7864454791225182, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:22,648] Trial 16 finished with value: 25252.842031658343 and parameters: {'n_estimators': 293, 'learning_rate': 0.054873333201424505, 'max_depth': 6, 'subsample': 0.8969834779038959, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:22,721] Trial 23 finished with value: 26204.633651844124 and parameters: {'n_estimators': 197, 'learning_rate': 0.09976311228925253, 'max_depth': 3, 'subsample': 0.9314391990770202, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:23,048] Trial 22 finished with value: 26966.322678857017 and parameters: {'n_estimators': 294, 'learning_rate': 0.03589528572745994, 'max_depth': 3, 'subsample': 0.7774555455483307, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:23,586] Trial 24 finished with value: 25444.336687661296 and parameters: {'n_estimators': 254, 'learning_rate': 0.03474421634273426, 'max_depth': 3, 'subsample': 0.763416577737084, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:24,027] Trial 26 finished with value: 25390.83450575977 and parameters: {'n_estimators': 206, 'learning_rate': 0.09951363804015703, 'max_depth': 4, 'subsample': 0.7579560984347027, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:24,296] Trial 27 finished with value: 24980.735474169036 and parameters: {'n_estimators': 212, 'learning_rate': 0.03425802828224108, 'max_depth': 4, 'subsample': 0.7498520518252636, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:24,564] Trial 25 finished with value: 25351.31435061016 and parameters: {'n_estimators': 209, 'learning_rate': 0.09653476599240332, 'max_depth': 5, 'subsample': 0.9228449440369298, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 19 with value: 24433.908050833244.\n",
      "[I 2024-06-18 20:56:24,622] Trial 28 finished with value: 23709.240126896846 and parameters: {'n_estimators': 222, 'learning_rate': 0.09546056087135882, 'max_depth': 4, 'subsample': 0.7474174172667248, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:25,053] Trial 30 finished with value: 24118.12557596973 and parameters: {'n_estimators': 232, 'learning_rate': 0.04034185671763017, 'max_depth': 4, 'subsample': 0.7445885641523012, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:25,196] Trial 29 finished with value: 24950.13347035831 and parameters: {'n_estimators': 227, 'learning_rate': 0.03872463733024316, 'max_depth': 4, 'subsample': 0.7519738492183545, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:25,532] Trial 31 finished with value: 24200.558401189835 and parameters: {'n_estimators': 237, 'learning_rate': 0.04315919813936201, 'max_depth': 4, 'subsample': 0.7437467257342576, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:25,959] Trial 32 finished with value: 24753.26148587005 and parameters: {'n_estimators': 229, 'learning_rate': 0.042055224284117794, 'max_depth': 4, 'subsample': 0.7380126991480093, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:26,657] Trial 33 finished with value: 24978.817323828607 and parameters: {'n_estimators': 227, 'learning_rate': 0.0774816086462925, 'max_depth': 5, 'subsample': 0.7397027927992957, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:26,853] Trial 34 finished with value: 25150.32951736664 and parameters: {'n_estimators': 220, 'learning_rate': 0.023178501502561, 'max_depth': 5, 'subsample': 0.7438119757505479, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:27,274] Trial 35 finished with value: 25379.331526158112 and parameters: {'n_estimators': 231, 'learning_rate': 0.022788953602071844, 'max_depth': 5, 'subsample': 0.7418013258758711, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:27,276] Trial 36 finished with value: 24156.718632847045 and parameters: {'n_estimators': 233, 'learning_rate': 0.07533645856361107, 'max_depth': 5, 'subsample': 0.7333161585988716, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:27,574] Trial 37 finished with value: 25111.144159558644 and parameters: {'n_estimators': 235, 'learning_rate': 0.04296694548969679, 'max_depth': 5, 'subsample': 0.7278221155769441, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:27,971] Trial 40 finished with value: 25333.41072637825 and parameters: {'n_estimators': 186, 'learning_rate': 0.02748693294549115, 'max_depth': 5, 'subsample': 0.7318899206385622, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:28,061] Trial 39 finished with value: 25583.08898875919 and parameters: {'n_estimators': 235, 'learning_rate': 0.026149903562239462, 'max_depth': 5, 'subsample': 0.7343519516046761, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:28,115] Trial 38 finished with value: 25374.614307044467 and parameters: {'n_estimators': 268, 'learning_rate': 0.07411400566828802, 'max_depth': 5, 'subsample': 0.7307084438297572, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:28,608] Trial 41 finished with value: 25592.525698243415 and parameters: {'n_estimators': 189, 'learning_rate': 0.024404864462744983, 'max_depth': 5, 'subsample': 0.702325979871528, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:28,817] Trial 42 finished with value: 25714.920445618016 and parameters: {'n_estimators': 190, 'learning_rate': 0.02550305346571928, 'max_depth': 5, 'subsample': 0.7221922119828746, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:29,191] Trial 45 finished with value: 25929.172462355804 and parameters: {'n_estimators': 184, 'learning_rate': 0.02611961672630078, 'max_depth': 4, 'subsample': 0.7118769929675188, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:29,193] Trial 43 finished with value: 25296.570863811638 and parameters: {'n_estimators': 185, 'learning_rate': 0.027504028363078498, 'max_depth': 5, 'subsample': 0.7067264827316614, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:29,209] Trial 44 finished with value: 24458.070504082043 and parameters: {'n_estimators': 185, 'learning_rate': 0.043947365601122966, 'max_depth': 5, 'subsample': 0.7079477555297095, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:29,758] Trial 46 finished with value: 25259.024946544094 and parameters: {'n_estimators': 243, 'learning_rate': 0.07293934399276211, 'max_depth': 4, 'subsample': 0.7005129597179524, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:29,905] Trial 48 finished with value: 26043.65793488092 and parameters: {'n_estimators': 247, 'learning_rate': 0.06938868135827156, 'max_depth': 4, 'subsample': 0.7004021483623996, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:29,996] Trial 47 finished with value: 25185.76244980666 and parameters: {'n_estimators': 268, 'learning_rate': 0.06661346278753771, 'max_depth': 4, 'subsample': 0.7026023655939173, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n",
      "[I 2024-06-18 20:56:30,207] Trial 49 finished with value: 26054.919358305404 and parameters: {'n_estimators': 249, 'learning_rate': 0.06956601413190983, 'max_depth': 4, 'subsample': 0.7182151446182563, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 28 with value: 23709.240126896846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 23709.24\n"
     ]
    }
   ],
   "source": [
    "def objective_gb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.7, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_gb = optuna.create_study(direction='minimize')\n",
    "study_gb.optimize(objective_gb, n_trials=50, n_jobs=-1)\n",
    "best_params_gb = study_gb.best_params\n",
    "\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    n_estimators=best_params_gb['n_estimators'],\n",
    "    learning_rate=best_params_gb['learning_rate'],\n",
    "    max_depth=best_params_gb['max_depth'],\n",
    "    subsample=best_params_gb['subsample'],\n",
    "    min_samples_split=best_params_gb['min_samples_split'],\n",
    "    min_samples_leaf=best_params_gb['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_gb.fit(X_train, y_train)\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "553b039b-ca10-4123-9482-c60374da8fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:56:31,395] A new study created in memory with name: no-name-58216d7f-2e4e-4c55-b253-9df3d03daceb\n",
      "[I 2024-06-18 20:56:32,881] Trial 4 finished with value: 32733.578440262143 and parameters: {'n_estimators': 137, 'learning_rate': 0.01405064267357732, 'max_depth': 5, 'subsample': 0.8058331082049244, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 4 with value: 32733.578440262143.\n",
      "[I 2024-06-18 20:56:33,260] Trial 1 finished with value: 29092.411939777758 and parameters: {'n_estimators': 265, 'learning_rate': 0.013660150118139446, 'max_depth': 3, 'subsample': 0.7498589867439706, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 29092.411939777758.\n",
      "[I 2024-06-18 20:56:33,869] Trial 7 finished with value: 26883.4615991445 and parameters: {'n_estimators': 167, 'learning_rate': 0.09098905971921131, 'max_depth': 6, 'subsample': 0.9164776488947898, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 26883.4615991445.\n",
      "[I 2024-06-18 20:56:34,126] Trial 3 finished with value: 31686.088614364733 and parameters: {'n_estimators': 114, 'learning_rate': 0.01643619583598121, 'max_depth': 10, 'subsample': 0.9717458718422257, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 26883.4615991445.\n",
      "[I 2024-06-18 20:56:35,677] Trial 5 finished with value: 26659.236300010274 and parameters: {'n_estimators': 266, 'learning_rate': 0.017333321670793236, 'max_depth': 7, 'subsample': 0.9120745070429157, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 5 with value: 26659.236300010274.\n",
      "[I 2024-06-18 20:56:36,367] Trial 2 finished with value: 26754.52695009885 and parameters: {'n_estimators': 473, 'learning_rate': 0.010438921298899832, 'max_depth': 4, 'subsample': 0.9503572216283241, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 5 with value: 26659.236300010274.\n",
      "[I 2024-06-18 20:56:36,702] Trial 10 finished with value: 25191.73798772822 and parameters: {'n_estimators': 256, 'learning_rate': 0.023580135731820478, 'max_depth': 5, 'subsample': 0.7648840419414336, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 10 with value: 25191.73798772822.\n",
      "[I 2024-06-18 20:56:37,634] Trial 0 finished with value: 25562.092382897692 and parameters: {'n_estimators': 440, 'learning_rate': 0.038684592950882495, 'max_depth': 7, 'subsample': 0.737327876230639, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 10 with value: 25191.73798772822.\n",
      "[I 2024-06-18 20:56:41,319] Trial 13 finished with value: 25185.52792148172 and parameters: {'n_estimators': 434, 'learning_rate': 0.020133574450117923, 'max_depth': 4, 'subsample': 0.804425125295868, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:42,996] Trial 12 finished with value: 26319.8477921179 and parameters: {'n_estimators': 354, 'learning_rate': 0.05607905799964771, 'max_depth': 9, 'subsample': 0.7360837175766765, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:44,116] Trial 11 finished with value: 26823.7430682804 and parameters: {'n_estimators': 586, 'learning_rate': 0.06518826777252452, 'max_depth': 6, 'subsample': 0.9387330565804985, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:46,447] Trial 6 finished with value: 28886.16965991526 and parameters: {'n_estimators': 542, 'learning_rate': 0.027820352475489193, 'max_depth': 10, 'subsample': 0.9821489555857923, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:46,746] Trial 8 finished with value: 25667.87549731659 and parameters: {'n_estimators': 718, 'learning_rate': 0.041695033972691725, 'max_depth': 7, 'subsample': 0.9702350460432878, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:47,042] Trial 16 finished with value: 26206.126229343474 and parameters: {'n_estimators': 501, 'learning_rate': 0.010510413752410974, 'max_depth': 4, 'subsample': 0.9628479900120651, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:48,722] Trial 17 finished with value: 25738.41579859245 and parameters: {'n_estimators': 724, 'learning_rate': 0.028864950112311206, 'max_depth': 3, 'subsample': 0.8457938658947137, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:48,994] Trial 14 finished with value: 26399.294950101703 and parameters: {'n_estimators': 762, 'learning_rate': 0.06388562916200492, 'max_depth': 7, 'subsample': 0.8045564641677903, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:49,364] Trial 20 finished with value: 26267.070337486264 and parameters: {'n_estimators': 326, 'learning_rate': 0.025396337077729793, 'max_depth': 3, 'subsample': 0.8188354869888537, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:49,611] Trial 21 finished with value: 26108.891033096537 and parameters: {'n_estimators': 325, 'learning_rate': 0.02267760808216251, 'max_depth': 3, 'subsample': 0.80619699151093, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:50,045] Trial 24 finished with value: 41801.33526006792 and parameters: {'n_estimators': 60, 'learning_rate': 0.0205538419402655, 'max_depth': 5, 'subsample': 0.7723713308996191, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:50,336] Trial 18 finished with value: 25397.90793107698 and parameters: {'n_estimators': 790, 'learning_rate': 0.02702935064629343, 'max_depth': 3, 'subsample': 0.8214386660414342, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:51,744] Trial 15 finished with value: 27270.003773785433 and parameters: {'n_estimators': 688, 'learning_rate': 0.09227251386215704, 'max_depth': 8, 'subsample': 0.9207899717121046, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:51,795] Trial 19 finished with value: 25354.951014545262 and parameters: {'n_estimators': 686, 'learning_rate': 0.026221655007664713, 'max_depth': 3, 'subsample': 0.8205063350010603, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:51,889] Trial 9 finished with value: 26482.70255984729 and parameters: {'n_estimators': 744, 'learning_rate': 0.06033414243906018, 'max_depth': 10, 'subsample': 0.9408469695118884, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:52,951] Trial 22 finished with value: 25494.900270543116 and parameters: {'n_estimators': 359, 'learning_rate': 0.02204111115948163, 'max_depth': 5, 'subsample': 0.7999562055903994, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 13 with value: 25185.52792148172.\n",
      "[I 2024-06-18 20:56:53,158] Trial 23 finished with value: 24890.363087599046 and parameters: {'n_estimators': 343, 'learning_rate': 0.022222365326144796, 'max_depth': 5, 'subsample': 0.7792281447104213, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 23 with value: 24890.363087599046.\n",
      "[I 2024-06-18 20:56:55,167] Trial 32 finished with value: 24658.79403742714 and parameters: {'n_estimators': 230, 'learning_rate': 0.03402593786578127, 'max_depth': 4, 'subsample': 0.7091180661188508, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 32 with value: 24658.79403742714.\n",
      "[I 2024-06-18 20:56:56,454] Trial 25 finished with value: 24633.597690893006 and parameters: {'n_estimators': 624, 'learning_rate': 0.021357027142043784, 'max_depth': 5, 'subsample': 0.7036208453182698, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 25 with value: 24633.597690893006.\n",
      "[I 2024-06-18 20:56:56,893] Trial 27 finished with value: 24032.392330026818 and parameters: {'n_estimators': 605, 'learning_rate': 0.03392561299615333, 'max_depth': 5, 'subsample': 0.7124063560550334, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:56:56,974] Trial 33 finished with value: 24868.375708647698 and parameters: {'n_estimators': 208, 'learning_rate': 0.03590372269624851, 'max_depth': 4, 'subsample': 0.7033535015316517, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:56:57,164] Trial 26 finished with value: 24707.58589431839 and parameters: {'n_estimators': 652, 'learning_rate': 0.03772038518709068, 'max_depth': 5, 'subsample': 0.7039838157005434, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:56:57,682] Trial 28 finished with value: 25249.855110536504 and parameters: {'n_estimators': 636, 'learning_rate': 0.03517007907609511, 'max_depth': 4, 'subsample': 0.7028966222754669, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:56:58,472] Trial 29 finished with value: 25090.201372970012 and parameters: {'n_estimators': 621, 'learning_rate': 0.033663667354804236, 'max_depth': 4, 'subsample': 0.8646976965868255, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:56:58,810] Trial 30 finished with value: 25448.56629898407 and parameters: {'n_estimators': 656, 'learning_rate': 0.03789543247879566, 'max_depth': 4, 'subsample': 0.8699773642745181, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:56:59,491] Trial 31 finished with value: 25218.95455395727 and parameters: {'n_estimators': 629, 'learning_rate': 0.03509184900926311, 'max_depth': 4, 'subsample': 0.8632579511163921, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:03,704] Trial 34 finished with value: 24834.79124600944 and parameters: {'n_estimators': 607, 'learning_rate': 0.03634891564034775, 'max_depth': 6, 'subsample': 0.7018657092828235, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:04,642] Trial 36 finished with value: 24750.920149643138 and parameters: {'n_estimators': 631, 'learning_rate': 0.04346633969669964, 'max_depth': 6, 'subsample': 0.7008928277396531, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:04,717] Trial 37 finished with value: 24964.106056906494 and parameters: {'n_estimators': 614, 'learning_rate': 0.04540902469309183, 'max_depth': 6, 'subsample': 0.7261686694981291, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:04,917] Trial 35 finished with value: 24959.404010478695 and parameters: {'n_estimators': 648, 'learning_rate': 0.03481174615391727, 'max_depth': 6, 'subsample': 0.7037197680307414, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:05,194] Trial 38 finished with value: 24771.61824677094 and parameters: {'n_estimators': 599, 'learning_rate': 0.0397481248736069, 'max_depth': 6, 'subsample': 0.7262990248580518, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:05,543] Trial 39 finished with value: 24693.999808255416 and parameters: {'n_estimators': 554, 'learning_rate': 0.04384461897361341, 'max_depth': 6, 'subsample': 0.7262340839884758, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:05,841] Trial 40 finished with value: 25317.89452738843 and parameters: {'n_estimators': 558, 'learning_rate': 0.051068165829353904, 'max_depth': 6, 'subsample': 0.7269342550936931, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:06,031] Trial 41 finished with value: 24803.34780843085 and parameters: {'n_estimators': 532, 'learning_rate': 0.043889190680083325, 'max_depth': 6, 'subsample': 0.7305099300098861, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:10,370] Trial 49 finished with value: 25030.435654745237 and parameters: {'n_estimators': 392, 'learning_rate': 0.030398026020554733, 'max_depth': 5, 'subsample': 0.7499936024642191, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:10,414] Trial 43 finished with value: 24981.306120804104 and parameters: {'n_estimators': 517, 'learning_rate': 0.016577312850071347, 'max_depth': 5, 'subsample': 0.7250547413769443, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:10,713] Trial 42 finished with value: 25161.12763264181 and parameters: {'n_estimators': 554, 'learning_rate': 0.04487950342412537, 'max_depth': 6, 'subsample': 0.7299328743650298, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:10,790] Trial 45 finished with value: 24907.985888470954 and parameters: {'n_estimators': 533, 'learning_rate': 0.05028584591472049, 'max_depth': 5, 'subsample': 0.7242934889367546, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:10,800] Trial 44 finished with value: 24874.152621878366 and parameters: {'n_estimators': 566, 'learning_rate': 0.05053456206428919, 'max_depth': 5, 'subsample': 0.7245001883410868, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:11,113] Trial 46 finished with value: 24263.059755653027 and parameters: {'n_estimators': 551, 'learning_rate': 0.049091223138762644, 'max_depth': 5, 'subsample': 0.7477070226683886, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:11,276] Trial 48 finished with value: 24864.413386029464 and parameters: {'n_estimators': 493, 'learning_rate': 0.048531142615300615, 'max_depth': 5, 'subsample': 0.7526795243606516, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n",
      "[I 2024-06-18 20:57:11,295] Trial 47 finished with value: 24083.572421745677 and parameters: {'n_estimators': 540, 'learning_rate': 0.04818891154711021, 'max_depth': 5, 'subsample': 0.7444178876260823, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 27 with value: 24032.392330026818.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 24032.39\n"
     ]
    }
   ],
   "source": [
    "def objective_gb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 800)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.7, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_gb = optuna.create_study(direction='minimize')\n",
    "study_gb.optimize(objective_gb, n_trials=50, n_jobs=-1)\n",
    "best_params_gb = study_gb.best_params\n",
    "\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    n_estimators=best_params_gb['n_estimators'],\n",
    "    learning_rate=best_params_gb['learning_rate'],\n",
    "    max_depth=best_params_gb['max_depth'],\n",
    "    subsample=best_params_gb['subsample'],\n",
    "    min_samples_split=best_params_gb['min_samples_split'],\n",
    "    min_samples_leaf=best_params_gb['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_gb.fit(X_train, y_train)\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82d37fe9-4741-4a93-9cb3-5c44c7ef8fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 20:57:15,259] A new study created in memory with name: no-name-6277ad67-6436-490e-8e4f-bbc3c60a8b2e\n",
      "[I 2024-06-18 20:57:16,324] Trial 0 finished with value: 27104.0078125 and parameters: {'n_estimators': 93, 'learning_rate': 0.09448812676075298, 'max_depth': 3, 'subsample': 0.994293259288344, 'colsample_bytree': 0.8909285122708718}. Best is trial 0 with value: 27104.0078125.\n",
      "[I 2024-06-18 20:57:17,469] Trial 3 finished with value: 26736.0078125 and parameters: {'n_estimators': 98, 'learning_rate': 0.04628907011407666, 'max_depth': 8, 'subsample': 0.7738181919087406, 'colsample_bytree': 0.913234529796185}. Best is trial 3 with value: 26736.0078125.\n",
      "[I 2024-06-18 20:57:17,680] Trial 8 finished with value: 41804.484375 and parameters: {'n_estimators': 120, 'learning_rate': 0.011463339469293794, 'max_depth': 4, 'subsample': 0.9622196308155149, 'colsample_bytree': 0.8949784454743753}. Best is trial 3 with value: 26736.0078125.\n",
      "[I 2024-06-18 20:57:18,261] Trial 5 finished with value: 25703.5625 and parameters: {'n_estimators': 135, 'learning_rate': 0.046420806611414525, 'max_depth': 8, 'subsample': 0.9599255129847977, 'colsample_bytree': 0.7007845188368352}. Best is trial 5 with value: 25703.5625.\n",
      "[I 2024-06-18 20:57:18,316] Trial 2 finished with value: 26352.861328125 and parameters: {'n_estimators': 136, 'learning_rate': 0.04066375905364729, 'max_depth': 8, 'subsample': 0.867485623562471, 'colsample_bytree': 0.9137271228048053}. Best is trial 5 with value: 25703.5625.\n",
      "[I 2024-06-18 20:57:18,445] Trial 1 finished with value: 25742.078125 and parameters: {'n_estimators': 264, 'learning_rate': 0.04465207704180287, 'max_depth': 4, 'subsample': 0.8499668382961982, 'colsample_bytree': 0.711516730211203}. Best is trial 5 with value: 25703.5625.\n",
      "[I 2024-06-18 20:57:19,048] Trial 7 finished with value: 25487.841796875 and parameters: {'n_estimators': 194, 'learning_rate': 0.033322727255086344, 'max_depth': 7, 'subsample': 0.7758396541795551, 'colsample_bytree': 0.856989055851428}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:19,192] Trial 13 finished with value: 26637.125 and parameters: {'n_estimators': 50, 'learning_rate': 0.08315952062500458, 'max_depth': 5, 'subsample': 0.9229992161117901, 'colsample_bytree': 0.7339697049444525}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:19,950] Trial 11 finished with value: 26433.294921875 and parameters: {'n_estimators': 178, 'learning_rate': 0.07612687748843067, 'max_depth': 3, 'subsample': 0.8855729186892312, 'colsample_bytree': 0.8719796121887377}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:20,704] Trial 10 finished with value: 25971.0078125 and parameters: {'n_estimators': 223, 'learning_rate': 0.026318476575895266, 'max_depth': 5, 'subsample': 0.7205995203624694, 'colsample_bytree': 0.912382252717161}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:21,353] Trial 16 finished with value: 26430.103515625 and parameters: {'n_estimators': 163, 'learning_rate': 0.04801157698652228, 'max_depth': 3, 'subsample': 0.7673100857489894, 'colsample_bytree': 0.9675520524517263}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:22,239] Trial 6 finished with value: 25517.814453125 and parameters: {'n_estimators': 292, 'learning_rate': 0.09002319795579287, 'max_depth': 9, 'subsample': 0.8937906077693365, 'colsample_bytree': 0.749686427444154}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:22,848] Trial 4 finished with value: 27651.60546875 and parameters: {'n_estimators': 280, 'learning_rate': 0.012498101588571332, 'max_depth': 10, 'subsample': 0.7694911643182011, 'colsample_bytree': 0.8370390810971635}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:23,310] Trial 9 finished with value: 27205.435546875 and parameters: {'n_estimators': 214, 'learning_rate': 0.02233783812371231, 'max_depth': 10, 'subsample': 0.8918969954602619, 'colsample_bytree': 0.8855048491818196}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:24,201] Trial 12 finished with value: 26427.91796875 and parameters: {'n_estimators': 290, 'learning_rate': 0.01702637120621481, 'max_depth': 7, 'subsample': 0.8579449812109732, 'colsample_bytree': 0.9502243787564024}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:24,451] Trial 15 finished with value: 25887.435546875 and parameters: {'n_estimators': 254, 'learning_rate': 0.018098573115497875, 'max_depth': 7, 'subsample': 0.7012233509438929, 'colsample_bytree': 0.8085743725259092}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:28,315] Trial 17 finished with value: 26466.51953125 and parameters: {'n_estimators': 202, 'learning_rate': 0.02137904312998695, 'max_depth': 10, 'subsample': 0.7805915399278882, 'colsample_bytree': 0.9990370835138744}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:28,835] Trial 14 finished with value: 25521.939453125 and parameters: {'n_estimators': 297, 'learning_rate': 0.06303483494143995, 'max_depth': 10, 'subsample': 0.756324599521307, 'colsample_bytree': 0.9106552156844681}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:28,981] Trial 18 finished with value: 26585.01171875 and parameters: {'n_estimators': 205, 'learning_rate': 0.023504747557198894, 'max_depth': 10, 'subsample': 0.808496266628489, 'colsample_bytree': 0.8003321908151177}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:31,350] Trial 21 finished with value: 26558.173828125 and parameters: {'n_estimators': 235, 'learning_rate': 0.018558263090187467, 'max_depth': 9, 'subsample': 0.8186898681774799, 'colsample_bytree': 0.7898642085608208}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:31,471] Trial 20 finished with value: 26287.771484375 and parameters: {'n_estimators': 230, 'learning_rate': 0.020838209861350137, 'max_depth': 10, 'subsample': 0.810693785980892, 'colsample_bytree': 0.7926714005282431}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:31,473] Trial 22 finished with value: 25863.26953125 and parameters: {'n_estimators': 213, 'learning_rate': 0.07024016665016489, 'max_depth': 9, 'subsample': 0.8158177365547333, 'colsample_bytree': 0.808646249006048}. Best is trial 7 with value: 25487.841796875.\n",
      "[I 2024-06-18 20:57:32,124] Trial 23 finished with value: 25060.306640625 and parameters: {'n_estimators': 227, 'learning_rate': 0.06447089642653937, 'max_depth': 9, 'subsample': 0.8066142143087918, 'colsample_bytree': 0.7854514292613954}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:34,755] Trial 19 finished with value: 25877.365234375 and parameters: {'n_estimators': 299, 'learning_rate': 0.021981771184138757, 'max_depth': 10, 'subsample': 0.8133991612414837, 'colsample_bytree': 0.7927186519222563}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:36,064] Trial 27 finished with value: 25673.43359375 and parameters: {'n_estimators': 176, 'learning_rate': 0.03341139814926713, 'max_depth': 6, 'subsample': 0.8225535436688927, 'colsample_bytree': 0.7602856803521398}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:36,403] Trial 24 finished with value: 25545.95703125 and parameters: {'n_estimators': 243, 'learning_rate': 0.06680470410925445, 'max_depth': 9, 'subsample': 0.8084713107444921, 'colsample_bytree': 0.7737174766810828}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:36,608] Trial 25 finished with value: 26164.259765625 and parameters: {'n_estimators': 234, 'learning_rate': 0.03155647984971869, 'max_depth': 9, 'subsample': 0.8316829804795772, 'colsample_bytree': 0.7693461696884618}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:36,874] Trial 26 finished with value: 26483.587890625 and parameters: {'n_estimators': 247, 'learning_rate': 0.03239598460785853, 'max_depth': 9, 'subsample': 0.8152181798019548, 'colsample_bytree': 0.7579743926350547}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:37,204] Trial 31 finished with value: 25263.33984375 and parameters: {'n_estimators': 187, 'learning_rate': 0.05846973045809496, 'max_depth': 6, 'subsample': 0.7415681336967251, 'colsample_bytree': 0.7516021519239643}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:37,431] Trial 30 finished with value: 25735.49609375 and parameters: {'n_estimators': 178, 'learning_rate': 0.03329252351517194, 'max_depth': 9, 'subsample': 0.7404076624232041, 'colsample_bytree': 0.7556768926478319}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:39,024] Trial 29 finished with value: 25329.494140625 and parameters: {'n_estimators': 293, 'learning_rate': 0.06115030734510631, 'max_depth': 9, 'subsample': 0.7336575199866502, 'colsample_bytree': 0.8486469259406324}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:39,070] Trial 28 finished with value: 26038.109375 and parameters: {'n_estimators': 292, 'learning_rate': 0.06363236975991274, 'max_depth': 9, 'subsample': 0.7353169246600701, 'colsample_bytree': 0.8545305584716555}. Best is trial 23 with value: 25060.306640625.\n",
      "[I 2024-06-18 20:57:39,478] Trial 36 finished with value: 24668.6484375 and parameters: {'n_estimators': 189, 'learning_rate': 0.054969104065756065, 'max_depth': 6, 'subsample': 0.7375530757685231, 'colsample_bytree': 0.8338929659308881}. Best is trial 36 with value: 24668.6484375.\n",
      "[I 2024-06-18 20:57:39,859] Trial 37 finished with value: 25146.408203125 and parameters: {'n_estimators': 195, 'learning_rate': 0.05846379809063256, 'max_depth': 6, 'subsample': 0.7418024012113982, 'colsample_bytree': 0.8333854606704071}. Best is trial 36 with value: 24668.6484375.\n",
      "[I 2024-06-18 20:57:40,148] Trial 33 finished with value: 24277.322265625 and parameters: {'n_estimators': 262, 'learning_rate': 0.05699590434189139, 'max_depth': 7, 'subsample': 0.7408521157921967, 'colsample_bytree': 0.7444217679662507}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:40,330] Trial 34 finished with value: 25505.083984375 and parameters: {'n_estimators': 263, 'learning_rate': 0.054765765268894116, 'max_depth': 7, 'subsample': 0.7363453792608128, 'colsample_bytree': 0.836189391639618}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:40,635] Trial 32 finished with value: 25189.88671875 and parameters: {'n_estimators': 254, 'learning_rate': 0.05888558241509097, 'max_depth': 9, 'subsample': 0.7398859167792556, 'colsample_bytree': 0.7522005849381516}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:40,716] Trial 35 finished with value: 26294.544921875 and parameters: {'n_estimators': 272, 'learning_rate': 0.09951649182472665, 'max_depth': 7, 'subsample': 0.748690136163992, 'colsample_bytree': 0.840134052448313}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:41,003] Trial 38 finished with value: 24886.984375 and parameters: {'n_estimators': 152, 'learning_rate': 0.05619929088641642, 'max_depth': 6, 'subsample': 0.7383317789769728, 'colsample_bytree': 0.8435129595141254}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:41,446] Trial 40 finished with value: 25166.611328125 and parameters: {'n_estimators': 156, 'learning_rate': 0.0525665610632071, 'max_depth': 6, 'subsample': 0.7120976980077522, 'colsample_bytree': 0.8292062811016184}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:41,499] Trial 39 finished with value: 25364.396484375 and parameters: {'n_estimators': 192, 'learning_rate': 0.05575309978131751, 'max_depth': 6, 'subsample': 0.7003786089158588, 'colsample_bytree': 0.829404097210474}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:41,744] Trial 41 finished with value: 24913.97265625 and parameters: {'n_estimators': 160, 'learning_rate': 0.053149410231744285, 'max_depth': 6, 'subsample': 0.7003763561084078, 'colsample_bytree': 0.7292064774688823}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,131] Trial 43 finished with value: 25230.248046875 and parameters: {'n_estimators': 157, 'learning_rate': 0.040059967379917856, 'max_depth': 6, 'subsample': 0.7007200676526524, 'colsample_bytree': 0.8326220000367138}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,262] Trial 46 finished with value: 25911.923828125 and parameters: {'n_estimators': 135, 'learning_rate': 0.04098930452848274, 'max_depth': 5, 'subsample': 0.7047024717882685, 'colsample_bytree': 0.7209927895136514}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,337] Trial 44 finished with value: 25346.595703125 and parameters: {'n_estimators': 156, 'learning_rate': 0.039646229944177956, 'max_depth': 6, 'subsample': 0.7027100918929674, 'colsample_bytree': 0.7227810205693261}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,375] Trial 45 finished with value: 25644.099609375 and parameters: {'n_estimators': 154, 'learning_rate': 0.041611901702531505, 'max_depth': 6, 'subsample': 0.7889084750877375, 'colsample_bytree': 0.8235840232130235}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,604] Trial 47 finished with value: 25682.318359375 and parameters: {'n_estimators': 153, 'learning_rate': 0.03826356688361335, 'max_depth': 5, 'subsample': 0.784381329997893, 'colsample_bytree': 0.7194143435242447}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,616] Trial 48 finished with value: 25801.150390625 and parameters: {'n_estimators': 149, 'learning_rate': 0.03844132806560759, 'max_depth': 5, 'subsample': 0.7926786007955439, 'colsample_bytree': 0.7232473301646187}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,690] Trial 49 finished with value: 25424.0234375 and parameters: {'n_estimators': 150, 'learning_rate': 0.04081854301672385, 'max_depth': 5, 'subsample': 0.7906623306868994, 'colsample_bytree': 0.7305417913797295}. Best is trial 33 with value: 24277.322265625.\n",
      "[I 2024-06-18 20:57:42,713] Trial 42 finished with value: 25631.62109375 and parameters: {'n_estimators': 267, 'learning_rate': 0.05338547493070365, 'max_depth': 6, 'subsample': 0.7071184096443064, 'colsample_bytree': 0.8299575171916027}. Best is trial 33 with value: 24277.322265625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost RMSE: 24277.32\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.7, 1.0)\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.7, 1.0)\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    return rmse\n",
    "\n",
    "study_xgb = optuna.create_study(direction='minimize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, n_jobs=-1)\n",
    "best_params_xgb = study_xgb.best_params\n",
    "\n",
    "best_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=best_params_xgb['n_estimators'],\n",
    "    learning_rate=best_params_xgb['learning_rate'],\n",
    "    max_depth=best_params_xgb['max_depth'],\n",
    "    subsample=best_params_xgb['subsample'],\n",
    "    colsample_bytree=best_params_xgb['colsample_bytree'],\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "best_xgb.fit(X_train, y_train)\n",
    "xgb_rmse = root_mean_squared_error(y_test, best_xgb.predict(X_test))\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0f938a-d553-4073-9404-7a5e167a2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 30063.90\n",
      "Best Random Forest RMSE: 28314.02\n",
      "Best Gradient Boosting RMSE: 24032.39\n",
      "Best XGBoost RMSE: 24277.32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d127-98a1-4e28-a8f9-3e55e8b82f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa5696-9c5c-434c-8c34-da2bb1cbc8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78ddf19b-fb92-4e08-aed9-628cade1d21a",
   "metadata": {},
   "source": [
    "***\n",
    "### Anwenden Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61b82f2d-64a1-4b31-abe8-19a41e004cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorbereitungen zur Behandlung der fehlenden Werte im Testdatensatz\n",
    "test_data = test.copy()\n",
    "\n",
    "for column in test_data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if test_data[column].isnull().mean() > 0:\n",
    "        test_data[column] = test_data[column].fillna(test_data[column].mean())\n",
    "\n",
    "for column in test_data.select_dtypes(include=['object']).columns:\n",
    "    if test_data[column].isnull().mean() > 0:\n",
    "        test_data[column] = test_data[column].fillna('Missing')\n",
    "\n",
    "test_data = pd.get_dummies(test_data, drop_first=True)\n",
    "\n",
    "missing_cols = set(X_train.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    test_data[col] = 0\n",
    "test_data = test_data[X_train.columns]\n",
    "\n",
    "X_test_final = test_data.astype(np.float32).values\n",
    "\n",
    "# Sicherstellen, dass 'Id' in den ursprünglichen Testdaten vorhanden ist\n",
    "test_ids = test['Id'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42eb4a1a-ae39-4ac7-b4c6-ead6c47f661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen mit dem Ridge-Modell\n",
    "y_pred_ridge = best_ridge.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von Ridge-Modell)\n",
    "submission_ridge = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_ridge\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_ridge.to_csv('submission_ridge.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87c3f0fc-313e-4195-8e63-926351d029dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen mit dem Random Forest-Modell\n",
    "y_pred_rf = best_rf.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von Random Forest-Modell)\n",
    "submission_rf = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_rf\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_rf.to_csv('submission_rf.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f223b7f-b9fb-4a33-a2bb-1bb9d564651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen mit dem Gradient Boosting-Modell\n",
    "y_pred_gb = best_gb.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von Gradient Boosting-Modell)\n",
    "submission_gb = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_gb\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_gb.to_csv('submission_gb.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff6eb20a-1067-4b6f-b938-792a74eaeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen mit dem XGBoost-Modell\n",
    "y_pred_xgboost = best_xgb.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von XGBoost-Modell)\n",
    "submission_xgboost = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_xgboost\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_xgboost.to_csv('submission_xgboost.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
