{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7bf24f-bbc6-492a-bb2e-7645aa9bdc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import optuna\n",
    "import tqdm as notebook_tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243fbe6e-98ba-4bfc-a054-26a05f1e9713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Datei öffnen und lesen\n",
    "#with open('data_description.txt', 'r') as file:\n",
    "#    content = file.read()\n",
    "\n",
    "# Inhalt als Markdown anzeigen\n",
    "#display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b584497-e38d-4c8a-8581-2d9c08c73f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba9c469-5c7b-4262-bc76-7ba22bb92157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bca2a79-db96-4d61-8af8-aadb8a02e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percent Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>872</td>\n",
       "      <td>59.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>47.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>99.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>80.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>96.301370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Values  Percent Missing\n",
       "LotFrontage              259        17.739726\n",
       "Alley                   1369        93.767123\n",
       "MasVnrType               872        59.726027\n",
       "MasVnrArea                 8         0.547945\n",
       "BsmtQual                  37         2.534247\n",
       "BsmtCond                  37         2.534247\n",
       "BsmtExposure              38         2.602740\n",
       "BsmtFinType1              37         2.534247\n",
       "BsmtFinType2              38         2.602740\n",
       "Electrical                 1         0.068493\n",
       "FireplaceQu              690        47.260274\n",
       "GarageType                81         5.547945\n",
       "GarageYrBlt               81         5.547945\n",
       "GarageFinish              81         5.547945\n",
       "GarageQual                81         5.547945\n",
       "GarageCond                81         5.547945\n",
       "PoolQC                  1453        99.520548\n",
       "Fence                   1179        80.753425\n",
       "MiscFeature             1406        96.301370"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count = train.isnull().sum()\n",
    "missing_values_percent = (train.isnull().sum() / len(train)) * 100\n",
    "\n",
    "# Umwandeln des Ergebnisses in ein DataFrame\n",
    "missing_data_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values_count,\n",
    "    'Percent Missing': missing_values_percent\n",
    "})\n",
    "\n",
    "missing_data_df = missing_data_df[missing_data_df['Missing Values'] > 0]\n",
    "missing_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f24e2",
   "metadata": {},
   "source": [
    "## Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be13722a-8e59-4a15-a74e-78f6e7e7ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtQual\n",
      "TA    649\n",
      "Gd    618\n",
      "Ex    121\n",
      "Fa     35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = train['BsmtQual'].value_counts()\n",
    "\n",
    "# Ausgabe des Ergebnisses\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8d01f",
   "metadata": {},
   "source": [
    "### Drop Columns which have a missing value score over 90 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4a8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.drop(columns=['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726e7d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       BrkFace\n",
       "1           NaN\n",
       "2       BrkFace\n",
       "3           NaN\n",
       "4       BrkFace\n",
       "         ...   \n",
       "1455        NaN\n",
       "1456      Stone\n",
       "1457        NaN\n",
       "1458        NaN\n",
       "1459        NaN\n",
       "Name: MasVnrType, Length: 1460, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MasVnrType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc473349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation Results:\n",
      "\n",
      "Column: BsmtFinSF1\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: BsmtFinSF2\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: BsmtFullBath\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: BsmtHalfBath\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: BsmtUnfSF\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: GarageArea\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: GarageCars\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: GarageYrBlt\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: LotFrontage\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: MasVnrArea\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Column: TotalBsmtSF\n",
      "Mean Imputer: MSE = 0.0\n",
      "Median Imputer: MSE = 0.0\n",
      "KNN Imputer: MSE = 0.0\n",
      "Iterative Imputer (Bayesian Ridge): MSE = 0.0\n",
      "Iterative Imputer (Random Forest): MSE = 0.0\n",
      "\n",
      "Best Models for Each Column:\n",
      "Column: BsmtFinSF1 -> Best Model: Mean Imputer\n",
      "Column: BsmtFinSF2 -> Best Model: Mean Imputer\n",
      "Column: BsmtFullBath -> Best Model: Mean Imputer\n",
      "Column: BsmtHalfBath -> Best Model: Mean Imputer\n",
      "Column: BsmtUnfSF -> Best Model: Mean Imputer\n",
      "Column: GarageArea -> Best Model: Mean Imputer\n",
      "Column: GarageCars -> Best Model: Mean Imputer\n",
      "Column: GarageYrBlt -> Best Model: Mean Imputer\n",
      "Column: LotFrontage -> Best Model: Mean Imputer\n",
      "Column: MasVnrArea -> Best Model: Mean Imputer\n",
      "Column: TotalBsmtSF -> Best Model: Mean Imputer\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the data\n",
    "train_data_path = 'train.csv'  # Replace with your actual data path\n",
    "test_data_path = 'test.csv'    # Replace with your actual data path\n",
    "df_train = pd.read_csv(train_data_path)\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# Drop columns with more than 90% missing values\n",
    "threshold = 0.90\n",
    "df_train = df_train.loc[:, df_train.isnull().mean() < threshold]\n",
    "df_test = df_test.loc[:, df_test.isnull().mean() < threshold]\n",
    "\n",
    "# Drop the target variable 'SalePrice' from train data\n",
    "if 'SalePrice' in df_train.columns:\n",
    "    df_train = df_train.drop(columns=['SalePrice'])\n",
    "\n",
    "# Identify columns with missing values\n",
    "missing_cols_train = df_train.columns[df_train.isnull().any()]\n",
    "missing_cols_test = df_test.columns[df_test.isnull().any()]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols_train = df_train.select_dtypes(include=['object']).columns\n",
    "numerical_cols_train = df_train.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "categorical_cols_test = df_test.select_dtypes(include=['object']).columns\n",
    "numerical_cols_test = df_test.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# One-Hot Encode categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "df_train_encoded = pd.DataFrame(encoder.fit_transform(df_train[categorical_cols_train]))\n",
    "df_test_encoded = pd.DataFrame(encoder.transform(df_test[categorical_cols_test]))\n",
    "\n",
    "# Restore the column names for the encoded features\n",
    "df_train_encoded.columns = encoder.get_feature_names_out(categorical_cols_train)\n",
    "df_test_encoded.columns = encoder.get_feature_names_out(categorical_cols_test)\n",
    "\n",
    "# Drop original categorical columns and append the encoded columns\n",
    "df_train = df_train.drop(columns=categorical_cols_train).reset_index(drop=True)\n",
    "df_test = df_test.drop(columns=categorical_cols_test).reset_index(drop=True)\n",
    "df_train = pd.concat([df_train, df_train_encoded], axis=1)\n",
    "df_test = pd.concat([df_test, df_test_encoded], axis=1)\n",
    "\n",
    "# List of imputation models to test\n",
    "imputation_models = {\n",
    "    'Mean Imputer': SimpleImputer(strategy='mean'),\n",
    "    'Median Imputer': SimpleImputer(strategy='median'),\n",
    "    'KNN Imputer': KNNImputer(n_neighbors=5),\n",
    "    'Iterative Imputer (Bayesian Ridge)': IterativeImputer(estimator=BayesianRidge(), random_state=42),\n",
    "    'Iterative Imputer (Random Forest)': IterativeImputer(estimator=RandomForestRegressor(), random_state=42),\n",
    "    #'Iterative Imputer (Decision Tree)': IterativeImputer(estimator=DecisionTreeRegressor(), random_state=42),\n",
    "}\n",
    "\n",
    "# Function to evaluate imputation models\n",
    "def evaluate_imputation_models(models, train_data, test_data, target):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # Split the data into features and target\n",
    "        X_train = train_data.drop(columns=[target])\n",
    "        y_train = train_data[target]\n",
    "        X_test = test_data.drop(columns=[target])\n",
    "        y_test = test_data[target]\n",
    "\n",
    "        # Fit the model on training data\n",
    "        imputer = model.fit(X_train, y_train)\n",
    "        # Transform both training and test data\n",
    "        imputed_train_data = imputer.transform(X_train)\n",
    "        imputed_test_data = imputer.transform(X_test)\n",
    "\n",
    "        # Combine the imputed data with the target column\n",
    "        imputed_train_data = pd.DataFrame(imputed_train_data, columns=X_train.columns)\n",
    "        imputed_test_data = pd.DataFrame(imputed_test_data, columns=X_test.columns)\n",
    "        imputed_train_data[target] = y_train.values\n",
    "        imputed_test_data[target] = y_test.values\n",
    "\n",
    "        # Calculate MSE for the imputation\n",
    "        mse = mean_squared_error(y_test.dropna(), imputed_test_data[target].dropna())\n",
    "        results[name] = mse\n",
    "    return results\n",
    "\n",
    "# Evaluate models for each missing column\n",
    "imputation_results = {}\n",
    "best_models = {}\n",
    "for col in missing_cols_train.union(missing_cols_test):\n",
    "    if col in df_train.columns:\n",
    "        # Drop rows where the target variable is missing in training data\n",
    "        train_data = df_train.dropna(subset=[col]).copy()\n",
    "        test_data = df_test.dropna(subset=[col]).copy()\n",
    "        \n",
    "        # Check if there are still missing values in the test data for the target column\n",
    "        if train_data[col].isnull().any() or test_data[col].isnull().any():\n",
    "            continue\n",
    "        \n",
    "        # Evaluate imputation models\n",
    "        results = evaluate_imputation_models(imputation_models, train_data, test_data, col)\n",
    "        imputation_results[col] = results\n",
    "        best_model = min(results, key=results.get)\n",
    "        best_models[col] = best_model\n",
    "\n",
    "# Display the results\n",
    "print(\"Imputation Results:\")\n",
    "for col, results in imputation_results.items():\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    for model_name, mse in results.items():\n",
    "        print(f\"{model_name}: MSE = {mse}\")\n",
    "\n",
    "print(\"\\nBest Models for Each Column:\")\n",
    "for col, best_model in best_models.items():\n",
    "    print(f\"Column: {col} -> Best Model: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297cbf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: BsmtFinSF1 -> Best Model: Mean Imputer\n",
      "Column: BsmtFinSF2 -> Best Model: Mean Imputer\n",
      "Column: BsmtFullBath -> Best Model: Mean Imputer\n",
      "Column: BsmtHalfBath -> Best Model: Mean Imputer\n",
      "Column: BsmtUnfSF -> Best Model: Mean Imputer\n",
      "Column: GarageArea -> Best Model: Mean Imputer\n",
      "Column: GarageCars -> Best Model: Mean Imputer\n",
      "Column: GarageYrBlt -> Best Model: Mean Imputer\n",
      "Column: LotFrontage -> Best Model: Mean Imputer\n",
      "Column: MasVnrArea -> Best Model: Mean Imputer\n",
      "Column: TotalBsmtSF -> Best Model: Mean Imputer\n"
     ]
    }
   ],
   "source": [
    "for col, best_model in best_models.items():\n",
    "    print(f\"Column: {col} -> Best Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d713b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice column added to the imputed train dataset and saved to 'train_filled_with_SalePrice.csv'\n",
      "Imputed test dataset saved to 'test_filled.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define a function to get the appropriate imputer model\n",
    "def get_imputer(model_name):\n",
    "    if model_name == 'Mean Imputer':\n",
    "        return SimpleImputer(strategy='mean')\n",
    "    elif model_name == 'Median Imputer':\n",
    "        return SimpleImputer(strategy='median')\n",
    "    elif model_name == 'KNN Imputer':\n",
    "        return KNNImputer(n_neighbors=5)\n",
    "    elif model_name == 'Iterative Imputer (Bayesian Ridge)':\n",
    "        return IterativeImputer(estimator=BayesianRidge(), random_state=42)\n",
    "    elif model_name == 'Iterative Imputer (Random Forest)':\n",
    "        return IterativeImputer(estimator=RandomForestRegressor(), random_state=42)\n",
    "    elif model_name == 'Iterative Imputer (Decision Tree)':\n",
    "        return IterativeImputer(estimator=DecisionTreeRegressor(), random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "# Load the original train data to get the SalePrice column\n",
    "df_train_original = pd.read_csv(train_data_path)\n",
    "\n",
    "# Function to fill missing values using the best model for each column\n",
    "def fill_missing_values(df, best_models):\n",
    "    for col in best_models:\n",
    "        best_model_name = best_models[col]\n",
    "        imputer = get_imputer(best_model_name)\n",
    "        \n",
    "        # Fit the imputer on the data\n",
    "        df[col] = imputer.fit_transform(df[[col]])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Impute missing values separately for train and test data\n",
    "df_train_imputed = fill_missing_values(df_train.copy(), best_models)\n",
    "df_test_imputed = fill_missing_values(df_test.copy(), best_models)\n",
    "\n",
    "# Add the SalePrice column back to the imputed train data using the 'Id' column\n",
    "df_train_imputed = df_train_imputed.set_index('Id')\n",
    "df_train_original = df_train_original.set_index('Id')\n",
    "df_train_imputed['SalePrice'] = df_train_original['SalePrice']\n",
    "\n",
    "# Reset the index to default\n",
    "df_train_imputed.reset_index(inplace=True)\n",
    "df_test_imputed.reset_index(inplace=True)\n",
    "\n",
    "# Save the updated train and test datasets to new CSV files\n",
    "df_train_imputed.to_csv('train_filled_with_SalePrice.csv', index=False)\n",
    "df_test_imputed.to_csv('test_filled.csv', index=False)\n",
    "\n",
    "print(\"SalePrice column added to the imputed train dataset and saved to 'train_filled_with_SalePrice.csv'\")\n",
    "print(\"Imputed test dataset saved to 'test_filled.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243ffce0-e22b-4624-a14a-76ba8eefb28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after preprocessing: 0\n"
     ]
    }
   ],
   "source": [
    "#data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "missing_values_after = df_train_imputed.isnull().sum().sum()\n",
    "print(f\"Missing values after preprocessing: {missing_values_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515f95d",
   "metadata": {},
   "source": [
    "## Model Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fb0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb3a6cc-ad5d-4cc3-b1f1-24480a4e4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 25153.38\n"
     ]
    }
   ],
   "source": [
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisieren und Trainieren des XGBoost Regressors\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                          colsample_bytree=0.3,\n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=5,\n",
    "                          alpha=10,\n",
    "                          n_estimators=500)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen und Berechnen des RMSE\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"XGBoost RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4693e74-a6e8-4bda-bcaf-d8e95395a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 29220.98\n"
     ]
    }
   ],
   "source": [
    "# Initialisieren und Trainieren des RandomForestRegressors\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen und Berechnen des RMSE\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "rmse_rf = root_mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest RMSE: {rmse_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5df3ba-ec57-493c-8af4-3a3108f81c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38131437568.0000 - val_loss: 34571628544.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 34148986880.0000 - val_loss: 23237545984.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 18425634816.0000 - val_loss: 5722854912.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 7442180608.0000 - val_loss: 3511546368.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 7989471744.0000 - val_loss: 3358743552.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 5330455040.0000 - val_loss: 3085826816.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 5631615488.0000 - val_loss: 2910709248.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 4594918912.0000 - val_loss: 2782270464.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 4113447936.0000 - val_loss: 2690154240.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 3975426560.0000 - val_loss: 2604156672.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 4329730560.0000 - val_loss: 2514183424.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 3789732864.0000 - val_loss: 2444677888.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 3625946880.0000 - val_loss: 2338755328.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 2934253056.0000 - val_loss: 2242526720.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 3038275328.0000 - val_loss: 2131949568.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 3136330496.0000 - val_loss: 2025417344.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 3081997056.0000 - val_loss: 1925959680.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 3117491200.0000 - val_loss: 1821492992.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 2577988352.0000 - val_loss: 1722277120.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 2335808768.0000 - val_loss: 1677871360.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 2167813632.0000 - val_loss: 1595097984.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 2583375872.0000 - val_loss: 1655371520.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 2165511168.0000 - val_loss: 1532978944.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 2494142976.0000 - val_loss: 1454821888.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 2035139456.0000 - val_loss: 1463891456.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 2015602560.0000 - val_loss: 1371302656.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 2363647744.0000 - val_loss: 1377566848.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2024207616.0000 - val_loss: 1303285504.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 1647924992.0000 - val_loss: 1304149760.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 2609101824.0000 - val_loss: 1256515456.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 1888182016.0000 - val_loss: 1250810624.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 2540210688.0000 - val_loss: 1230056448.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 2013971840.0000 - val_loss: 1228521088.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 1742129408.0000 - val_loss: 1209048960.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 1868175488.0000 - val_loss: 1225089664.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 2509815808.0000 - val_loss: 1225794688.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 2018938880.0000 - val_loss: 1204001536.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 1772504192.0000 - val_loss: 1204098944.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 2402945280.0000 - val_loss: 1207023616.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 1844117760.0000 - val_loss: 1214616832.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 2531908096.0000 - val_loss: 1202996096.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 1771462272.0000 - val_loss: 1250853376.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 1681964416.0000 - val_loss: 1285946496.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 2090784768.0000 - val_loss: 1212542848.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 1680908416.0000 - val_loss: 1207159296.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 1886113152.0000 - val_loss: 1195040896.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 2665337856.0000 - val_loss: 1202683008.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 1924222208.0000 - val_loss: 1199745408.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 1686721024.0000 - val_loss: 1225387008.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 2655221504.0000 - val_loss: 1290594048.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 1725109504.0000 - val_loss: 1272497664.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 2330973696.0000 - val_loss: 1221560704.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 2058920704.0000 - val_loss: 1219190528.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 1567177600.0000 - val_loss: 1277164416.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 2638733568.0000 - val_loss: 1208246400.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 2520508672.0000 - val_loss: 1211220224.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 2097332224.0000 - val_loss: 1206642944.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 1828087168.0000 - val_loss: 1256712832.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 1927551872.0000 - val_loss: 1277604096.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 1511266816.0000 - val_loss: 1260681728.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 2237766912.0000 - val_loss: 1209596544.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 1941568640.0000 - val_loss: 1221415424.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 1890369536.0000 - val_loss: 1215575296.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 1509682560.0000 - val_loss: 1204848000.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 1621564032.0000 - val_loss: 1221938688.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 1939233536.0000 - val_loss: 1231787648.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 1950115072.0000 - val_loss: 1257250432.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 1529794944.0000 - val_loss: 1223138816.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 2028032768.0000 - val_loss: 1233315968.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 2635497984.0000 - val_loss: 1208786816.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 1817526016.0000 - val_loss: 1213399168.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 1970332928.0000 - val_loss: 1200149120.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 1866304512.0000 - val_loss: 1243855872.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 2011987584.0000 - val_loss: 1208506112.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 1657464576.0000 - val_loss: 1203357696.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 1737654656.0000 - val_loss: 1197831296.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 1972334464.0000 - val_loss: 1204505728.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 1916657024.0000 - val_loss: 1218687232.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 1656508288.0000 - val_loss: 1328092928.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 1537390464.0000 - val_loss: 1203882880.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 1870082176.0000 - val_loss: 1197575296.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 1575498368.0000 - val_loss: 1228104960.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 1894158976.0000 - val_loss: 1193946752.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 1990395136.0000 - val_loss: 1194729088.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 1625636480.0000 - val_loss: 1245761536.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 1672540544.0000 - val_loss: 1201908992.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 1819064832.0000 - val_loss: 1244626048.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 2116928000.0000 - val_loss: 1201111680.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 1827844096.0000 - val_loss: 1201264640.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 1939874944.0000 - val_loss: 1208077440.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 1855145088.0000 - val_loss: 1192215808.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 1747899264.0000 - val_loss: 1190104576.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 1602755840.0000 - val_loss: 1263859200.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 1625965824.0000 - val_loss: 1354985088.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 1450568320.0000 - val_loss: 1318164864.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 2060197632.0000 - val_loss: 1205991808.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 1920683264.0000 - val_loss: 1199231232.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 1802318208.0000 - val_loss: 1256041216.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 1606233088.0000 - val_loss: 1220793600.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1660317824.0000 - val_loss: 1180162304.0000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Keras NN RMSE: 40028.62\n"
     ]
    }
   ],
   "source": [
    "# Angenommen, 'data' ist Ihr DataFrame mit den Features und der Zielvariable 'SalePrice'\n",
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)\n",
    "\n",
    "# Initialisieren des Keras-Modells\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Kompilieren des Modells\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Trainieren des Modells\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Vorhersagen und Berechnen des RMSE\n",
    "y_pred_nn = model.predict(X_test)\n",
    "rmse_nn = root_mean_squared_error(y_test, y_pred_nn)\n",
    "print(f\"Keras NN RMSE: {rmse_nn:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9289c71f-3f86-4289-b7b5-f6a79c12b5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 34873.20\n",
      "Ridge Regression RMSE: 29349.26\n",
      "Lasso Regression RMSE: 28349.81\n",
      "Decision Tree Regressor RMSE: 44601.12\n",
      "Random Forest Regressor RMSE: 29220.98\n",
      "Gradient Boosting Regressor RMSE: 27140.03\n",
      "XGBoost Regressor RMSE: 26168.06\n"
     ]
    }
   ],
   "source": [
    "# Angenommen, 'data' ist Ihr DataFrame mit den Features und der Zielvariable 'SalePrice'\n",
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)\n",
    "\n",
    "# Initialisieren der Modelle\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost Regressor\": xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, alpha=10, n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Trainieren und Evaluieren der Modelle\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{name} RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e523c7ff-1229-4938-9587-54852ac69fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92fe1d4a-921c-4164-a2c5-833054de54b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.72712e-13): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.72712e-13): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.61384e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.61384e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.92128e-11): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.92128e-11): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.77124e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.54355e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.36574e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.56686e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.51376e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.77124e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.54355e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.36574e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.56686e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.51376e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 30479.78\n"
     ]
    }
   ],
   "source": [
    "ridge_params = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 100.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge_grid = GridSearchCV(ridge, ridge_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_rmse = root_mean_squared_error(y_test, best_ridge.predict(X_test))\n",
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb830971-536f-4dc0-9244-95f8ff184ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest RMSE: 28854.85\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_grid = RandomizedSearchCV(rf, rf_params, cv=5, scoring='neg_mean_squared_error', n_iter=10, n_jobs=-1, random_state=42)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_rmse = root_mean_squared_error(y_test, best_rf.predict(X_test))\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7afc2ed6-0df5-4ffc-9184-c920d79c4e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 26389.63\n"
     ]
    }
   ],
   "source": [
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb_grid = RandomizedSearchCV(gb, gb_params, cv=5, scoring='neg_mean_squared_error', n_iter=10, n_jobs=-1, random_state=42)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bb535cf-57b8-46bf-9e46-a3eaa625c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost RMSE: 26977.62\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgb_grid = RandomizedSearchCV(xgb_reg, xgb_params, cv=5, scoring='neg_mean_squared_error', n_iter=10, n_jobs=-1, random_state=42)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "xgb_rmse = mean_squared_error(y_test, best_xgb.predict(X_test), squared=False)\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c5e2c08-677d-4783-8916-647ca9efdd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 30479.78\n",
      "Best Random Forest RMSE: 28854.85\n",
      "Best Gradient Boosting RMSE: 26389.63\n",
      "Best XGBoost RMSE: 26977.62\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47cbe96a-395e-427d-9655-8e52312549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angenommen, 'data' ist Ihr DataFrame mit den Features und der Zielvariable 'SalePrice'\n",
    "# Extrahieren der Merkmale und Zielvariable\n",
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sicherstellen, dass alle Daten numerisch sind und in numpy-Arrays konvertieren\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ede0572d-93d5-4367-a271-fba1077dd990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 18:22:27,290] A new study created in memory with name: no-name-03088e28-74ef-41b9-90d3-993645b67388\n",
      "[I 2024-06-21 18:22:28,069] Trial 7 finished with value: 34514.71875 and parameters: {'alpha': 0.2107060758643458, 'solver': 'sparse_cg'}. Best is trial 7 with value: 34514.71875.\n",
      "[I 2024-06-21 18:22:28,201] Trial 3 finished with value: 34506.86328125 and parameters: {'alpha': 0.34829860250427097, 'solver': 'sparse_cg'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:29,069] Trial 6 finished with value: 34515.9140625 and parameters: {'alpha': 24.115126381871317, 'solver': 'sparse_cg'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:31,538] Trial 4 finished with value: 43380.43359375 and parameters: {'alpha': 9.675794280284423, 'solver': 'sag'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:31,546] Trial 1 finished with value: 43380.29296875 and parameters: {'alpha': 5.019367958719341, 'solver': 'sag'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:32,534] Trial 2 finished with value: 44320.84375 and parameters: {'alpha': 4.167507540145485, 'solver': 'saga'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:32,543] Trial 10 finished with value: 34511.97265625 and parameters: {'alpha': 0.9307215339235688, 'solver': 'sparse_cg'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:34,326] Trial 13 finished with value: 40408.34375 and parameters: {'alpha': 1.1755027476130633, 'solver': 'lsqr'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:35,273] Trial 11 finished with value: 43379.6875 and parameters: {'alpha': 0.28548060411194454, 'solver': 'sag'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:35,605] Trial 12 finished with value: 43379.453125 and parameters: {'alpha': 20.516540525632166, 'solver': 'sag'}. Best is trial 3 with value: 34506.86328125.\n",
      "[I 2024-06-21 18:22:37,196] Trial 16 finished with value: 34503.75390625 and parameters: {'alpha': 0.6952538846744506, 'solver': 'sparse_cg'}. Best is trial 16 with value: 34503.75390625.\n",
      "[I 2024-06-21 18:22:38,264] Trial 15 finished with value: 43381.25390625 and parameters: {'alpha': 13.368006079269133, 'solver': 'sag'}. Best is trial 16 with value: 34503.75390625.\n",
      "[I 2024-06-21 18:22:57,485] Trial 5 finished with value: 29391.58984375 and parameters: {'alpha': 1.0774076566955826, 'solver': 'svd'}. Best is trial 5 with value: 29391.58984375.\n",
      "[I 2024-06-21 18:22:59,239] Trial 18 finished with value: 29099.44140625 and parameters: {'alpha': 0.6228249349067488, 'solver': 'auto'}. Best is trial 18 with value: 29099.44140625.\n",
      "[I 2024-06-21 18:22:59,881] Trial 9 finished with value: 29189.37109375 and parameters: {'alpha': 0.7459917291354207, 'solver': 'svd'}. Best is trial 18 with value: 29099.44140625.\n",
      "[I 2024-06-21 18:23:00,649] Trial 22 finished with value: 31964.3359375 and parameters: {'alpha': 93.29187703651566, 'solver': 'auto'}. Best is trial 18 with value: 29099.44140625.\n",
      "[I 2024-06-21 18:23:01,258] Trial 8 finished with value: 29771.578125 and parameters: {'alpha': 2.108042649572941, 'solver': 'cholesky'}. Best is trial 18 with value: 29099.44140625.\n",
      "[I 2024-06-21 18:23:05,141] Trial 14 finished with value: 30984.677734375 and parameters: {'alpha': 28.946547996187146, 'solver': 'auto'}. Best is trial 18 with value: 29099.44140625.\n",
      "[I 2024-06-21 18:23:06,065] Trial 19 finished with value: 28935.24609375 and parameters: {'alpha': 0.1030196897286219, 'solver': 'svd'}. Best is trial 19 with value: 28935.24609375.\n",
      "[I 2024-06-21 18:23:07,049] Trial 0 finished with value: 29447.97265625 and parameters: {'alpha': 1.1888252823905012, 'solver': 'auto'}. Best is trial 19 with value: 28935.24609375.\n",
      "[I 2024-06-21 18:23:08,689] Trial 17 finished with value: 28905.837890625 and parameters: {'alpha': 0.11592029679487449, 'solver': 'cholesky'}. Best is trial 17 with value: 28905.837890625.\n",
      "[I 2024-06-21 18:23:24,301] Trial 20 finished with value: 31918.259765625 and parameters: {'alpha': 89.52734358449736, 'solver': 'svd'}. Best is trial 17 with value: 28905.837890625.\n",
      "[I 2024-06-21 18:23:24,687] Trial 24 finished with value: 28891.900390625 and parameters: {'alpha': 0.12327242650210245, 'solver': 'auto'}. Best is trial 24 with value: 28891.900390625.\n",
      "[I 2024-06-21 18:23:27,190] Trial 21 finished with value: 31612.935546875 and parameters: {'alpha': 66.52760862641378, 'solver': 'svd'}. Best is trial 24 with value: 28891.900390625.\n",
      "[I 2024-06-21 18:23:29,486] Trial 23 finished with value: 28909.537109375 and parameters: {'alpha': 0.11411315126051806, 'solver': 'auto'}. Best is trial 24 with value: 28891.900390625.\n",
      "[I 2024-06-21 18:23:29,918] Trial 26 finished with value: 28914.802734375 and parameters: {'alpha': 0.11165782655631193, 'solver': 'auto'}. Best is trial 24 with value: 28891.900390625.\n",
      "[I 2024-06-21 18:23:37,335] Trial 27 finished with value: 28940.447265625 and parameters: {'alpha': 0.10101930302921211, 'solver': 'svd'}. Best is trial 24 with value: 28891.900390625.\n",
      "[I 2024-06-21 18:23:38,959] Trial 28 finished with value: 28923.251953125 and parameters: {'alpha': 0.10792729175575645, 'solver': 'cholesky'}. Best is trial 24 with value: 28891.900390625.\n",
      "[I 2024-06-21 18:23:42,209] Trial 25 finished with value: 28845.333984375 and parameters: {'alpha': 0.16127691334886196, 'solver': 'svd'}. Best is trial 25 with value: 28845.333984375.\n",
      "[I 2024-06-21 18:23:47,264] Trial 30 finished with value: 28907.73046875 and parameters: {'alpha': 0.11499070045240407, 'solver': 'cholesky'}. Best is trial 25 with value: 28845.333984375.\n",
      "[I 2024-06-21 18:23:47,557] Trial 37 finished with value: 40408.34375 and parameters: {'alpha': 0.20044435633262003, 'solver': 'lsqr'}. Best is trial 25 with value: 28845.333984375.\n",
      "[I 2024-06-21 18:23:48,186] Trial 29 finished with value: 28934.169921875 and parameters: {'alpha': 0.10344569533711598, 'solver': 'cholesky'}. Best is trial 25 with value: 28845.333984375.\n",
      "[I 2024-06-21 18:23:56,401] Trial 31 finished with value: 28913.126953125 and parameters: {'alpha': 0.11242082041098839, 'solver': 'cholesky'}. Best is trial 25 with value: 28845.333984375.\n",
      "[I 2024-06-21 18:23:57,804] Trial 33 finished with value: 28838.26171875 and parameters: {'alpha': 0.17182913785649856, 'solver': 'cholesky'}. Best is trial 33 with value: 28838.26171875.\n",
      "[I 2024-06-21 18:24:00,437] Trial 32 finished with value: 28934.46875 and parameters: {'alpha': 0.10333002473503532, 'solver': 'cholesky'}. Best is trial 33 with value: 28838.26171875.\n",
      "[I 2024-06-21 18:24:00,840] Trial 40 finished with value: 44319.7578125 and parameters: {'alpha': 0.45374469223069747, 'solver': 'saga'}. Best is trial 33 with value: 28838.26171875.\n",
      "[I 2024-06-21 18:24:02,438] Trial 41 finished with value: 44319.89453125 and parameters: {'alpha': 0.4481005151857525, 'solver': 'saga'}. Best is trial 33 with value: 28838.26171875.\n",
      "[I 2024-06-21 18:24:05,122] Trial 42 finished with value: 44320.4609375 and parameters: {'alpha': 0.3814567773344253, 'solver': 'saga'}. Best is trial 33 with value: 28838.26171875.\n",
      "[I 2024-06-21 18:24:05,505] Trial 43 finished with value: 44319.55078125 and parameters: {'alpha': 0.2507816110249626, 'solver': 'saga'}. Best is trial 33 with value: 28838.26171875.\n",
      "[I 2024-06-21 18:24:07,303] Trial 35 finished with value: 28828.447265625 and parameters: {'alpha': 0.199745959443584, 'solver': 'cholesky'}. Best is trial 35 with value: 28828.447265625.\n",
      "[I 2024-06-21 18:24:11,510] Trial 36 finished with value: 28827.7734375 and parameters: {'alpha': 0.22259176055568378, 'solver': 'cholesky'}. Best is trial 36 with value: 28827.7734375.\n",
      "[I 2024-06-21 18:24:12,874] Trial 34 finished with value: 28835.314453125 and parameters: {'alpha': 0.17747439567868914, 'solver': 'cholesky'}. Best is trial 36 with value: 28827.7734375.\n",
      "[I 2024-06-21 18:24:19,735] Trial 38 finished with value: 28966.654296875 and parameters: {'alpha': 0.454277360500598, 'solver': 'cholesky'}. Best is trial 36 with value: 28827.7734375.\n",
      "[I 2024-06-21 18:24:22,462] Trial 39 finished with value: 28883.328125 and parameters: {'alpha': 0.34403694924710015, 'solver': 'cholesky'}. Best is trial 36 with value: 28827.7734375.\n",
      "[I 2024-06-21 18:24:25,637] Trial 45 finished with value: 28829.466796875 and parameters: {'alpha': 0.19433723096451166, 'solver': 'cholesky'}. Best is trial 36 with value: 28827.7734375.\n",
      "[I 2024-06-21 18:24:25,773] Trial 44 finished with value: 28827.65234375 and parameters: {'alpha': 0.2066187095033581, 'solver': 'cholesky'}. Best is trial 44 with value: 28827.65234375.\n",
      "[I 2024-06-21 18:24:26,113] Trial 46 finished with value: 28839.6875 and parameters: {'alpha': 0.16944616261144455, 'solver': 'cholesky'}. Best is trial 44 with value: 28827.65234375.\n",
      "[I 2024-06-21 18:24:26,606] Trial 47 finished with value: 29618.556640625 and parameters: {'alpha': 1.60076072894109, 'solver': 'cholesky'}. Best is trial 44 with value: 28827.65234375.\n",
      "[I 2024-06-21 18:24:26,619] Trial 48 finished with value: 28829.595703125 and parameters: {'alpha': 0.19376611804421187, 'solver': 'cholesky'}. Best is trial 44 with value: 28827.65234375.\n",
      "[I 2024-06-21 18:24:26,640] Trial 49 finished with value: 28833.12109375 and parameters: {'alpha': 0.18250892898250223, 'solver': 'cholesky'}. Best is trial 44 with value: 28827.65234375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 28827.65\n"
     ]
    }
   ],
   "source": [
    "def objective_ridge(trial):\n",
    "    alpha = trial.suggest_loguniform('alpha', 0.1, 100.0)\n",
    "    solver = trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n",
    "    \n",
    "    model = Ridge(alpha=alpha, solver=solver)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_ridge = optuna.create_study(direction='minimize')\n",
    "study_ridge.optimize(objective_ridge, n_trials=50, n_jobs=-1)\n",
    "\n",
    "best_params_ridge = study_ridge.best_params\n",
    "best_ridge = Ridge(**best_params_ridge)\n",
    "best_ridge.fit(X_train, y_train)\n",
    "ridge_rmse = mean_squared_error(y_test, best_ridge.predict(X_test), squared=False)\n",
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fec3bf41-f8a3-4d5c-9f79-3f08b5828dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 27324.99\n"
     ]
    }
   ],
   "source": [
    "# Definieren der Parameter für Bayesian Optimization\n",
    "gb_params = {\n",
    "    'n_estimators': Integer(50, 300),\n",
    "    'learning_rate': Real(0.01, 0.1, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 10),\n",
    "    'subsample': Real(0.7, 1.0),\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'min_samples_leaf': Integer(1, 4)\n",
    "}\n",
    "\n",
    "# Initialisieren des Gradient Boosting Regressors\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Bayesian Optimization mit BayesSearchCV\n",
    "gb_opt = BayesSearchCV(gb, gb_params, n_iter=32, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "gb_opt.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell und RMSE berechnen\n",
    "best_gb = gb_opt.best_estimator_\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d1e96c-a878-4a6b-89e6-a2fc4e55b8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 28827.65\n",
      "Best Random Forest RMSE: 28854.85\n",
      "Best Gradient Boosting RMSE: 27324.99\n",
      "Best XGBoost RMSE: 26977.62\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dc9ef18-369f-4d7d-8ac2-5f4c216da78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 18:25:55,143] A new study created in memory with name: no-name-4c749431-ed65-4296-aea3-0f8f948910a7\n",
      "[I 2024-06-21 18:25:57,022] Trial 3 finished with value: 29633.545684343488 and parameters: {'n_estimators': 88, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 29633.545684343488.\n",
      "[I 2024-06-21 18:25:57,665] Trial 6 finished with value: 30008.55948570428 and parameters: {'n_estimators': 127, 'max_depth': 41, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 3 with value: 29633.545684343488.\n",
      "[I 2024-06-21 18:25:57,972] Trial 0 finished with value: 30880.747874100678 and parameters: {'n_estimators': 161, 'max_depth': 46, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 29633.545684343488.\n",
      "[I 2024-06-21 18:25:58,069] Trial 2 finished with value: 29717.171400022697 and parameters: {'n_estimators': 145, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 29633.545684343488.\n",
      "[I 2024-06-21 18:25:58,187] Trial 7 finished with value: 29679.270672324423 and parameters: {'n_estimators': 149, 'max_depth': 37, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 29633.545684343488.\n",
      "[I 2024-06-21 18:25:58,226] Trial 4 finished with value: 29420.847360109332 and parameters: {'n_estimators': 150, 'max_depth': 43, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 4 with value: 29420.847360109332.\n",
      "[I 2024-06-21 18:25:58,554] Trial 1 finished with value: 30671.211357496322 and parameters: {'n_estimators': 188, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 4 with value: 29420.847360109332.\n",
      "[I 2024-06-21 18:25:58,653] Trial 5 finished with value: 28988.85960057656 and parameters: {'n_estimators': 159, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:25:59,273] Trial 9 finished with value: 31100.371046753116 and parameters: {'n_estimators': 83, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:00,104] Trial 8 finished with value: 30892.397745250026 and parameters: {'n_estimators': 166, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:01,250] Trial 12 finished with value: 29393.787299241507 and parameters: {'n_estimators': 145, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:02,802] Trial 14 finished with value: 29385.024022517082 and parameters: {'n_estimators': 216, 'max_depth': 43, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:03,072] Trial 10 finished with value: 29480.80126979827 and parameters: {'n_estimators': 285, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:03,783] Trial 11 finished with value: 29236.538107924058 and parameters: {'n_estimators': 279, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:04,179] Trial 15 finished with value: 30140.57773254854 and parameters: {'n_estimators': 286, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:04,302] Trial 13 finished with value: 29062.53753883719 and parameters: {'n_estimators': 266, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:04,465] Trial 17 finished with value: 29559.948683528164 and parameters: {'n_estimators': 260, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 5 with value: 28988.85960057656.\n",
      "[I 2024-06-21 18:26:05,037] Trial 16 finished with value: 28879.031164979435 and parameters: {'n_estimators': 232, 'max_depth': 44, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:06,293] Trial 18 finished with value: 29195.77115893549 and parameters: {'n_estimators': 241, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:08,189] Trial 20 finished with value: 29123.449673985815 and parameters: {'n_estimators': 224, 'max_depth': 35, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:08,344] Trial 19 finished with value: 29150.292452869555 and parameters: {'n_estimators': 252, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:09,134] Trial 22 finished with value: 29136.120584744298 and parameters: {'n_estimators': 219, 'max_depth': 35, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:09,990] Trial 23 finished with value: 29232.281981729357 and parameters: {'n_estimators': 238, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:10,070] Trial 24 finished with value: 29276.442788208453 and parameters: {'n_estimators': 231, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:10,087] Trial 21 finished with value: 29343.763933373622 and parameters: {'n_estimators': 273, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:10,686] Trial 25 finished with value: 28884.669067002073 and parameters: {'n_estimators': 224, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:11,248] Trial 26 finished with value: 28936.66682752626 and parameters: {'n_estimators': 198, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:12,919] Trial 31 finished with value: 29288.896907854098 and parameters: {'n_estimators': 110, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:13,353] Trial 27 finished with value: 28972.2069050957 and parameters: {'n_estimators': 200, 'max_depth': 33, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:13,575] Trial 28 finished with value: 29225.168999387348 and parameters: {'n_estimators': 208, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:13,659] Trial 29 finished with value: 29110.458271398802 and parameters: {'n_estimators': 192, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:14,907] Trial 32 finished with value: 28886.661199788603 and parameters: {'n_estimators': 191, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 28879.031164979435.\n",
      "[I 2024-06-21 18:26:15,018] Trial 30 finished with value: 28875.529891234255 and parameters: {'n_estimators': 192, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 30 with value: 28875.529891234255.\n",
      "[I 2024-06-21 18:26:15,709] Trial 33 finished with value: 28891.30608088918 and parameters: {'n_estimators': 195, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 30 with value: 28875.529891234255.\n",
      "[I 2024-06-21 18:26:16,125] Trial 34 finished with value: 28936.66682752626 and parameters: {'n_estimators': 198, 'max_depth': 39, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 30 with value: 28875.529891234255.\n",
      "[I 2024-06-21 18:26:17,632] Trial 35 finished with value: 28851.294835484783 and parameters: {'n_estimators': 193, 'max_depth': 39, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 35 with value: 28851.294835484783.\n",
      "[I 2024-06-21 18:26:18,361] Trial 36 finished with value: 28851.885160365426 and parameters: {'n_estimators': 192, 'max_depth': 39, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 35 with value: 28851.294835484783.\n",
      "[I 2024-06-21 18:26:18,580] Trial 37 finished with value: 28824.57330397222 and parameters: {'n_estimators': 185, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 37 with value: 28824.57330397222.\n",
      "[I 2024-06-21 18:26:19,121] Trial 38 finished with value: 28953.82266642192 and parameters: {'n_estimators': 197, 'max_depth': 39, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 37 with value: 28824.57330397222.\n",
      "[I 2024-06-21 18:26:19,721] Trial 39 finished with value: 28827.50346953177 and parameters: {'n_estimators': 184, 'max_depth': 39, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 37 with value: 28824.57330397222.\n",
      "[I 2024-06-21 18:26:19,818] Trial 40 finished with value: 28819.28670378865 and parameters: {'n_estimators': 179, 'max_depth': 39, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 40 with value: 28819.28670378865.\n",
      "[I 2024-06-21 18:26:20,324] Trial 41 finished with value: 28808.278614387047 and parameters: {'n_estimators': 177, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 41 with value: 28808.278614387047.\n",
      "[I 2024-06-21 18:26:20,694] Trial 42 finished with value: 28839.8227931612 and parameters: {'n_estimators': 171, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 41 with value: 28808.278614387047.\n",
      "[I 2024-06-21 18:26:22,460] Trial 43 finished with value: 28833.475222441004 and parameters: {'n_estimators': 177, 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 41 with value: 28808.278614387047.\n",
      "[I 2024-06-21 18:26:22,914] Trial 44 finished with value: 28819.28670378865 and parameters: {'n_estimators': 179, 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 41 with value: 28808.278614387047.\n",
      "[I 2024-06-21 18:26:22,922] Trial 45 finished with value: 28804.95487629437 and parameters: {'n_estimators': 175, 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 28804.95487629437.\n",
      "[I 2024-06-21 18:26:22,948] Trial 47 finished with value: 29579.06996762555 and parameters: {'n_estimators': 181, 'max_depth': 48, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 45 with value: 28804.95487629437.\n",
      "[I 2024-06-21 18:26:23,430] Trial 46 finished with value: 28822.257031500423 and parameters: {'n_estimators': 176, 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 28804.95487629437.\n",
      "[I 2024-06-21 18:26:23,713] Trial 48 finished with value: 28813.223967111964 and parameters: {'n_estimators': 174, 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 28804.95487629437.\n",
      "[I 2024-06-21 18:26:24,021] Trial 49 finished with value: 28822.257031500423 and parameters: {'n_estimators': 176, 'max_depth': 46, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 28804.95487629437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest RMSE: 28804.95\n"
     ]
    }
   ],
   "source": [
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, n_jobs=-1)\n",
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "best_rf = RandomForestRegressor(\n",
    "    n_estimators=best_params_rf['n_estimators'],\n",
    "    max_depth=best_params_rf['max_depth'],\n",
    "    min_samples_split=best_params_rf['min_samples_split'],\n",
    "    min_samples_leaf=best_params_rf['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "rf_rmse = mean_squared_error(y_test, best_rf.predict(X_test), squared=False)\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b88394fd-4654-4364-8733-6b314057f1a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 18:26:26,862] A new study created in memory with name: no-name-3be7c142-3507-4bba-b977-eb4e9c7f9a66\n",
      "[I 2024-06-21 18:26:28,038] Trial 7 finished with value: 30158.440419390045 and parameters: {'n_estimators': 61, 'max_depth': 42, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 7 with value: 30158.440419390045.\n",
      "[I 2024-06-21 18:26:28,072] Trial 0 finished with value: 30128.956557459784 and parameters: {'n_estimators': 54, 'max_depth': 36, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 30128.956557459784.\n",
      "[I 2024-06-21 18:26:28,407] Trial 6 finished with value: 30138.141218524284 and parameters: {'n_estimators': 79, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 0 with value: 30128.956557459784.\n",
      "[I 2024-06-21 18:26:28,742] Trial 1 finished with value: 29843.197971878828 and parameters: {'n_estimators': 90, 'max_depth': 44, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 1 with value: 29843.197971878828.\n",
      "[I 2024-06-21 18:26:29,451] Trial 3 finished with value: 30929.613460554297 and parameters: {'n_estimators': 147, 'max_depth': 37, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 1 with value: 29843.197971878828.\n",
      "[I 2024-06-21 18:26:29,633] Trial 4 finished with value: 30069.12096306614 and parameters: {'n_estimators': 143, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 1 with value: 29843.197971878828.\n",
      "[I 2024-06-21 18:26:29,718] Trial 2 finished with value: 30675.76604629334 and parameters: {'n_estimators': 167, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 1 with value: 29843.197971878828.\n",
      "[I 2024-06-21 18:26:29,756] Trial 11 finished with value: 29239.51806330941 and parameters: {'n_estimators': 57, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 11 with value: 29239.51806330941.\n",
      "[I 2024-06-21 18:26:30,243] Trial 9 finished with value: 29633.699348164053 and parameters: {'n_estimators': 105, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 11 with value: 29239.51806330941.\n",
      "[I 2024-06-21 18:26:30,423] Trial 14 finished with value: 31876.86071076217 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 11 with value: 29239.51806330941.\n",
      "[I 2024-06-21 18:26:30,632] Trial 15 finished with value: 33001.72465101662 and parameters: {'n_estimators': 84, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 11 with value: 29239.51806330941.\n",
      "[I 2024-06-21 18:26:31,168] Trial 13 finished with value: 31066.15328394575 and parameters: {'n_estimators': 88, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 11 with value: 29239.51806330941.\n",
      "[I 2024-06-21 18:26:31,365] Trial 5 finished with value: 29575.93074421408 and parameters: {'n_estimators': 251, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 29239.51806330941.\n",
      "[I 2024-06-21 18:26:31,851] Trial 10 finished with value: 28834.44710566418 and parameters: {'n_estimators': 165, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:32,142] Trial 8 finished with value: 30069.976832116216 and parameters: {'n_estimators': 218, 'max_depth': 31, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:33,388] Trial 12 finished with value: 30937.432774633682 and parameters: {'n_estimators': 218, 'max_depth': 35, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:35,018] Trial 17 finished with value: 29518.83620999812 and parameters: {'n_estimators': 238, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:35,240] Trial 16 finished with value: 30178.539202359996 and parameters: {'n_estimators': 267, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:36,248] Trial 23 finished with value: 29494.70659238557 and parameters: {'n_estimators': 129, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:36,510] Trial 20 finished with value: 29566.757848083136 and parameters: {'n_estimators': 261, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:37,066] Trial 21 finished with value: 29168.34590329592 and parameters: {'n_estimators': 243, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:37,237] Trial 18 finished with value: 29280.137384275935 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:37,381] Trial 19 finished with value: 29173.97781721981 and parameters: {'n_estimators': 295, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:37,957] Trial 25 finished with value: 29344.924598537287 and parameters: {'n_estimators': 127, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:38,569] Trial 22 finished with value: 29262.23261349458 and parameters: {'n_estimators': 291, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:40,337] Trial 27 finished with value: 29089.423094158654 and parameters: {'n_estimators': 187, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:40,431] Trial 26 finished with value: 28999.527541228075 and parameters: {'n_estimators': 191, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:41,055] Trial 29 finished with value: 29397.945932558552 and parameters: {'n_estimators': 190, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:41,663] Trial 24 finished with value: 29318.060187774077 and parameters: {'n_estimators': 294, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:42,138] Trial 31 finished with value: 29285.16488433374 and parameters: {'n_estimators': 191, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:43,056] Trial 32 finished with value: 29150.445309482042 and parameters: {'n_estimators': 196, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:43,275] Trial 28 finished with value: 29210.43602209729 and parameters: {'n_estimators': 300, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:43,738] Trial 30 finished with value: 29283.90487151468 and parameters: {'n_estimators': 295, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:44,077] Trial 34 finished with value: 29295.222363488978 and parameters: {'n_estimators': 186, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:44,697] Trial 35 finished with value: 29295.222363488978 and parameters: {'n_estimators': 186, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:44,702] Trial 33 finished with value: 29220.026631558005 and parameters: {'n_estimators': 201, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:44,947] Trial 36 finished with value: 29477.16590197161 and parameters: {'n_estimators': 187, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:45,285] Trial 37 finished with value: 29542.366807706072 and parameters: {'n_estimators': 173, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:46,169] Trial 38 finished with value: 29495.61749070537 and parameters: {'n_estimators': 174, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:46,387] Trial 39 finished with value: 29485.04012177029 and parameters: {'n_estimators': 175, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:46,894] Trial 40 finished with value: 29538.935870166923 and parameters: {'n_estimators': 172, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:48,299] Trial 41 finished with value: 29207.815653425878 and parameters: {'n_estimators': 167, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:48,842] Trial 42 finished with value: 29291.13226634916 and parameters: {'n_estimators': 162, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:48,871] Trial 44 finished with value: 29372.680274386978 and parameters: {'n_estimators': 160, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:48,876] Trial 43 finished with value: 29227.310776168935 and parameters: {'n_estimators': 165, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:49,161] Trial 45 finished with value: 29378.254002747686 and parameters: {'n_estimators': 158, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:49,364] Trial 47 finished with value: 29814.34870682962 and parameters: {'n_estimators': 157, 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:49,501] Trial 46 finished with value: 28907.010945932 and parameters: {'n_estimators': 157, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:49,666] Trial 48 finished with value: 29064.492360286084 and parameters: {'n_estimators': 155, 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n",
      "[I 2024-06-21 18:26:50,592] Trial 49 finished with value: 29054.072284545746 and parameters: {'n_estimators': 157, 'max_depth': 21, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 10 with value: 28834.44710566418.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest RMSE: 28834.45\n"
     ]
    }
   ],
   "source": [
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, n_jobs=-1)\n",
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "best_rf = RandomForestRegressor(\n",
    "    n_estimators=best_params_rf['n_estimators'],\n",
    "    max_depth=best_params_rf['max_depth'],\n",
    "    min_samples_split=best_params_rf['min_samples_split'],\n",
    "    min_samples_leaf=best_params_rf['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "rf_rmse = mean_squared_error(y_test, best_rf.predict(X_test), squared=False)\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f51608f3-d399-42dd-afcd-537309524835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 18:26:52,751] A new study created in memory with name: no-name-920c92fa-471f-4ef2-8b14-683425e34220\n",
      "[I 2024-06-21 18:26:53,392] Trial 0 finished with value: 53627.189204728056 and parameters: {'n_estimators': 86, 'learning_rate': 0.010283404763510704, 'max_depth': 3, 'subsample': 0.7103465807840714, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 53627.189204728056.\n",
      "[I 2024-06-21 18:26:53,701] Trial 4 finished with value: 26379.38182324945 and parameters: {'n_estimators': 85, 'learning_rate': 0.062482629932233066, 'max_depth': 4, 'subsample': 0.9420362547938566, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 4 with value: 26379.38182324945.\n",
      "[I 2024-06-21 18:26:53,992] Trial 1 finished with value: 39549.51694198498 and parameters: {'n_estimators': 103, 'learning_rate': 0.012996323811688896, 'max_depth': 5, 'subsample': 0.8054917375840991, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 4 with value: 26379.38182324945.\n",
      "[I 2024-06-21 18:26:54,000] Trial 3 finished with value: 31111.155296001558 and parameters: {'n_estimators': 152, 'learning_rate': 0.02056333439817529, 'max_depth': 3, 'subsample': 0.8810917724581918, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 4 with value: 26379.38182324945.\n",
      "[I 2024-06-21 18:26:54,651] Trial 6 finished with value: 27581.28161165162 and parameters: {'n_estimators': 98, 'learning_rate': 0.03704155228675856, 'max_depth': 7, 'subsample': 0.975655019894319, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 4 with value: 26379.38182324945.\n",
      "[I 2024-06-21 18:26:55,584] Trial 9 finished with value: 26605.863455836043 and parameters: {'n_estimators': 165, 'learning_rate': 0.02484325185790906, 'max_depth': 4, 'subsample': 0.9126231679295173, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 4 with value: 26379.38182324945.\n",
      "[I 2024-06-21 18:26:55,818] Trial 2 finished with value: 25816.684129804307 and parameters: {'n_estimators': 234, 'learning_rate': 0.08327540716523003, 'max_depth': 5, 'subsample': 0.8829937498346171, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:55,877] Trial 12 finished with value: 39250.83391005288 and parameters: {'n_estimators': 69, 'learning_rate': 0.017712079393970986, 'max_depth': 9, 'subsample': 0.7506855245593539, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:55,941] Trial 10 finished with value: 27079.757237372312 and parameters: {'n_estimators': 105, 'learning_rate': 0.028787524921749314, 'max_depth': 9, 'subsample': 0.7593662909760255, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:56,376] Trial 14 finished with value: 42877.234066403624 and parameters: {'n_estimators': 53, 'learning_rate': 0.023417473640891893, 'max_depth': 4, 'subsample': 0.7590620723753971, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:56,828] Trial 11 finished with value: 25863.427236640244 and parameters: {'n_estimators': 196, 'learning_rate': 0.05036210847624405, 'max_depth': 5, 'subsample': 0.9996778140037037, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:57,789] Trial 7 finished with value: 26473.000285804148 and parameters: {'n_estimators': 199, 'learning_rate': 0.03846618183786462, 'max_depth': 10, 'subsample': 0.8207143315554007, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:58,090] Trial 5 finished with value: 26400.56404315224 and parameters: {'n_estimators': 286, 'learning_rate': 0.012729555696220068, 'max_depth': 8, 'subsample': 0.8319440077071831, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:58,413] Trial 15 finished with value: 26469.714492212985 and parameters: {'n_estimators': 97, 'learning_rate': 0.09803567524657192, 'max_depth': 10, 'subsample': 0.9306454125335751, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:58,496] Trial 8 finished with value: 26426.09029209963 and parameters: {'n_estimators': 293, 'learning_rate': 0.04027226389224872, 'max_depth': 6, 'subsample': 0.9539951226248555, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 2 with value: 25816.684129804307.\n",
      "[I 2024-06-21 18:26:58,694] Trial 16 finished with value: 25663.724729651225 and parameters: {'n_estimators': 154, 'learning_rate': 0.07878444610023908, 'max_depth': 8, 'subsample': 0.7638841008012535, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 16 with value: 25663.724729651225.\n",
      "[I 2024-06-21 18:26:58,841] Trial 13 finished with value: 29410.542226160753 and parameters: {'n_estimators': 243, 'learning_rate': 0.010398087036930433, 'max_depth': 5, 'subsample': 0.8158410413125149, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 16 with value: 25663.724729651225.\n",
      "[I 2024-06-21 18:27:01,714] Trial 18 finished with value: 26243.769355630542 and parameters: {'n_estimators': 257, 'learning_rate': 0.09832633964545025, 'max_depth': 6, 'subsample': 0.9901505199136881, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 16 with value: 25663.724729651225.\n",
      "[I 2024-06-21 18:27:02,059] Trial 17 finished with value: 25574.49104421279 and parameters: {'n_estimators': 288, 'learning_rate': 0.09855073840306187, 'max_depth': 7, 'subsample': 0.8407713960328207, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 17 with value: 25574.49104421279.\n",
      "[I 2024-06-21 18:27:02,520] Trial 22 finished with value: 25374.375484394186 and parameters: {'n_estimators': 227, 'learning_rate': 0.05854964830869971, 'max_depth': 6, 'subsample': 0.8820449201275795, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 22 with value: 25374.375484394186.\n",
      "[I 2024-06-21 18:27:02,565] Trial 20 finished with value: 26850.58597770998 and parameters: {'n_estimators': 236, 'learning_rate': 0.08985310348357212, 'max_depth': 6, 'subsample': 0.9977211542302553, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 22 with value: 25374.375484394186.\n",
      "[I 2024-06-21 18:27:02,677] Trial 19 finished with value: 26674.7853861179 and parameters: {'n_estimators': 258, 'learning_rate': 0.09606681621824355, 'max_depth': 6, 'subsample': 0.9927478900852567, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 22 with value: 25374.375484394186.\n",
      "[I 2024-06-21 18:27:02,886] Trial 21 finished with value: 27431.015805397867 and parameters: {'n_estimators': 232, 'learning_rate': 0.05663187199815954, 'max_depth': 6, 'subsample': 0.9979053547112248, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 22 with value: 25374.375484394186.\n",
      "[I 2024-06-21 18:27:03,184] Trial 24 finished with value: 25666.059690843922 and parameters: {'n_estimators': 222, 'learning_rate': 0.09656070993576232, 'max_depth': 7, 'subsample': 0.8669289243616495, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 22 with value: 25374.375484394186.\n",
      "[I 2024-06-21 18:27:03,304] Trial 23 finished with value: 25272.30508338343 and parameters: {'n_estimators': 236, 'learning_rate': 0.09528356579012298, 'max_depth': 7, 'subsample': 0.8674038789883336, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:04,251] Trial 25 finished with value: 26678.721639818694 and parameters: {'n_estimators': 139, 'learning_rate': 0.06829873228884423, 'max_depth': 7, 'subsample': 0.8733584324138803, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:04,377] Trial 26 finished with value: 25568.89085406838 and parameters: {'n_estimators': 138, 'learning_rate': 0.06635214467579888, 'max_depth': 7, 'subsample': 0.7866383406798537, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:05,239] Trial 28 finished with value: 25919.713836506573 and parameters: {'n_estimators': 146, 'learning_rate': 0.06888823747343467, 'max_depth': 7, 'subsample': 0.8707539047909417, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:05,612] Trial 30 finished with value: 26302.664258879515 and parameters: {'n_estimators': 136, 'learning_rate': 0.07111005634446899, 'max_depth': 8, 'subsample': 0.8662994058546087, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:05,724] Trial 31 finished with value: 25926.63059817002 and parameters: {'n_estimators': 137, 'learning_rate': 0.07112100071909119, 'max_depth': 8, 'subsample': 0.7833571380750605, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:06,827] Trial 29 finished with value: 26613.313603663002 and parameters: {'n_estimators': 210, 'learning_rate': 0.06806643392507067, 'max_depth': 8, 'subsample': 0.8730141221469772, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:07,586] Trial 27 finished with value: 25566.143019939464 and parameters: {'n_estimators': 271, 'learning_rate': 0.057503533664205, 'max_depth': 7, 'subsample': 0.8623460717391264, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:08,503] Trial 34 finished with value: 27005.20979860873 and parameters: {'n_estimators': 193, 'learning_rate': 0.07215814443033977, 'max_depth': 8, 'subsample': 0.9070601486032864, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:08,812] Trial 32 finished with value: 26714.718363937227 and parameters: {'n_estimators': 273, 'learning_rate': 0.07107994500171834, 'max_depth': 8, 'subsample': 0.8513912034884353, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:08,840] Trial 35 finished with value: 26112.141521012072 and parameters: {'n_estimators': 195, 'learning_rate': 0.04700039302915628, 'max_depth': 8, 'subsample': 0.7909059626373989, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 23 with value: 25272.30508338343.\n",
      "[I 2024-06-21 18:27:08,995] Trial 36 finished with value: 24971.19048044299 and parameters: {'n_estimators': 195, 'learning_rate': 0.05040615482646318, 'max_depth': 8, 'subsample': 0.7013518242989085, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 36 with value: 24971.19048044299.\n",
      "[I 2024-06-21 18:27:09,410] Trial 37 finished with value: 26484.68133989331 and parameters: {'n_estimators': 192, 'learning_rate': 0.04951310418539107, 'max_depth': 9, 'subsample': 0.7019605147929574, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 36 with value: 24971.19048044299.\n",
      "[I 2024-06-21 18:27:10,268] Trial 33 finished with value: 26770.613176015446 and parameters: {'n_estimators': 275, 'learning_rate': 0.07271888963552695, 'max_depth': 8, 'subsample': 0.9076318290681903, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 36 with value: 24971.19048044299.\n",
      "[I 2024-06-21 18:27:10,923] Trial 38 finished with value: 24761.064498985837 and parameters: {'n_estimators': 268, 'learning_rate': 0.05353817322474799, 'max_depth': 7, 'subsample': 0.7064758304180906, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 38 with value: 24761.064498985837.\n",
      "[I 2024-06-21 18:27:11,466] Trial 41 finished with value: 26059.011572130923 and parameters: {'n_estimators': 177, 'learning_rate': 0.04865732420093047, 'max_depth': 7, 'subsample': 0.701945653598148, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 24761.064498985837.\n",
      "[I 2024-06-21 18:27:11,560] Trial 42 finished with value: 25258.125940540045 and parameters: {'n_estimators': 176, 'learning_rate': 0.05189416930691921, 'max_depth': 7, 'subsample': 0.734346088716904, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 24761.064498985837.\n",
      "[I 2024-06-21 18:27:12,262] Trial 43 finished with value: 25624.660481107014 and parameters: {'n_estimators': 180, 'learning_rate': 0.05546848381558829, 'max_depth': 9, 'subsample': 0.7299425047135477, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 24761.064498985837.\n",
      "[I 2024-06-21 18:27:12,453] Trial 39 finished with value: 26064.552649612702 and parameters: {'n_estimators': 267, 'learning_rate': 0.05032516900017658, 'max_depth': 7, 'subsample': 0.90240992739259, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 38 with value: 24761.064498985837.\n",
      "[I 2024-06-21 18:27:12,761] Trial 40 finished with value: 25159.00623254589 and parameters: {'n_estimators': 265, 'learning_rate': 0.05182547776125235, 'max_depth': 7, 'subsample': 0.7911938394965083, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 38 with value: 24761.064498985837.\n",
      "[I 2024-06-21 18:27:12,901] Trial 44 finished with value: 24752.871454992674 and parameters: {'n_estimators': 254, 'learning_rate': 0.0569284817759682, 'max_depth': 5, 'subsample': 0.9076603587662184, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 44 with value: 24752.871454992674.\n",
      "[I 2024-06-21 18:27:12,987] Trial 45 finished with value: 24806.623653616145 and parameters: {'n_estimators': 253, 'learning_rate': 0.05853835137495084, 'max_depth': 5, 'subsample': 0.7221310769419018, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 44 with value: 24752.871454992674.\n",
      "[I 2024-06-21 18:27:13,193] Trial 46 finished with value: 25164.378375503748 and parameters: {'n_estimators': 212, 'learning_rate': 0.033287274862437134, 'max_depth': 5, 'subsample': 0.7254403879649297, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 44 with value: 24752.871454992674.\n",
      "[I 2024-06-21 18:27:13,920] Trial 48 finished with value: 25468.208582472707 and parameters: {'n_estimators': 215, 'learning_rate': 0.033587067873616594, 'max_depth': 6, 'subsample': 0.7282853316472679, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 44 with value: 24752.871454992674.\n",
      "[I 2024-06-21 18:27:14,325] Trial 49 finished with value: 25264.4469073122 and parameters: {'n_estimators': 212, 'learning_rate': 0.04254043285015542, 'max_depth': 6, 'subsample': 0.7209078469141487, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 44 with value: 24752.871454992674.\n",
      "[I 2024-06-21 18:27:14,646] Trial 47 finished with value: 25948.40494689591 and parameters: {'n_estimators': 216, 'learning_rate': 0.03471201750059658, 'max_depth': 9, 'subsample': 0.7273707611182085, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 44 with value: 24752.871454992674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 24752.87\n"
     ]
    }
   ],
   "source": [
    "def objective_gb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.7, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_gb = optuna.create_study(direction='minimize')\n",
    "study_gb.optimize(objective_gb, n_trials=50, n_jobs=-1)\n",
    "best_params_gb = study_gb.best_params\n",
    "\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    n_estimators=best_params_gb['n_estimators'],\n",
    "    learning_rate=best_params_gb['learning_rate'],\n",
    "    max_depth=best_params_gb['max_depth'],\n",
    "    subsample=best_params_gb['subsample'],\n",
    "    min_samples_split=best_params_gb['min_samples_split'],\n",
    "    min_samples_leaf=best_params_gb['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_gb.fit(X_train, y_train)\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "553b039b-ca10-4123-9482-c60374da8fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 18:27:16,956] A new study created in memory with name: no-name-97752b99-8102-40d8-9364-6811c3d8bbe6\n",
      "[I 2024-06-21 18:27:19,255] Trial 6 finished with value: 36614.29148786407 and parameters: {'n_estimators': 173, 'learning_rate': 0.012033775551671087, 'max_depth': 3, 'subsample': 0.9465329227040771, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 36614.29148786407.\n",
      "[I 2024-06-21 18:27:19,744] Trial 5 finished with value: 38874.869611721115 and parameters: {'n_estimators': 118, 'learning_rate': 0.010971519662208567, 'max_depth': 6, 'subsample': 0.9501847354626695, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 36614.29148786407.\n",
      "[I 2024-06-21 18:27:19,850] Trial 1 finished with value: 37898.10687525293 and parameters: {'n_estimators': 80, 'learning_rate': 0.016969850997249004, 'max_depth': 10, 'subsample': 0.9963886760945527, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 6 with value: 36614.29148786407.\n",
      "[I 2024-06-21 18:27:22,482] Trial 3 finished with value: 26915.907039458478 and parameters: {'n_estimators': 292, 'learning_rate': 0.016531562618522955, 'max_depth': 6, 'subsample': 0.924132777280011, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 3 with value: 26915.907039458478.\n",
      "[I 2024-06-21 18:27:23,301] Trial 10 finished with value: 26483.457064468927 and parameters: {'n_estimators': 289, 'learning_rate': 0.018791954145538192, 'max_depth': 4, 'subsample': 0.9967650983546174, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 10 with value: 26483.457064468927.\n",
      "[I 2024-06-21 18:27:23,575] Trial 4 finished with value: 25384.328468576867 and parameters: {'n_estimators': 645, 'learning_rate': 0.025881720732314338, 'max_depth': 3, 'subsample': 0.9272612301192285, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 4 with value: 25384.328468576867.\n",
      "[I 2024-06-21 18:27:26,539] Trial 13 finished with value: 26090.529816284845 and parameters: {'n_estimators': 241, 'learning_rate': 0.026162435474779866, 'max_depth': 5, 'subsample': 0.7552691128127643, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 4 with value: 25384.328468576867.\n",
      "[I 2024-06-21 18:27:27,257] Trial 0 finished with value: 26633.724962846543 and parameters: {'n_estimators': 450, 'learning_rate': 0.012202998992576621, 'max_depth': 9, 'subsample': 0.7991424244058615, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 4 with value: 25384.328468576867.\n",
      "[I 2024-06-21 18:27:27,685] Trial 12 finished with value: 27370.51596078714 and parameters: {'n_estimators': 208, 'learning_rate': 0.015401063885152213, 'max_depth': 9, 'subsample': 0.7206488997943468, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 4 with value: 25384.328468576867.\n",
      "[I 2024-06-21 18:27:27,712] Trial 2 finished with value: 24929.667835795335 and parameters: {'n_estimators': 629, 'learning_rate': 0.013820488870413, 'max_depth': 7, 'subsample': 0.7579503318874308, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:28,951] Trial 7 finished with value: 25458.66660193562 and parameters: {'n_estimators': 554, 'learning_rate': 0.04222378247439385, 'max_depth': 8, 'subsample': 0.8591453188899543, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:29,723] Trial 9 finished with value: 25016.16014441883 and parameters: {'n_estimators': 721, 'learning_rate': 0.06878185012186593, 'max_depth': 5, 'subsample': 0.873316301006882, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:33,465] Trial 15 finished with value: 26490.349985669993 and parameters: {'n_estimators': 309, 'learning_rate': 0.025154084075319057, 'max_depth': 9, 'subsample': 0.7925842861019338, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:33,568] Trial 14 finished with value: 26267.96481044069 and parameters: {'n_estimators': 380, 'learning_rate': 0.048757366138033414, 'max_depth': 8, 'subsample': 0.798601434207779, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:35,446] Trial 16 finished with value: 25014.85009323916 and parameters: {'n_estimators': 661, 'learning_rate': 0.010283771187565904, 'max_depth': 5, 'subsample': 0.7628093662277983, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:35,755] Trial 8 finished with value: 26343.166034254013 and parameters: {'n_estimators': 696, 'learning_rate': 0.0401642643896462, 'max_depth': 10, 'subsample': 0.841862135820163, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:38,699] Trial 11 finished with value: 26782.718110469636 and parameters: {'n_estimators': 798, 'learning_rate': 0.03149801324729597, 'max_depth': 7, 'subsample': 0.9998428628471888, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:42,370] Trial 17 finished with value: 26150.062517305247 and parameters: {'n_estimators': 774, 'learning_rate': 0.06386093960350406, 'max_depth': 8, 'subsample': 0.837338756461219, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:42,464] Trial 18 finished with value: 26361.590453073928 and parameters: {'n_estimators': 783, 'learning_rate': 0.0713761406365933, 'max_depth': 7, 'subsample': 0.8581473719156603, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:42,995] Trial 19 finished with value: 26578.09460533391 and parameters: {'n_estimators': 787, 'learning_rate': 0.09935639981979554, 'max_depth': 7, 'subsample': 0.8529794931835912, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:44,448] Trial 23 finished with value: 26047.131006407693 and parameters: {'n_estimators': 583, 'learning_rate': 0.010114566732281699, 'max_depth': 7, 'subsample': 0.7046581090588033, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:46,003] Trial 20 finished with value: 26317.452216737016 and parameters: {'n_estimators': 737, 'learning_rate': 0.09065276330544018, 'max_depth': 7, 'subsample': 0.8549301005272093, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:46,697] Trial 24 finished with value: 25654.320251890804 and parameters: {'n_estimators': 557, 'learning_rate': 0.010036962645858532, 'max_depth': 7, 'subsample': 0.7162978643146037, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:47,152] Trial 22 finished with value: 27805.818052770283 and parameters: {'n_estimators': 798, 'learning_rate': 0.09698778231459877, 'max_depth': 7, 'subsample': 0.7048327176475705, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:47,390] Trial 21 finished with value: 26495.112604319907 and parameters: {'n_estimators': 787, 'learning_rate': 0.0997618251143774, 'max_depth': 7, 'subsample': 0.8654018918866843, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 2 with value: 24929.667835795335.\n",
      "[I 2024-06-21 18:27:48,495] Trial 26 finished with value: 24464.872197777357 and parameters: {'n_estimators': 558, 'learning_rate': 0.013933961100634105, 'max_depth': 5, 'subsample': 0.7021624087006317, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:48,769] Trial 25 finished with value: 24884.057142738737 and parameters: {'n_estimators': 575, 'learning_rate': 0.010305785910239413, 'max_depth': 5, 'subsample': 0.7067641874228765, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:49,455] Trial 27 finished with value: 24574.65000335049 and parameters: {'n_estimators': 585, 'learning_rate': 0.01315092874005822, 'max_depth': 5, 'subsample': 0.7320230672268488, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:52,111] Trial 28 finished with value: 25166.17702768651 and parameters: {'n_estimators': 675, 'learning_rate': 0.013687878468944223, 'max_depth': 5, 'subsample': 0.7471155022138418, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:52,317] Trial 29 finished with value: 25214.761476185504 and parameters: {'n_estimators': 556, 'learning_rate': 0.013641136577612812, 'max_depth': 5, 'subsample': 0.7520228471542353, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:53,234] Trial 34 finished with value: 24958.155641000914 and parameters: {'n_estimators': 479, 'learning_rate': 0.014400263449698287, 'max_depth': 4, 'subsample': 0.7427418116433667, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:53,840] Trial 30 finished with value: 25150.681258165056 and parameters: {'n_estimators': 636, 'learning_rate': 0.013947506744406405, 'max_depth': 5, 'subsample': 0.7536900615223021, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:53,907] Trial 33 finished with value: 25473.46647732246 and parameters: {'n_estimators': 476, 'learning_rate': 0.014014781126753377, 'max_depth': 5, 'subsample': 0.7496113175985645, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:53,978] Trial 35 finished with value: 24907.44344471108 and parameters: {'n_estimators': 486, 'learning_rate': 0.021854361186589937, 'max_depth': 4, 'subsample': 0.7410317576741909, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:54,358] Trial 31 finished with value: 24727.412697247397 and parameters: {'n_estimators': 648, 'learning_rate': 0.014838198751645547, 'max_depth': 5, 'subsample': 0.7624758844601476, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:55,011] Trial 32 finished with value: 24774.842489035378 and parameters: {'n_estimators': 666, 'learning_rate': 0.013899141589858782, 'max_depth': 5, 'subsample': 0.7632502800957137, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 26 with value: 24464.872197777357.\n",
      "[I 2024-06-21 18:27:56,655] Trial 36 finished with value: 24351.299396490296 and parameters: {'n_estimators': 487, 'learning_rate': 0.021033765682018857, 'max_depth': 4, 'subsample': 0.7347235814275724, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:27:57,093] Trial 37 finished with value: 25026.298404381567 and parameters: {'n_estimators': 472, 'learning_rate': 0.02036833562741971, 'max_depth': 4, 'subsample': 0.7797776323770339, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:27:58,211] Trial 41 finished with value: 25105.791480920652 and parameters: {'n_estimators': 416, 'learning_rate': 0.019377495241478977, 'max_depth': 4, 'subsample': 0.7748579993884719, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:27:58,281] Trial 38 finished with value: 24359.983374075444 and parameters: {'n_estimators': 478, 'learning_rate': 0.01964346146628285, 'max_depth': 4, 'subsample': 0.7785329697477035, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:27:59,067] Trial 39 finished with value: 24635.17581533687 and parameters: {'n_estimators': 475, 'learning_rate': 0.018910838209930645, 'max_depth': 4, 'subsample': 0.777195304451668, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:27:59,877] Trial 40 finished with value: 25017.672071323865 and parameters: {'n_estimators': 417, 'learning_rate': 0.019074680738328284, 'max_depth': 6, 'subsample': 0.7282901487523401, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:01,557] Trial 43 finished with value: 25617.596082291617 and parameters: {'n_estimators': 421, 'learning_rate': 0.018831058939754442, 'max_depth': 6, 'subsample': 0.7734691668265599, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:02,353] Trial 44 finished with value: 25060.930410558594 and parameters: {'n_estimators': 386, 'learning_rate': 0.01840572189511899, 'max_depth': 6, 'subsample': 0.7268403947719011, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:03,060] Trial 47 finished with value: 25567.952607561194 and parameters: {'n_estimators': 526, 'learning_rate': 0.01694200863403607, 'max_depth': 3, 'subsample': 0.8205936202623669, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:03,445] Trial 42 finished with value: 25021.61850123813 and parameters: {'n_estimators': 606, 'learning_rate': 0.018130601256903682, 'max_depth': 6, 'subsample': 0.7777495779817448, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:03,496] Trial 48 finished with value: 25702.358924387918 and parameters: {'n_estimators': 515, 'learning_rate': 0.017102807129952893, 'max_depth': 3, 'subsample': 0.8223816269316032, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:03,666] Trial 45 finished with value: 25460.03447957549 and parameters: {'n_estimators': 424, 'learning_rate': 0.011887914711965007, 'max_depth': 6, 'subsample': 0.8225810960565777, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:03,860] Trial 49 finished with value: 26074.05063123319 and parameters: {'n_estimators': 517, 'learning_rate': 0.0168718546195571, 'max_depth': 3, 'subsample': 0.8171287929741455, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 36 with value: 24351.299396490296.\n",
      "[I 2024-06-21 18:28:05,268] Trial 46 finished with value: 24662.070570174124 and parameters: {'n_estimators': 598, 'learning_rate': 0.016776566191922606, 'max_depth': 6, 'subsample': 0.7258614045017497, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 36 with value: 24351.299396490296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting RMSE: 24351.30\n"
     ]
    }
   ],
   "source": [
    "def objective_gb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 800)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.7, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study_gb = optuna.create_study(direction='minimize')\n",
    "study_gb.optimize(objective_gb, n_trials=50, n_jobs=-1)\n",
    "best_params_gb = study_gb.best_params\n",
    "\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    n_estimators=best_params_gb['n_estimators'],\n",
    "    learning_rate=best_params_gb['learning_rate'],\n",
    "    max_depth=best_params_gb['max_depth'],\n",
    "    subsample=best_params_gb['subsample'],\n",
    "    min_samples_split=best_params_gb['min_samples_split'],\n",
    "    min_samples_leaf=best_params_gb['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_gb.fit(X_train, y_train)\n",
    "gb_rmse = mean_squared_error(y_test, best_gb.predict(X_test), squared=False)\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82d37fe9-4741-4a93-9cb3-5c44c7ef8fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 18:28:08,062] A new study created in memory with name: no-name-46b8c0a2-e549-472a-894c-0ecca74845a0\n",
      "[I 2024-06-21 18:28:09,298] Trial 4 finished with value: 55820.5390625 and parameters: {'n_estimators': 61, 'learning_rate': 0.010668140802295433, 'max_depth': 9, 'subsample': 0.9658454569157986, 'colsample_bytree': 0.8682015181566904}. Best is trial 4 with value: 55820.5390625.\n",
      "[I 2024-06-21 18:28:09,496] Trial 2 finished with value: 29567.28515625 and parameters: {'n_estimators': 72, 'learning_rate': 0.03531730952878587, 'max_depth': 9, 'subsample': 0.8978142119618417, 'colsample_bytree': 0.9697431010781125}. Best is trial 2 with value: 29567.28515625.\n",
      "[I 2024-06-21 18:28:09,890] Trial 6 finished with value: 25203.140625 and parameters: {'n_estimators': 168, 'learning_rate': 0.03418601977043926, 'max_depth': 5, 'subsample': 0.8265267343501088, 'colsample_bytree': 0.8559118471989939}. Best is trial 6 with value: 25203.140625.\n",
      "[I 2024-06-21 18:28:10,101] Trial 5 finished with value: 24857.62109375 and parameters: {'n_estimators': 276, 'learning_rate': 0.03998182510702095, 'max_depth': 3, 'subsample': 0.8852009161958123, 'colsample_bytree': 0.856044308106858}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:10,251] Trial 7 finished with value: 31904.400390625 and parameters: {'n_estimators': 232, 'learning_rate': 0.010118480065463495, 'max_depth': 4, 'subsample': 0.8639795808379638, 'colsample_bytree': 0.9477764790138545}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:10,917] Trial 0 finished with value: 25097.501953125 and parameters: {'n_estimators': 261, 'learning_rate': 0.05256928008346467, 'max_depth': 5, 'subsample': 0.8589320645372814, 'colsample_bytree': 0.8671986407722394}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:10,954] Trial 8 finished with value: 28207.240234375 and parameters: {'n_estimators': 127, 'learning_rate': 0.0238926833774258, 'max_depth': 6, 'subsample': 0.721965296281675, 'colsample_bytree': 0.8694494326815957}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:12,079] Trial 10 finished with value: 25312.025390625 and parameters: {'n_estimators': 154, 'learning_rate': 0.03282353855668056, 'max_depth': 5, 'subsample': 0.7788390238028564, 'colsample_bytree': 0.8603680117399125}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:12,846] Trial 12 finished with value: 29357.736328125 and parameters: {'n_estimators': 268, 'learning_rate': 0.013883361138973186, 'max_depth': 3, 'subsample': 0.8618985960966227, 'colsample_bytree': 0.8160805238700921}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:12,931] Trial 1 finished with value: 25609.638671875 and parameters: {'n_estimators': 281, 'learning_rate': 0.03860751918476982, 'max_depth': 7, 'subsample': 0.8673575640541318, 'colsample_bytree': 0.8809846075173547}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:13,953] Trial 11 finished with value: 25282.482421875 and parameters: {'n_estimators': 201, 'learning_rate': 0.09949621136941586, 'max_depth': 8, 'subsample': 0.9624499245870299, 'colsample_bytree': 0.8347316308368419}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:14,069] Trial 3 finished with value: 27813.83203125 and parameters: {'n_estimators': 262, 'learning_rate': 0.011888094844677989, 'max_depth': 10, 'subsample': 0.7987891572024948, 'colsample_bytree': 0.9477840982355001}. Best is trial 5 with value: 24857.62109375.\n",
      "[I 2024-06-21 18:28:14,167] Trial 14 finished with value: 24839.814453125 and parameters: {'n_estimators': 291, 'learning_rate': 0.05156160144452398, 'max_depth': 4, 'subsample': 0.8700106659426433, 'colsample_bytree': 0.9161434489740591}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:14,249] Trial 13 finished with value: 25535.12109375 and parameters: {'n_estimators': 299, 'learning_rate': 0.025799003563836412, 'max_depth': 4, 'subsample': 0.9237113138769008, 'colsample_bytree': 0.9992856016559639}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:14,380] Trial 17 finished with value: 26151.330078125 and parameters: {'n_estimators': 215, 'learning_rate': 0.09454897509558813, 'max_depth': 3, 'subsample': 0.9986920893543288, 'colsample_bytree': 0.7078161747512388}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:14,497] Trial 9 finished with value: 26259.27734375 and parameters: {'n_estimators': 298, 'learning_rate': 0.015490767676038547, 'max_depth': 7, 'subsample': 0.9269059995350226, 'colsample_bytree': 0.8567900604962795}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:14,873] Trial 15 finished with value: 25016.79296875 and parameters: {'n_estimators': 295, 'learning_rate': 0.057308734977156946, 'max_depth': 4, 'subsample': 0.789164730420908, 'colsample_bytree': 0.9149969395768799}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:15,059] Trial 16 finished with value: 25378.412109375 and parameters: {'n_estimators': 147, 'learning_rate': 0.06571541348029726, 'max_depth': 8, 'subsample': 0.8177926307000283, 'colsample_bytree': 0.8353749777987234}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:15,450] Trial 19 finished with value: 25266.73828125 and parameters: {'n_estimators': 215, 'learning_rate': 0.06573124177244637, 'max_depth': 3, 'subsample': 0.9250292677124236, 'colsample_bytree': 0.7036878092751282}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:15,678] Trial 21 finished with value: 25007.5859375 and parameters: {'n_estimators': 219, 'learning_rate': 0.061528896315254704, 'max_depth': 3, 'subsample': 0.9241858144555737, 'colsample_bytree': 0.7484046074752647}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:15,825] Trial 22 finished with value: 25022.76953125 and parameters: {'n_estimators': 235, 'learning_rate': 0.06036041895176753, 'max_depth': 3, 'subsample': 0.9131561364426051, 'colsample_bytree': 0.7869499806951721}. Best is trial 14 with value: 24839.814453125.\n",
      "[I 2024-06-21 18:28:15,880] Trial 18 finished with value: 24575.615234375 and parameters: {'n_estimators': 300, 'learning_rate': 0.0641106637420257, 'max_depth': 3, 'subsample': 0.9204143136134896, 'colsample_bytree': 0.7157414842645327}. Best is trial 18 with value: 24575.615234375.\n",
      "[I 2024-06-21 18:28:15,961] Trial 23 finished with value: 24852.2421875 and parameters: {'n_estimators': 237, 'learning_rate': 0.06120261568430334, 'max_depth': 3, 'subsample': 0.7506487786709775, 'colsample_bytree': 0.7752853119982717}. Best is trial 18 with value: 24575.615234375.\n",
      "[I 2024-06-21 18:28:16,080] Trial 20 finished with value: 25625.244140625 and parameters: {'n_estimators': 296, 'learning_rate': 0.0650102236804627, 'max_depth': 3, 'subsample': 0.9263587326188191, 'colsample_bytree': 0.7364053898737347}. Best is trial 18 with value: 24575.615234375.\n",
      "[I 2024-06-21 18:28:16,383] Trial 24 finished with value: 25242.314453125 and parameters: {'n_estimators': 236, 'learning_rate': 0.06249360754726051, 'max_depth': 3, 'subsample': 0.9025640267305713, 'colsample_bytree': 0.7863387575883215}. Best is trial 18 with value: 24575.615234375.\n",
      "[I 2024-06-21 18:28:16,592] Trial 25 finished with value: 25919.962890625 and parameters: {'n_estimators': 240, 'learning_rate': 0.04508416157191589, 'max_depth': 3, 'subsample': 0.9026565310506711, 'colsample_bytree': 0.772867603829747}. Best is trial 18 with value: 24575.615234375.\n",
      "[I 2024-06-21 18:28:17,741] Trial 28 finished with value: 24892.421875 and parameters: {'n_estimators': 249, 'learning_rate': 0.04538639790170603, 'max_depth': 4, 'subsample': 0.8891659133472707, 'colsample_bytree': 0.7595640455460237}. Best is trial 18 with value: 24575.615234375.\n",
      "[I 2024-06-21 18:28:17,798] Trial 29 finished with value: 24366.603515625 and parameters: {'n_estimators': 252, 'learning_rate': 0.044749405603491194, 'max_depth': 4, 'subsample': 0.8849915774649532, 'colsample_bytree': 0.9131219422931061}. Best is trial 29 with value: 24366.603515625.\n",
      "[I 2024-06-21 18:28:17,808] Trial 30 finished with value: 24552.015625 and parameters: {'n_estimators': 245, 'learning_rate': 0.07880056159043378, 'max_depth': 4, 'subsample': 0.7163075044202922, 'colsample_bytree': 0.7496752749494826}. Best is trial 29 with value: 24366.603515625.\n",
      "[I 2024-06-21 18:28:18,112] Trial 31 finished with value: 24354.42578125 and parameters: {'n_estimators': 247, 'learning_rate': 0.04636487433957198, 'max_depth': 4, 'subsample': 0.7434041758696306, 'colsample_bytree': 0.7762938181268443}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:18,167] Trial 33 finished with value: 24969.470703125 and parameters: {'n_estimators': 190, 'learning_rate': 0.07724731137720137, 'max_depth': 4, 'subsample': 0.7081708667590523, 'colsample_bytree': 0.7376035111147734}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:18,278] Trial 26 finished with value: 24907.03125 and parameters: {'n_estimators': 247, 'learning_rate': 0.043718921025179415, 'max_depth': 6, 'subsample': 0.7568811834303162, 'colsample_bytree': 0.7853797068445292}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:18,448] Trial 32 finished with value: 24488.0234375 and parameters: {'n_estimators': 251, 'learning_rate': 0.04726522301449749, 'max_depth': 4, 'subsample': 0.7454207584830158, 'colsample_bytree': 0.747391251554086}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:18,597] Trial 27 finished with value: 25256.341796875 and parameters: {'n_estimators': 253, 'learning_rate': 0.04458903125359104, 'max_depth': 6, 'subsample': 0.7409167169176887, 'colsample_bytree': 0.8008128286458902}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:20,014] Trial 34 finished with value: 25286.240234375 and parameters: {'n_estimators': 192, 'learning_rate': 0.08773229737202855, 'max_depth': 6, 'subsample': 0.8326032021766017, 'colsample_bytree': 0.7252309107545069}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:20,066] Trial 36 finished with value: 25029.64453125 and parameters: {'n_estimators': 192, 'learning_rate': 0.0844933282104841, 'max_depth': 6, 'subsample': 0.7099555304482168, 'colsample_bytree': 0.7274645903280026}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:20,118] Trial 35 finished with value: 25741.76171875 and parameters: {'n_estimators': 195, 'learning_rate': 0.02689317242584654, 'max_depth': 6, 'subsample': 0.8325046667906726, 'colsample_bytree': 0.905718641336022}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:20,270] Trial 37 finished with value: 25033.921875 and parameters: {'n_estimators': 191, 'learning_rate': 0.08064304845598169, 'max_depth': 6, 'subsample': 0.7058157640330016, 'colsample_bytree': 0.8203188085834532}. Best is trial 31 with value: 24354.42578125.\n",
      "[I 2024-06-21 18:28:20,635] Trial 38 finished with value: 24304.041015625 and parameters: {'n_estimators': 259, 'learning_rate': 0.08116660273132155, 'max_depth': 5, 'subsample': 0.7223400129851532, 'colsample_bytree': 0.71382371531788}. Best is trial 38 with value: 24304.041015625.\n",
      "[I 2024-06-21 18:28:20,731] Trial 39 finished with value: 24118.86328125 and parameters: {'n_estimators': 258, 'learning_rate': 0.07991332711473557, 'max_depth': 5, 'subsample': 0.7414811118284349, 'colsample_bytree': 0.7278719405366092}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:20,904] Trial 40 finished with value: 25161.431640625 and parameters: {'n_estimators': 260, 'learning_rate': 0.026514579009197518, 'max_depth': 5, 'subsample': 0.7253142114146546, 'colsample_bytree': 0.8137486119458998}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:21,072] Trial 41 finished with value: 25420.212890625 and parameters: {'n_estimators': 266, 'learning_rate': 0.02196424270149884, 'max_depth': 5, 'subsample': 0.7061433545340622, 'colsample_bytree': 0.8971505668564443}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:22,513] Trial 42 finished with value: 25510.228515625 and parameters: {'n_estimators': 266, 'learning_rate': 0.023410533696105226, 'max_depth': 5, 'subsample': 0.7037364793364809, 'colsample_bytree': 0.892196051651291}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:22,540] Trial 43 finished with value: 25660.271484375 and parameters: {'n_estimators': 269, 'learning_rate': 0.02707355051178789, 'max_depth': 5, 'subsample': 0.770547694967994, 'colsample_bytree': 0.8886366427741877}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:22,612] Trial 44 finished with value: 25041.966796875 and parameters: {'n_estimators': 275, 'learning_rate': 0.051205916040126885, 'max_depth': 5, 'subsample': 0.7277733631322418, 'colsample_bytree': 0.7547032043944213}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:22,719] Trial 45 finished with value: 25188.185546875 and parameters: {'n_estimators': 272, 'learning_rate': 0.05228621622292472, 'max_depth': 5, 'subsample': 0.7327248453587712, 'colsample_bytree': 0.7493127262506991}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:22,903] Trial 46 finished with value: 25012.955078125 and parameters: {'n_estimators': 276, 'learning_rate': 0.029222074744817764, 'max_depth': 5, 'subsample': 0.7699238788082083, 'colsample_bytree': 0.8875749542117402}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:22,983] Trial 47 finished with value: 24844.640625 and parameters: {'n_estimators': 281, 'learning_rate': 0.03755878982939465, 'max_depth': 5, 'subsample': 0.7728684277140583, 'colsample_bytree': 0.894915438929465}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:23,039] Trial 48 finished with value: 24779.20703125 and parameters: {'n_estimators': 278, 'learning_rate': 0.05203119612761126, 'max_depth': 5, 'subsample': 0.7682401340761386, 'colsample_bytree': 0.8929028130670258}. Best is trial 39 with value: 24118.86328125.\n",
      "[I 2024-06-21 18:28:23,117] Trial 49 finished with value: 24295.462890625 and parameters: {'n_estimators': 279, 'learning_rate': 0.03727942746181385, 'max_depth': 5, 'subsample': 0.73801780517875, 'colsample_bytree': 0.7589379641748379}. Best is trial 39 with value: 24118.86328125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost RMSE: 24118.86\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.7, 1.0)\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.7, 1.0)\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    return rmse\n",
    "\n",
    "study_xgb = optuna.create_study(direction='minimize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, n_jobs=-1)\n",
    "best_params_xgb = study_xgb.best_params\n",
    "\n",
    "best_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=best_params_xgb['n_estimators'],\n",
    "    learning_rate=best_params_xgb['learning_rate'],\n",
    "    max_depth=best_params_xgb['max_depth'],\n",
    "    subsample=best_params_xgb['subsample'],\n",
    "    colsample_bytree=best_params_xgb['colsample_bytree'],\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "best_xgb.fit(X_train, y_train)\n",
    "xgb_rmse = root_mean_squared_error(y_test, best_xgb.predict(X_test))\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f0f938a-d553-4073-9404-7a5e167a2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression RMSE: 28827.65\n",
      "Best Random Forest RMSE: 28834.45\n",
      "Best Gradient Boosting RMSE: 24351.30\n",
      "Best XGBoost RMSE: 24118.86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Ridge Regression RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"Best Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"Best Gradient Boosting RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"Best XGBoost RMSE: {xgb_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d127-98a1-4e28-a8f9-3e55e8b82f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16fa5696-9c5c-434c-8c34-da2bb1cbc8a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uzf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muzf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'uzf' is not defined"
     ]
    }
   ],
   "source": [
    "uzf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddf19b-fb92-4e08-aed9-628cade1d21a",
   "metadata": {},
   "source": [
    "***\n",
    "### Anwenden Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61b82f2d-64a1-4b31-abe8-19a41e004cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_original = pd.read_csv(test_data_path)\n",
    "# Prepare the test data for prediction\n",
    "df_test_imputed = pd.get_dummies(df_test_imputed, drop_first=True)\n",
    "\n",
    "# Ensure the test data has the same columns as the training data\n",
    "missing_cols = set(X_train.columns) - set(df_test_imputed.columns)\n",
    "for col in missing_cols:\n",
    "    df_test_imputed[col] = 0\n",
    "df_test_imputed = df_test_imputed[X_train.columns]\n",
    "\n",
    "# Sicherstellen, dass 'Id' in den ursprünglichen Testdaten vorhanden ist\n",
    "test_ids = df_test_original['Id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e0a4662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'submission_xgb.csv'\n"
     ]
    }
   ],
   "source": [
    "# Vorhersagen mit dem XGBoost-Modell\n",
    "X_test_final = df_test_imputed.astype(np.float32)\n",
    "y_pred_xgb = xg_reg.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von XGBoost-Modell)\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_xgb\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_xgb.to_csv('submission_xgb.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'submission_xgb.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42eb4a1a-ae39-4ac7-b4c6-ead6c47f661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen mit dem Ridge-Modell\n",
    "X_test_final = df_test_imputed.astype(np.float32)\n",
    "y_pred_ridge = best_ridge.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von Ridge-Modell)\n",
    "submission_ridge = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_ridge\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_ridge.to_csv('submission_ridge.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87c3f0fc-313e-4195-8e63-926351d029dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen mit dem Random Forest-Modell\n",
    "y_pred_rf = best_rf.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von Random Forest-Modell)\n",
    "submission_rf = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_rf\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_rf.to_csv('submission_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f223b7f-b9fb-4a33-a2bb-1bb9d564651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen mit dem Gradient Boosting-Modell\n",
    "y_pred_gb = best_gb.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von Gradient Boosting-Modell)\n",
    "submission_gb = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_gb\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_gb.to_csv('submission_gb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff6eb20a-1067-4b6f-b938-792a74eaeec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'submission_ridge.csv', 'submission_rf.csv', 'submission_gb.csv', and 'submission_xgboost.csv'\n"
     ]
    }
   ],
   "source": [
    "# Vorhersagen mit dem XGBoost-Modell\n",
    "y_pred_xgboost = best_xgb.predict(X_test_final)\n",
    "\n",
    "# Erstellen des DataFrames mit 'Id' und 'SalePrice' (von XGBoost-Modell)\n",
    "submission_xgboost = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred_xgboost\n",
    "})\n",
    "\n",
    "# Exportieren als CSV\n",
    "submission_xgboost.to_csv('submission_xgboost.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'submission_ridge.csv', 'submission_rf.csv', 'submission_gb.csv', and 'submission_xgboost.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
